"""
ë²•ì œì²˜ ë²•ë ¹ ìˆ˜ì§‘ê¸° - ë²„ê·¸ ìˆ˜ì • ì™„ë£Œ ë²„ì „ (v6.6)
- ë²•ë ¹ëª… ì¶”ì¶œ ì •í™•ë„ ê°œì„  (ì—°ê²°ëœ í…ìŠ¤íŠ¸ ë¶„ë¦¬)
- ì¤‘ë³µ ìˆ˜ì§‘ ë°©ì§€
- PDF ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ ìˆ˜ì •
"""

import streamlit as st
import requests
import xml.etree.ElementTree as ET
import json
import time
import re
import os
from datetime import datetime
from io import BytesIO
import zipfile
import pandas as pd
import PyPDF2
import pdfplumber
from typing import List, Set, Dict, Optional, Tuple, Any
from dataclasses import dataclass
from functools import lru_cache
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
import base64

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ“š ë²•ì œì²˜ ë²•ë ¹ ìˆ˜ì§‘ê¸°",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===== ì„¤ì • í´ë˜ìŠ¤ =====
@dataclass
class APIConfig:
    """API ì„¤ì •ì„ ê´€ë¦¬í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    # ë²•ì œì²˜ API ì—”ë“œí¬ì¸íŠ¸
    LAW_SEARCH_URL = "https://www.law.go.kr/DRF/lawSearch.do"  # ì¼ë°˜ ë²•ë ¹ ê²€ìƒ‰
    LAW_DETAIL_URL = "https://www.law.go.kr/DRF/lawService.do"  # ë²•ë ¹ ìƒì„¸
    ADMIN_RULE_SEARCH_URL = "https://www.law.go.kr/DRF/lawSearch.do"  # í–‰ì •ê·œì¹™ ê²€ìƒ‰
    ADMIN_RULE_DETAIL_URL = "https://www.law.go.kr/DRF/lawService.do"  # í–‰ì •ê·œì¹™ë„ ë™ì¼ ì„œë¹„ìŠ¤ ì‚¬ìš©
    
    # PDF ë‹¤ìš´ë¡œë“œ URL íŒ¨í„´
    PDF_DOWNLOAD_URL = "https://www.law.go.kr/flDownload.do"
    
    # API ì„¤ì •
    DEFAULT_DELAY = 0.3  # API í˜¸ì¶œ ê°„ê²© (ì´ˆ)
    MAX_RETRIES = 3      # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
    TIMEOUT = 30         # íƒ€ì„ì•„ì›ƒ (ì´ˆ)
    MAX_CONCURRENT = 5   # ìµœëŒ€ ë™ì‹œ ìš”ì²­ ìˆ˜
    
    # í˜ì´ì§€ë‹¹ ê²°ê³¼ ìˆ˜
    RESULTS_PER_PAGE = 100


class LawPatterns:
    """ë²•ë ¹ëª… ì¶”ì¶œ íŒ¨í„´ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ - ê°œì„ ëœ ë²„ì „"""
    
    # ì œì™¸ í‚¤ì›Œë“œ (ìˆ˜ì •: í‚¤ì›Œë“œë§Œ ë‚¨ê¹€)
    EXCLUDE_KEYWORDS = {
        'ìƒí•˜ìœ„ë²•', 'ê´€ë ¨ë²•ë ¹', 'ìƒìœ„ë²•', 'í•˜ìœ„ë²•', 'ì„ íƒëœ'
    }
    
    # ë²•ë ¹ íƒ€ì…
    LAW_TYPES = {
        'ë²•', 'ë²•ë¥ ', 'ì‹œí–‰ë ¹', 'ì‹œí–‰ê·œì¹™', 'ê·œì •', 'ê·œì¹™', 'ì„¸ì¹™', 
        'ê³ ì‹œ', 'í›ˆë ¹', 'ì˜ˆê·œ', 'ì§€ì¹¨', 'ë¶„ë¥˜', 'ì—…ë¬´ê·œì •', 'ê°ë…ê·œì •'
    }
    
    # í–‰ì •ê·œì¹™ í‚¤ì›Œë“œ
    ADMIN_KEYWORDS = {
        'ê·œì •', 'ê³ ì‹œ', 'í›ˆë ¹', 'ì˜ˆê·œ', 'ì§€ì¹¨', 'ì„¸ì¹™', 'ê¸°ì¤€', 'ìš”ë ¹', 'ì§€ì‹œ'
    }
    
    # ì œê±°í•  ì ‘ë‘ì–´ íŒ¨í„´
    PREFIX_PATTERNS = [
        r'^í–‰ì •ê·œì¹™\s*',
        r'^ë²•ë ¹\s*',
        r'^\d{8}\s*',  # ë‚ ì§œ í˜•ì‹ (20250422 ê°™ì€)
        r'^\d+\.\s*',  # ë²ˆí˜¸ í˜•ì‹ (1. 2. ê°™ì€)
    ]
    
    # ë²•ë ¹ëª… íŒ¨í„´ (ì •ê·œí‘œí˜„ì‹) - ê°œì„ ëœ ë²„ì „
    LAW_PATTERNS = [
        # ì‹œí–‰ ë‚ ì§œ í¬í•¨ íŒ¨í„´
        r'([ê°€-í£]+(?:\s+[ê°€-í£]+)*(?:ë²•|ë²•ë¥ |ê·œì •|ê·œì¹™|ì„¸ì¹™|ë¶„ë¥˜))\s*\[ì‹œí–‰\s*\d{4}\.\s*\d{1,2}\.\s*\d{1,2}\.\]',
        # ë…ë¦½ì ì¸ ê·œì •/ì„¸ì¹™
        r'^([ê°€-í£]+(?:(?:\s+ë°\s+)|(?:\s+))?[ê°€-í£]*(?:ì—\s*ê´€í•œ\s*)?(?:ê·œì •|ì—…ë¬´ê·œì •|ê°ë…ê·œì •|ìš´ì˜ê·œì •|ê´€ë¦¬ê·œì •))(?:\s|$)',
        # ì‹œí–‰ì„¸ì¹™
        r'^([ê°€-í£]+(?:(?:\s+ë°\s+)|(?:\s+))?[ê°€-í£]*(?:ì—…ë¬´)?ì‹œí–‰ì„¸ì¹™)(?:\s|$)',
        # ë¶™ì–´ìˆëŠ” í˜•íƒœ
        r'([ê°€-í£]+(?:ê²€ì‚¬ë°ì œì¬ì—ê´€í•œ|ì—ê´€í•œ)?ê·œì •)(?:\s|$)',
        # ì¼ë°˜ ë²•ë¥ 
        r'^([ê°€-í£]+(?:\s+[ê°€-í£]+)*(?:ì—\s*ê´€í•œ\s*)?(?:íŠ¹ë³„|ê¸°ë³¸|ê´€ë¦¬|ì´‰ì§„|ì§€ì›|ìœ¡ì„±|ì§„í¥|ë³´í˜¸|ê·œì œ|ë°©ì§€)?ë²•(?:ë¥ )?)(?:\s|$)',
        # ì‹œí–‰ë ¹/ì‹œí–‰ê·œì¹™
        r'^([ê°€-í£]+(?:\s+[ê°€-í£]+)*ë²•(?:ë¥ )?)\s+ì‹œí–‰ë ¹(?:\s|$)',
        r'^([ê°€-í£]+(?:\s+[ê°€-í£]+)*ë²•(?:ë¥ )?)\s+ì‹œí–‰ê·œì¹™(?:\s|$)',
        # ê³ ì‹œ/í›ˆë ¹ íŒ¨í„´ ì¶”ê°€
        r'([ê°€-í£]+(?:\s+[ê°€-í£]+)*(?:ê³ ì‹œ|í›ˆë ¹|ì˜ˆê·œ|ì§€ì¹¨))(?:\s|$)',
        # ë¶„ë¥˜ íŒ¨í„´ ì¶”ê°€
        r'([ê°€-í£]+(?:\s+)?ë¶„ë¥˜)(?:\s|$)',
    ]


# ===== íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ í´ë˜ìŠ¤ =====
class EnhancedLawFileExtractor:
    """ê°œì„ ëœ ë²•ë ¹ëª… ì¶”ì¶œ í´ë˜ìŠ¤"""
    
    def __init__(self, use_ai: bool = False, api_key: Optional[str] = None):
        self.patterns = LawPatterns()
        self.use_ai = use_ai
        self.api_key = api_key
        self.logger = logging.getLogger(self.__class__.__name__)
        
    def extract_from_file(self, file, file_type: str) -> List[str]:
        """íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ì¶”ì¶œ ë©”ì„œë“œ ë””ìŠ¤íŒ¨ì¹˜"""
        extractors = {
            'pdf': self._extract_from_pdf,
            'xlsx': self._extract_from_excel,
            'xls': self._extract_from_excel,
            'md': self._extract_from_markdown,
            'txt': self._extract_from_text
        }
        
        extractor = extractors.get(file_type.lower())
        if not extractor:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_type}")
            
        return extractor(file)
    
    def _extract_from_pdf(self, file) -> List[str]:
        """PDF íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        try:
            text = self._read_pdf_content(file)
            laws = self._extract_laws_from_text(text)
            
            if self.use_ai and self.api_key:
                laws = self._enhance_with_ai(text, laws)
                
            return sorted(list(laws))
            
        except Exception as e:
            self.logger.error(f"PDF ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            st.error(f"PDF íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return []
    
    def _read_pdf_content(self, file) -> str:
        """PDF ë‚´ìš© ì½ê¸° - pdfplumber ìš°ì„ , ì‹¤íŒ¨ì‹œ PyPDF2"""
        text = ""
        
        # pdfplumber ì‹œë„
        try:
            with pdfplumber.open(file) as pdf:
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
            return text
        except Exception as e:
            self.logger.warning(f"pdfplumber ì‹¤íŒ¨: {e}")
        
        # PyPDF2 í´ë°±
        try:
            file.seek(0)
            pdf_reader = PyPDF2.PdfReader(file)
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
            return text
        except Exception as e:
            self.logger.error(f"PyPDF2ë„ ì‹¤íŒ¨: {e}")
            raise
    
    def _extract_laws_from_text(self, text: str) -> Set[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ - ê°œì„ ëœ ë²„ì „"""
        laws = set()
        
        # í…ìŠ¤íŠ¸ ì •ê·œí™”
        text = self._normalize_text(text)
        
        # ì œì™¸ í‚¤ì›Œë“œë¡œ í…ìŠ¤íŠ¸ ë¶„í•  ì²˜ë¦¬
        # 'ì—¬ì‹ ì „ë¬¸ê¸ˆìœµì—…ë²• ìƒí•˜ìœ„ë²• ì—¬ì‹ ì „ë¬¸ê¸ˆìœµì—…ë²•' -> ë¶„ë¦¬
        for exclude_keyword in self.patterns.EXCLUDE_KEYWORDS:
            text = text.replace(exclude_keyword, '\n')
        
        # íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ë²•ë ¹ëª… ì¶”ì¶œ
        for pattern in self.patterns.LAW_PATTERNS:
            matches = re.findall(pattern, text, re.MULTILINE | re.IGNORECASE)
            for match in matches:
                law_name = self._clean_law_name(match)
                if self._validate_law_name(law_name):
                    laws.add(law_name)
        
        # ë¼ì¸ë³„ ì¶”ê°€ ì²˜ë¦¬
        for line in text.split('\n'):
            line = line.strip()
            
            # ì œì™¸ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¼ì¸ì€ ë¶„í•  ì²˜ë¦¬
            contains_exclude = False
            for exclude_keyword in self.patterns.EXCLUDE_KEYWORDS:
                if exclude_keyword in line:
                    # ì œì™¸ í‚¤ì›Œë“œ ì•ë’¤ë¡œ ë¶„í• 
                    parts = line.split(exclude_keyword)
                    for part in parts:
                        part = part.strip()
                        if part and part not in self.patterns.EXCLUDE_KEYWORDS:
                            # ê° ë¶€ë¶„ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ
                            for law_type in self.patterns.LAW_TYPES:
                                if law_type in part:
                                    law_name = self._extract_law_name_from_line(part, law_type)
                                    if law_name and self._validate_law_name(law_name):
                                        laws.add(law_name)
                    contains_exclude = True
                    break
            
            if contains_exclude:
                continue
                
            # ì ‘ë‘ì–´ ì œê±°
            for prefix_pattern in self.patterns.PREFIX_PATTERNS:
                line = re.sub(prefix_pattern, '', line)
            
            if line in self.patterns.EXCLUDE_KEYWORDS:
                continue
            
            # ë²•ë ¹ íƒ€ì…ë³„ ë§¤ì¹­
            for law_type in self.patterns.LAW_TYPES:
                if law_type in line:
                    law_name = self._extract_law_name_from_line(line, law_type)
                    if law_name and self._validate_law_name(law_name):
                        laws.add(law_name)
        
        # í›„ì²˜ë¦¬
        laws = self._post_process_laws(laws)
        
        return laws
    
    def _normalize_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ê·œí™”"""
        # ì—°ì† ê³µë°± ì œê±°
        text = ' '.join(text.split())
        
        # í‘œì¤€í™”
        replacements = {
            'ì—ê´€í•œ': 'ì— ê´€í•œ',
            'ë°': ' ë° ',
            'Â·': 'Â·',  # ì¤‘ì  í†µì¼
            'ï¼Œ': ',',  # ì‰¼í‘œ í†µì¼
        }
        
        for old, new in replacements.items():
            text = text.replace(old, new)
            
        return text
    
    def _clean_law_name(self, law_name: str) -> str:
        """ë²•ë ¹ëª… ì •ì œ"""
        if not isinstance(law_name, str):
            law_name = str(law_name)
        
        # ì‹œí–‰ ì •ë³´ ì œê±°
        law_name = re.sub(r'\s*\[ì‹œí–‰[^\]]+\]', '', law_name)
        
        # ì ‘ë‘ì–´ ì œê±°
        for prefix_pattern in self.patterns.PREFIX_PATTERNS:
            law_name = re.sub(prefix_pattern, '', law_name)
        
        # ì•ë’¤ ê³µë°± ì œê±°
        law_name = law_name.strip()
        
        # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        law_name = ' '.join(law_name.split())
        
        # ë¶™ì–´ìˆëŠ” í˜•íƒœ ì •ê·œí™”
        law_name = re.sub(r'ê²€ì‚¬ë°', 'ê²€ì‚¬ ë° ', law_name)
        law_name = re.sub(r'ì—ê´€í•œ', 'ì— ê´€í•œ ', law_name)
        
        return law_name
    
    def _extract_law_name_from_line(self, line: str, law_type: str) -> Optional[str]:
        """ë¼ì¸ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        # ë²•ë ¹ íƒ€ì… ìœ„ì¹˜ ì°¾ê¸°
        type_pos = line.find(law_type)
        if type_pos == -1:
            return None
            
        # ì‹œì‘ ìœ„ì¹˜ ì°¾ê¸° (í•œê¸€ë¡œ ì‹œì‘)
        start = 0
        for i in range(type_pos - 1, -1, -1):
            if not (line[i].isalnum() or line[i] in ' Â·ë°ê´€í•œì˜ì—'):
                start = i + 1
                break
        
        # ë ìœ„ì¹˜ëŠ” ë²•ë ¹ íƒ€ì… ë’¤
        end = type_pos + len(law_type)
        
        # ì‹œí–‰ë ¹/ì‹œí–‰ê·œì¹™ ì²˜ë¦¬
        if end < len(line) - 3:
            next_chars = line[end:end+4]
            if 'ì‹œí–‰ë ¹' in next_chars or 'ì‹œí–‰ê·œì¹™' in next_chars:
                space_pos = line.find(' ', end)
                if space_pos != -1:
                    end = space_pos
                else:
                    end = len(line)
        
        return line[start:end].strip()
    
    def _validate_law_name(self, law_name: str) -> bool:
        """ë²•ë ¹ëª… ìœ íš¨ì„± ê²€ì¦"""
        # ê¸¸ì´ ì²´í¬
        if len(law_name) < 3 or len(law_name) > 100:
            return False
            
        # ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
        if law_name in self.patterns.EXCLUDE_KEYWORDS:
            return False
            
        # í•œê¸€ í¬í•¨ ì²´í¬
        if not re.search(r'[ê°€-í£]', law_name):
            return False
            
        # ë²•ë ¹ íƒ€ì… í¬í•¨ ì²´í¬
        if not any(law_type in law_name for law_type in self.patterns.LAW_TYPES):
            return False
            
        # ì ‘ë‘ì–´ê°€ ë‚¨ì•„ìˆëŠ” ê²½ìš° ì œê±°
        if any(pattern in law_name for pattern in ['í–‰ì •ê·œì¹™', 'ë²•ë ¹']):
            return False
            
        return True
    
    def _post_process_laws(self, laws: Set[str]) -> Set[str]:
        """ë²•ë ¹ëª… í›„ì²˜ë¦¬ - ì¤‘ë³µ ì œê±°, ì •ê·œí™”"""
        processed = set()
        
        # ì •ë ¬í•˜ì—¬ ê¸´ ê²ƒë¶€í„° ì²˜ë¦¬
        sorted_laws = sorted(laws, key=len, reverse=True)
        
        for law in sorted_laws:
            # ë¶€ë¶„ ë¬¸ìì—´ ì²´í¬
            is_substring = False
            for existing in processed:
                if law in existing and law != existing:
                    is_substring = True
                    break
                    
            if not is_substring:
                # ìµœì¢… ì •ê·œí™”
                law = law.strip()
                law = ' '.join(law.split())  # ì—°ì† ê³µë°± ì œê±°
                
                # ì ‘ë‘ì–´ ìµœì¢… ì œê±°
                for prefix_pattern in self.patterns.PREFIX_PATTERNS:
                    law = re.sub(prefix_pattern, '', law)
                
                processed.add(law)
                
        return processed
    
    def _enhance_with_ai(self, text: str, laws: Set[str]) -> Set[str]:
        """AIë¥¼ í™œìš©í•œ ë²•ë ¹ëª… ì¶”ì¶œ ê°œì„  - ìˆ˜ì •ëœ ë²„ì „"""
        try:
            # OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì²´í¬
            try:
                from openai import OpenAI
            except ImportError:
                self.logger.warning("OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return laws
            
            # API í‚¤ ìœ íš¨ì„± ê²€ì¦ ê°œì„ 
            if not self.api_key:
                self.logger.warning("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return laws
            
            # API í‚¤ ì •ë¦¬ (ê³µë°± ì œê±°, íŠ¹ìˆ˜ë¬¸ì í™•ì¸)
            cleaned_key = self.api_key.strip()
            
            # API í‚¤ í˜•ì‹ ê²€ì¦
            if not (cleaned_key.startswith('sk-') or cleaned_key.startswith('sess-')):
                self.logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ API í‚¤ í˜•ì‹")
                return laws
            
            self.logger.info(f"OpenAI API í‚¤ ì‚¬ìš© ì¤‘: {cleaned_key[:10]}...")
            
            # OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± (í‚¤ ì¬ì„¤ì •)
            client = OpenAI(
                api_key=cleaned_key,
                max_retries=2,
                timeout=30.0
            )
            
            # API í‚¤ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ í˜¸ì¶œ
            try:
                # í…ìŠ¤íŠ¸ ìƒ˜í”Œë§ (í† í° ì œí•œ)
                sample = text[:3000]
                
                # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                prompt = self._create_ai_prompt(sample, laws)
                
                # API í˜¸ì¶œ - ì•ˆì „í•œ ë°©ì‹ìœ¼ë¡œ
                try:
                    response = client.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=[
                            {"role": "system", "content": "í•œêµ­ ë²•ë ¹ ë°ì´í„°ë² ì´ìŠ¤ ì „ë¬¸ê°€"},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.1,
                        max_tokens=1000
                    )
                    
                    # ì‘ë‹µ íŒŒì‹±
                    ai_laws = self._parse_ai_response(response.choices[0].message.content)
                    
                    self.logger.info(f"AIê°€ ì¶”ê°€ë¡œ {len(ai_laws - laws)}ê°œì˜ ë²•ë ¹ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                    
                    # ê²°ê³¼ ë³‘í•©
                    return laws.union(ai_laws)
                    
                except Exception as chat_error:
                    # GPT-3.5ê°€ ì‹¤íŒ¨í•˜ë©´ GPT-4 ì‹œë„
                    try:
                        response = client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "í•œêµ­ ë²•ë ¹ ë°ì´í„°ë² ì´ìŠ¤ ì „ë¬¸ê°€"},
                                {"role": "user", "content": prompt}
                            ],
                            temperature=0.1,
                            max_tokens=1000
                        )
                        
                        ai_laws = self._parse_ai_response(response.choices[0].message.content)
                        self.logger.info(f"GPT-4ë¡œ {len(ai_laws - laws)}ê°œì˜ ë²•ë ¹ì„ ì¶”ê°€ë¡œ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                        return laws.union(ai_laws)
                        
                    except:
                        self.logger.warning("AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì¶”ì¶œë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
                        return laws
                
            except Exception as api_error:
                error_msg = str(api_error)
                if "401" in error_msg or "Incorrect API key" in error_msg:
                    self.logger.error("API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í‚¤ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    st.error("âš ï¸ OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ í‚¤ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
                elif "insufficient_quota" in error_msg:
                    self.logger.warning("API ì‚¬ìš©ëŸ‰ í•œë„ ì´ˆê³¼")
                    st.warning("âš ï¸ OpenAI API ì‚¬ìš©ëŸ‰ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")
                else:
                    self.logger.error(f"OpenAI API í˜¸ì¶œ ì˜¤ë¥˜: {error_msg}")
                return laws
            
        except Exception as e:
            self.logger.error(f"AI ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return laws
    
    def _create_ai_prompt(self, text: str, existing_laws: Set[str]) -> str:
        """AI í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ í•œêµ­ ë²•ë ¹ëª…ì„ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”.

ê·œì¹™:
1. ë²•ì œì²˜ ê³µì‹ ëª…ì¹­ ì‚¬ìš©
2. "ìƒí•˜ìœ„ë²•", "ê´€ë ¨ë²•ë ¹", "í–‰ì •ê·œì¹™", "ë²•ë ¹" ê°™ì€ ì¹´í…Œê³ ë¦¬ë‚˜ ì ‘ë‘ì–´ ì œì™¸
3. ë‚ ì§œ(ì˜ˆ: 20250422) ì œì™¸
4. ì‹œí–‰ë ¹/ì‹œí–‰ê·œì¹™ì€ ê¸°ë³¸ë²•ê³¼ í•¨ê»˜ í‘œê¸°
5. í•œ ì¤„ì— í•˜ë‚˜ì”© ì¶œë ¥

í…ìŠ¤íŠ¸:
{text}

í˜„ì¬ ì¶”ì¶œëœ ë²•ë ¹ (ì°¸ê³ ):
{', '.join(list(existing_laws)[:10])}

ë²•ë ¹ëª…ë§Œ ì¶œë ¥:"""
    
    def _parse_ai_response(self, response: str) -> Set[str]:
        """AI ì‘ë‹µ íŒŒì‹±"""
        laws = set()
        
        for line in response.strip().split('\n'):
            line = line.strip()
            
            # ë²ˆí˜¸, ê¸°í˜¸ ì œê±°
            line = re.sub(r'^[\d\-\.\*\â€¢\Â·]+\s*', '', line)
            line = line.strip('"\'')
            
            # ì ‘ë‘ì–´ ì œê±°
            for prefix_pattern in self.patterns.PREFIX_PATTERNS:
                line = re.sub(prefix_pattern, '', line)
            
            if line and self._validate_law_name(line):
                laws.add(line)
                
        return laws
    
    def _extract_from_excel(self, file) -> List[str]:
        """Excel íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        laws = set()
        
        try:
            excel_file = pd.ExcelFile(file)
            
            for sheet_name in excel_file.sheet_names:
                df = pd.read_excel(file, sheet_name=sheet_name)
                
                # ëª¨ë“  ì…€ì˜ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
                text = self._collect_excel_text(df)
                
                # ë²•ë ¹ëª… ì¶”ì¶œ
                sheet_laws = self._extract_laws_from_text(text)
                laws.update(sheet_laws)
                
        except Exception as e:
            self.logger.error(f"Excel ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            st.error(f"Excel íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            
        return sorted(list(laws))
    
    def _collect_excel_text(self, df: pd.DataFrame) -> str:
        """DataFrameì—ì„œ í…ìŠ¤íŠ¸ ìˆ˜ì§‘"""
        texts = []
        
        for column in df.columns:
            for value in df[column].dropna():
                if isinstance(value, str):
                    texts.append(value)
                    
        return '\n'.join(texts)
    
    def _extract_from_markdown(self, file) -> List[str]:
        """Markdown íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        try:
            content = file.read().decode('utf-8')
            laws = self._extract_laws_from_text(content)
            return sorted(list(laws))
        except Exception as e:
            self.logger.error(f"Markdown ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []
    
    def _extract_from_text(self, file) -> List[str]:
        """í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        try:
            content = file.read().decode('utf-8')
            laws = self._extract_laws_from_text(content)
            return sorted(list(laws))
        except Exception as e:
            self.logger.error(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []


# ===== ë²•ë ¹ ìˆ˜ì§‘ API í´ë˜ìŠ¤ =====
class LawCollectorAPI:
    """ê°œì„ ëœ ë²•ë ¹ ìˆ˜ì§‘ API í´ë˜ìŠ¤ - í–‰ì •ê·œì¹™ ì™„ë²½ ì§€ì›"""
    
    def __init__(self, oc_code: str):
        self.oc_code = oc_code
        self.config = APIConfig()
        self.logger = logging.getLogger(self.__class__.__name__)
        self.session = self._create_session()
        self._cache = {}  # ê²€ìƒ‰ ê²°ê³¼ ìºì‹œ
        self._pdf_cache = {}  # PDF URL ìºì‹œ ì¶”ê°€
        
    @lru_cache(maxsize=128)
    def _get_cached_search_result(self, law_name: str) -> Optional[str]:
        """ìºì‹œëœ ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜"""
        return None  # ì‹¤ì œ êµ¬í˜„ì‹œ ìºì‹œ ë¡œì§ ì¶”ê°€
        
    def _create_session(self) -> requests.Session:
        """ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ì…˜ ìƒì„±"""
        session = requests.Session()
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # SSL ì¸ì¦ì„œ ê²€ì¦ í™œì„±í™” (ë³´ì•ˆ ê°•í™”)
        session.verify = True
        
        # ì¬ì‹œë„ ì„¤ì •
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        
        retry_strategy = Retry(
            total=self.config.MAX_RETRIES,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504]
        )
        
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        return session
    
    def search_laws(self, law_names: List[str], 
                   progress_callback=None) -> List[Dict[str, Any]]:
        """ì—¬ëŸ¬ ë²•ë ¹ì„ ë³‘ë ¬ë¡œ ê²€ìƒ‰ - ì¤‘ë³µ ì œê±° ì¶”ê°€"""
        results = []
        no_result_laws = []
        seen_law_ids = set()  # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ set
        
        with ThreadPoolExecutor(max_workers=self.config.MAX_CONCURRENT) as executor:
            # ê²€ìƒ‰ ì‘ì—… ì œì¶œ
            future_to_law = {
                executor.submit(self._search_with_variations, law_name): law_name
                for law_name in law_names
            }
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for idx, future in enumerate(as_completed(future_to_law)):
                law_name = future_to_law[future]
                
                try:
                    result = future.result()
                    if result:
                        # ì¤‘ë³µ ì œê±°
                        for law in result:
                            if law['law_id'] not in seen_law_ids:
                                seen_law_ids.add(law['law_id'])
                                results.append(law)
                    else:
                        no_result_laws.append(law_name)
                    
                    if progress_callback:
                        progress_callback((idx + 1) / len(law_names))
                        
                except Exception as e:
                    self.logger.error(f"{law_name} ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                    no_result_laws.append(law_name)
        
        # ê²€ìƒ‰ ì‹¤íŒ¨í•œ ë²•ë ¹ í‘œì‹œ
        if no_result_laws:
            with st.expander(f"âŒ ê²€ìƒ‰ë˜ì§€ ì•Šì€ ë²•ë ¹ ({len(no_result_laws)}ê°œ)"):
                for law in no_result_laws:
                    st.write(f"- {law}")
                st.info("ğŸ’¡ Tip: ê¸°ê´€ì½”ë“œë¥¼ í™•ì¸í•˜ê±°ë‚˜, ë²•ë ¹ëª…ì„ ìˆ˜ì •í•´ë³´ì„¸ìš”.")
                    
        return results
    
    def _search_with_variations(self, law_name: str) -> List[Dict[str, Any]]:
        """ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ë²•ë ¹ ê²€ìƒ‰"""
        variations = self._generate_search_variations(law_name)
        
        for variation in variations:
            results = self.search_single_law(variation)
            if results:
                # ì›ë˜ ê²€ìƒ‰ì–´ ì €ì¥
                for result in results:
                    result['search_query'] = law_name
                return results
        
        return []
    
    def _generate_search_variations(self, law_name: str) -> List[str]:
        """ë²•ë ¹ëª…ì˜ ë‹¤ì–‘í•œ ë³€í˜• ìƒì„±"""
        variations = [law_name]
        
        # ë„ì–´ì“°ê¸° ì¶”ê°€/ì œê±°
        spaced = law_name.replace('ë°', ' ë° ').replace('ì—ê´€í•œ', 'ì— ê´€í•œ')
        if spaced != law_name:
            variations.append(spaced)
        
        no_space = law_name.replace(' ', '')
        if no_space != law_name:
            variations.append(no_space)
        
        # ì‹œí–‰ë ¹/ì‹œí–‰ê·œì¹™ ë¶„ë¦¬
        if ' ì‹œí–‰ë ¹' in law_name:
            base = law_name.replace(' ì‹œí–‰ë ¹', '')
            variations.extend([base, f"{base}ì‹œí–‰ë ¹"])
        
        if ' ì‹œí–‰ê·œì¹™' in law_name:
            base = law_name.replace(' ì‹œí–‰ê·œì¹™', '')
            variations.extend([base, f"{base}ì‹œí–‰ê·œì¹™"])
        
        return variations[:3]  # ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ
    
    def search_single_law(self, law_name: str) -> List[Dict[str, Any]]:
        """ë‹¨ì¼ ë²•ë ¹ ê²€ìƒ‰ - ì¼ë°˜ ë²•ë ¹ê³¼ í–‰ì •ê·œì¹™ ëª¨ë‘"""
        results = []
        
        # 1. ì¼ë°˜ ë²•ë ¹ ê²€ìƒ‰ (target=law)
        general_laws = self._search_general_law(law_name)
        results.extend(general_laws)
        
        # 2. í–‰ì •ê·œì¹™ ê²€ìƒ‰ (ë³„ë„ API)
        admin_rules = self._search_admin_rule(law_name)
        results.extend(admin_rules)
        
        # ì¤‘ë³µ ì œê±°
        unique_results = self._remove_duplicates(results)
        
        # ê²€ìƒ‰ ê²°ê³¼ ë¡œê·¸
        if unique_results:
            general_count = sum(1 for r in unique_results if not r.get('is_admin_rule'))
            admin_count = sum(1 for r in unique_results if r.get('is_admin_rule'))
            self.logger.info(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {law_name} - ì¼ë°˜ë²•ë ¹ {general_count}ê°œ, í–‰ì •ê·œì¹™ {admin_count}ê°œ")
        
        return unique_results
    
    def _search_general_law(self, law_name: str) -> List[Dict[str, Any]]:
        """ì¼ë°˜ ë²•ë ¹ ê²€ìƒ‰"""
        params = {
            'OC': self.oc_code,
            'target': 'law',
            'type': 'XML',
            'query': law_name,
            'display': str(self.config.RESULTS_PER_PAGE),
            'page': '1'
        }
        
        try:
            self.logger.debug(f"ì¼ë°˜ ë²•ë ¹ ê²€ìƒ‰: {law_name}")
            
            response = self.session.get(
                self.config.LAW_SEARCH_URL,
                params=params,
                timeout=self.config.TIMEOUT
            )
            
            if response.status_code != 200:
                self.logger.warning(f"ì¼ë°˜ ë²•ë ¹ ê²€ìƒ‰ ì‹¤íŒ¨: {law_name} - ìƒíƒœì½”ë“œ: {response.status_code}")
                return []
                
            # XML íŒŒì‹±
            laws = self._parse_law_search_response(response.text, law_name)
            
            if laws:
                self.logger.info(f"ì¼ë°˜ ë²•ë ¹ {len(laws)}ê°œ ë°œê²¬: {law_name}")
            
            return laws
            
        except Exception as e:
            self.logger.error(f"ì¼ë°˜ ë²•ë ¹ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def _search_admin_rule(self, law_name: str) -> List[Dict[str, Any]]:
        """í–‰ì •ê·œì¹™ ê²€ìƒ‰ - ì™„ì „ ì¬ì‘ì„±"""
        params = {
            'OC': self.oc_code,
            'target': 'admrul',
            'type': 'XML',
            'query': law_name,
            'display': '100',
            'page': '1'
        }
        
        try:
            self.logger.info(f"í–‰ì •ê·œì¹™ ê²€ìƒ‰ ì‹œì‘: {law_name}")
            self.logger.debug(f"API URL: {self.config.ADMIN_RULE_SEARCH_URL}")
            self.logger.debug(f"íŒŒë¼ë¯¸í„°: {params}")
            
            # í–‰ì •ê·œì¹™ ì „ìš© API ì‚¬ìš©
            response = self.session.get(
                self.config.ADMIN_RULE_SEARCH_URL,  # admRulSc.do
                params=params,
                timeout=self.config.TIMEOUT
            )
            
            self.logger.debug(f"ì‘ë‹µ ìƒíƒœì½”ë“œ: {response.status_code}")
            
            if response.status_code == 200:
                # í–‰ì •ê·œì¹™ ì „ìš© íŒŒì‹±
                rules = self._parse_admin_rule_search_response(response.text, law_name)
                
                if rules:
                    self.logger.info(f"âœ… í–‰ì •ê·œì¹™ {len(rules)}ê°œ ë°œê²¬: {law_name}")
                else:
                    self.logger.info(f"í–‰ì •ê·œì¹™ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ: {law_name}")
                
                return rules
            else:
                self.logger.warning(f"í–‰ì •ê·œì¹™ ê²€ìƒ‰ ì‹¤íŒ¨: {law_name} - ìƒíƒœì½”ë“œ: {response.status_code}")
                return []
                
        except Exception as e:
            self.logger.error(f"í–‰ì •ê·œì¹™ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def _parse_law_search_response(self, content: str, 
                                  search_query: str) -> List[Dict[str, Any]]:
        """ì¼ë°˜ ë²•ë ¹ ê²€ìƒ‰ ì‘ë‹µ íŒŒì‹±"""
        laws = []
        
        try:
            # ì „ì²˜ë¦¬
            content = self._preprocess_xml_content(content)
            
            # XML íŒŒì‹±
            root = ET.fromstring(content.encode('utf-8'))
            
            for law_elem in root.findall('.//law'):
                law_info = {
                    'law_id': law_elem.findtext('ë²•ë ¹ID', ''),
                    'law_msn': law_elem.findtext('ë²•ë ¹ì¼ë ¨ë²ˆí˜¸', ''),
                    'law_name': law_elem.findtext('ë²•ë ¹ëª…í•œê¸€', ''),
                    'law_type': law_elem.findtext('ë²•ì¢…êµ¬ë¶„', ''),
                    'promulgation_date': law_elem.findtext('ê³µí¬ì¼ì', ''),
                    'enforcement_date': law_elem.findtext('ì‹œí–‰ì¼ì', ''),
                    'is_admin_rule': False,
                    'search_query': search_query
                }
                
                if law_info['law_id'] and law_info['law_name']:
                    laws.append(law_info)
                    
        except ET.ParseError as e:
            self.logger.error(f"ì¼ë°˜ ë²•ë ¹ XML íŒŒì‹± ì˜¤ë¥˜: {e}")
            
        return laws
    
    def _parse_admin_rule_search_response(self, content: str, 
                                         search_query: str) -> List[Dict[str, Any]]:
        """í–‰ì •ê·œì¹™ ê²€ìƒ‰ ì‘ë‹µ íŒŒì‹± - ì „ìš© íŒŒì„œ"""
        rules = []
        
        try:
            # ì „ì²˜ë¦¬
            content = self._preprocess_xml_content(content)
            
            # XML íŒŒì‹±
            root = ET.fromstring(content.encode('utf-8'))
            
            self.logger.debug(f"í–‰ì •ê·œì¹™ XML ë£¨íŠ¸ íƒœê·¸: {root.tag}")
            self.logger.debug(f"í•˜ìœ„ ìš”ì†Œ: {[child.tag for child in root][:5]}")
            
            # í–‰ì •ê·œì¹™ì€ admrul íƒœê·¸ ì‚¬ìš©
            for rule_elem in root.findall('.//admrul'):
                rule_info = {
                    'law_id': rule_elem.findtext('í–‰ì •ê·œì¹™ID', ''),
                    'law_msn': rule_elem.findtext('í–‰ì •ê·œì¹™ì¼ë ¨ë²ˆí˜¸', ''),
                    'law_name': rule_elem.findtext('í–‰ì •ê·œì¹™ëª…', ''),
                    'law_type': rule_elem.findtext('í–‰ì •ê·œì¹™ì¢…ë¥˜', ''),
                    'promulgation_date': rule_elem.findtext('ë°œë ¹ì¼ì', ''),
                    'enforcement_date': rule_elem.findtext('ì‹œí–‰ì¼ì', ''),
                    'is_admin_rule': True,
                    'search_query': search_query
                }
                
                if rule_info['law_id'] and rule_info['law_name']:
                    rules.append(rule_info)
                    self.logger.debug(f"í–‰ì •ê·œì¹™ ë°œê²¬: {rule_info['law_name']}")
                    
        except ET.ParseError as e:
            self.logger.error(f"í–‰ì •ê·œì¹™ XML íŒŒì‹± ì˜¤ë¥˜: {e}")
            self.logger.debug(f"íŒŒì‹± ì‹¤íŒ¨í•œ ë‚´ìš© ì¼ë¶€: {content[:500]}")
            
        return rules
    
    def _preprocess_xml_content(self, content: str) -> str:
        """XML ë‚´ìš© ì „ì²˜ë¦¬"""
        # BOM ì œê±°
        if content.startswith('\ufeff'):
            content = content[1:]
        
        # XML í—¤ë” í™•ì¸
        if not content.strip().startswith('<?xml'):
            content = '<?xml version="1.0" encoding="UTF-8"?>\n' + content
        
        # íŠ¹ìˆ˜ë¬¸ì ì œê±°
        content = re.sub(r'[\x00-\x08\x0B-\x0C\x0E-\x1F\x7F]', '', content)
        
        return content
    
    def collect_law_details(self, laws: List[Dict[str, Any]], 
                           progress_callback=None) -> Dict[str, Dict[str, Any]]:
        """ë²•ë ¹ ìƒì„¸ ì •ë³´ ë³‘ë ¬ ìˆ˜ì§‘"""
        collected = {}
        
        with ThreadPoolExecutor(max_workers=self.config.MAX_CONCURRENT) as executor:
            # ìˆ˜ì§‘ ì‘ì—… ì œì¶œ
            future_to_law = {
                executor.submit(
                    self._get_law_detail,
                    law['law_id'],
                    law['law_msn'],
                    law['law_name'],
                    law.get('is_admin_rule', False)
                ): law
                for law in laws
            }
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for idx, future in enumerate(as_completed(future_to_law)):
                law = future_to_law[future]
                
                try:
                    detail = future.result()
                    if detail:
                        collected[law['law_id']] = detail
                        
                    if progress_callback:
                        progress_callback((idx + 1) / len(laws))
                        
                except Exception as e:
                    self.logger.error(f"{law['law_name']} ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
                    
        return collected
    
    def _get_law_detail(self, law_id: str, law_msn: str, 
                       law_name: str, is_admin_rule: bool) -> Optional[Dict[str, Any]]:
        """ë²•ë ¹ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        if is_admin_rule:
            return self._get_admin_rule_detail(law_msn, law_name)
        else:
            return self._get_general_law_detail(law_id, law_msn, law_name)
    
    def _get_general_law_detail(self, law_id: str, law_msn: str, 
                               law_name: str) -> Optional[Dict[str, Any]]:
        """ì¼ë°˜ ë²•ë ¹ ìƒì„¸ ì •ë³´"""
        params = {
            'OC': self.oc_code,
            'target': 'law',
            'type': 'XML',
            'MST': law_msn
        }
        
        try:
            response = self.session.get(
                self.config.LAW_DETAIL_URL,
                params=params,
                timeout=self.config.TIMEOUT
            )
            
            if response.status_code != 200:
                return None
                
            # ìƒì„¸ ì •ë³´ íŒŒì‹±
            return self._parse_law_detail(response.text, law_id, law_msn, law_name)
            
        except Exception as e:
            self.logger.error(f"ë²•ë ¹ ìƒì„¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None
    
    def _get_admin_rule_detail(self, law_msn: str, law_name: str) -> Optional[Dict[str, Any]]:
        """í–‰ì •ê·œì¹™ ìƒì„¸ ì •ë³´ - ID íŒŒë¼ë¯¸í„° ì‚¬ìš©"""
        params = {
            'OC': self.oc_code,
            'target': 'admrul',
            'type': 'XML',
            'ID': law_msn  # MSTê°€ ì•„ë‹Œ ID ì‚¬ìš©!
        }
        
        try:
            self.logger.debug(f"í–‰ì •ê·œì¹™ ìƒì„¸ ì¡°íšŒ: {law_name}")
            self.logger.debug(f"íŒŒë¼ë¯¸í„°: {params}")
            
            response = self.session.get(
                self.config.ADMIN_RULE_DETAIL_URL,
                params=params,
                timeout=self.config.TIMEOUT
            )
            
            if response.status_code != 200:
                self.logger.warning(f"í–‰ì •ê·œì¹™ ìƒì„¸ ì¡°íšŒ ì‹¤íŒ¨: {response.status_code}")
                return None
                
            # í–‰ì •ê·œì¹™ ìƒì„¸ íŒŒì‹±
            return self._parse_admin_rule_detail(response.text, law_msn, law_name)
            
        except Exception as e:
            self.logger.error(f"í–‰ì •ê·œì¹™ ìƒì„¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None
    
    def _parse_law_detail(self, content: str, law_id: str, 
                         law_msn: str, law_name: str) -> Dict[str, Any]:
        """ì¼ë°˜ ë²•ë ¹ ìƒì„¸ ì •ë³´ íŒŒì‹± - ê°œì„ ëœ PDF ì¶”ì¶œ"""
        detail = {
            'law_id': law_id,
            'law_msn': law_msn,
            'law_name': law_name,
            'law_type': '',
            'promulgation_date': '',
            'enforcement_date': '',
            'department': '',
            'articles': [],
            'supplementary_provisions': [],
            'attachments': [],
            'attachment_pdfs': [],  # PDF ì²¨ë¶€íŒŒì¼ ì¶”ê°€
            'raw_content': '',
            'is_admin_rule': False
        }
        
        try:
            # ì „ì²˜ë¦¬
            content = self._preprocess_xml_content(content)
            
            # XML íŒŒì‹±
            root = ET.fromstring(content.encode('utf-8'))
            
            # ê¸°ë³¸ ì •ë³´
            basic_info = root.find('.//ê¸°ë³¸ì •ë³´')
            if basic_info is not None:
                detail['law_type'] = basic_info.findtext('ë²•ì¢…êµ¬ë¶„ëª…', '')
                detail['department'] = basic_info.findtext('ì†Œê´€ë¶€ì²˜ëª…', '')
                detail['promulgation_date'] = basic_info.findtext('ê³µí¬ì¼ì', '')
                detail['enforcement_date'] = basic_info.findtext('ì‹œí–‰ì¼ì', '')
            
            # ì¡°ë¬¸ ì¶”ì¶œ
            self._extract_articles(root, detail)
            
            # ë¶€ì¹™ ì¶”ì¶œ
            self._extract_supplementary_provisions(root, detail)
            
            # ë³„í‘œ ì¶”ì¶œ
            self._extract_attachments(root, detail)
            
            # PDF ì²¨ë¶€íŒŒì¼ ì¶”ì¶œ - ê°œì„ ëœ ë²„ì „
            self._extract_pdf_attachments_enhanced(root, detail)
            
            # ì›ë¬¸ ì €ì¥ (ì¡°ë¬¸ì´ ì—†ëŠ” ê²½ìš°)
            if not detail['articles']:
                detail['raw_content'] = self._extract_full_text(root)
                
            self.logger.info(f"ìƒì„¸ ì •ë³´ íŒŒì‹± ì™„ë£Œ: {law_name} - ì¡°ë¬¸ {len(detail['articles'])}ê°œ, PDF {len(detail['attachment_pdfs'])}ê°œ")
                
        except Exception as e:
            self.logger.error(f"ìƒì„¸ ì •ë³´ íŒŒì‹± ì˜¤ë¥˜: {e}")
            
        return detail
    
    def _parse_admin_rule_detail(self, content: str, law_msn: str, 
                                law_name: str) -> Dict[str, Any]:
        """í–‰ì •ê·œì¹™ ìƒì„¸ ì •ë³´ íŒŒì‹±"""
        detail = {
            'law_id': '',
            'law_msn': law_msn,
            'law_name': law_name,
            'law_type': '',
            'promulgation_date': '',
            'enforcement_date': '',
            'department': '',
            'articles': [],
            'supplementary_provisions': [],
            'attachments': [],
            'attachment_pdfs': [],  # PDF ì²¨ë¶€íŒŒì¼ ì¶”ê°€
            'raw_content': '',
            'is_admin_rule': True
        }
        
        try:
            # ì „ì²˜ë¦¬
            content = self._preprocess_xml_content(content)
            
            # XML íŒŒì‹±
            root = ET.fromstring(content.encode('utf-8'))
            
            # í–‰ì •ê·œì¹™ ê¸°ë³¸ ì •ë³´
            basic_info = root.find('.//í–‰ì •ê·œì¹™ê¸°ë³¸ì •ë³´')
            if basic_info is not None:
                detail['law_id'] = basic_info.findtext('í–‰ì •ê·œì¹™ID', '')
                detail['law_type'] = basic_info.findtext('í–‰ì •ê·œì¹™ì¢…ë¥˜', '')
                detail['department'] = basic_info.findtext('ì†Œê´€ë¶€ì²˜ëª…', '')
                detail['promulgation_date'] = basic_info.findtext('ë°œë ¹ì¼ì', '')
                detail['enforcement_date'] = basic_info.findtext('ì‹œí–‰ì¼ì', '')
            else:
                # ëŒ€ì²´ ê²½ë¡œ
                detail['law_id'] = root.findtext('.//í–‰ì •ê·œì¹™ID', '')
                detail['law_type'] = root.findtext('.//í–‰ì •ê·œì¹™ì¢…ë¥˜', '')
                detail['department'] = root.findtext('.//ì†Œê´€ë¶€ì²˜ëª…', '')
                detail['promulgation_date'] = root.findtext('.//ë°œë ¹ì¼ì', '')
                detail['enforcement_date'] = root.findtext('.//ì‹œí–‰ì¼ì', '')
            
            # ì¡°ë¬¸ ì¶”ì¶œ (í–‰ì •ê·œì¹™ë„ ë™ì¼í•œ êµ¬ì¡° ì‚¬ìš© ê°€ëŠ¥)
            self._extract_articles(root, detail)
            
            # ë¶€ì¹™ ì¶”ì¶œ
            self._extract_supplementary_provisions(root, detail)
            
            # ë³„í‘œ ì¶”ì¶œ
            self._extract_attachments(root, detail)
            
            # PDF ì²¨ë¶€íŒŒì¼ ì¶”ì¶œ - ê°œì„ ëœ ë²„ì „
            self._extract_pdf_attachments_enhanced(root, detail)
            
            # ì›ë¬¸ ì €ì¥
            if not detail['articles']:
                detail['raw_content'] = self._extract_full_text(root)
                
            self.logger.info(f"í–‰ì •ê·œì¹™ ìƒì„¸ íŒŒì‹± ì™„ë£Œ: {law_name} - ì¡°ë¬¸ {len(detail['articles'])}ê°œ, PDF {len(detail['attachment_pdfs'])}ê°œ")
                
        except Exception as e:
            self.logger.error(f"í–‰ì •ê·œì¹™ ìƒì„¸ íŒŒì‹± ì˜¤ë¥˜: {e}")
            
        return detail
    
    def _extract_articles(self, root: ET.Element, detail: Dict[str, Any]) -> None:
        """ì¡°ë¬¸ ì¶”ì¶œ"""
        # í‘œì¤€ ì¡°ë¬¸ êµ¬ì¡°
        articles_section = root.find('.//ì¡°ë¬¸')
        if articles_section is not None:
            for article_unit in articles_section.findall('.//ì¡°ë¬¸ë‹¨ìœ„'):
                article = self._parse_article_unit(article_unit)
                if article:
                    detail['articles'].append(article)
            return
        
        # ì¡°ë¬¸ë‚´ìš© ì§ì ‘ ì°¾ê¸°
        for article_content in root.findall('.//ì¡°ë¬¸ë‚´ìš©'):
            if article_content.text:
                articles = self._parse_article_text(article_content.text)
                detail['articles'].extend(articles)
    
    def _parse_article_unit(self, article_elem: ET.Element) -> Optional[Dict[str, Any]]:
        """ì¡°ë¬¸ë‹¨ìœ„ íŒŒì‹±"""
        article = {
            'number': '',
            'title': '',
            'content': '',
            'paragraphs': []
        }
        
        # ì¡°ë¬¸ë²ˆí˜¸
        article_num = article_elem.findtext('ì¡°ë¬¸ë²ˆí˜¸', '')
        if article_num:
            article['number'] = f"ì œ{article_num}ì¡°"
        
        # ì¡°ë¬¸ì œëª©
        article['title'] = article_elem.findtext('ì¡°ë¬¸ì œëª©', '')
        
        # ì¡°ë¬¸ë‚´ìš©
        article['content'] = article_elem.findtext('ì¡°ë¬¸ë‚´ìš©', '')
        
        # í•­ ì¶”ì¶œ
        for para in article_elem.findall('.//í•­'):
            paragraph = {
                'number': para.findtext('í•­ë²ˆí˜¸', ''),
                'content': para.findtext('í•­ë‚´ìš©', '')
            }
            if paragraph['content']:
                article['paragraphs'].append(paragraph)
        
        return article if (article['number'] or article['content']) else None
    
    def _parse_article_text(self, text: str) -> List[Dict[str, Any]]:
        """ì¡°ë¬¸ í…ìŠ¤íŠ¸ íŒŒì‹±"""
        articles = []
        
        # ì¡°ë¬¸ íŒ¨í„´
        pattern = r'(ì œ\d+ì¡°(?:ì˜\d+)?)\s*(?:\((.*?)\))?\s*(.*?)(?=ì œ\d+ì¡°|$)'
        matches = re.findall(pattern, text, re.DOTALL)
        
        for match in matches:
            article = {
                'number': match[0],
                'title': match[1],
                'content': match[2].strip(),
                'paragraphs': []
            }
            articles.append(article)
            
        return articles
    
    def _extract_supplementary_provisions(self, root: ET.Element, 
                                        detail: Dict[str, Any]) -> None:
        """ë¶€ì¹™ ì¶”ì¶œ"""
        for addendum in root.findall('.//ë¶€ì¹™'):
            provision = {
                'number': addendum.findtext('ë¶€ì¹™ë²ˆí˜¸', ''),
                'promulgation_date': addendum.findtext('ë¶€ì¹™ê³µí¬ì¼ì', ''),
                'content': self._get_all_text(addendum)
            }
            if provision['content']:
                detail['supplementary_provisions'].append(provision)
        
        # ë¶€ì¹™ë‚´ìš© ì§ì ‘ ì°¾ê¸°
        if not detail['supplementary_provisions']:
            for elem in root.findall('.//ë¶€ì¹™ë‚´ìš©'):
                if elem.text:
                    detail['supplementary_provisions'].append({
                        'number': '',
                        'promulgation_date': '',
                        'content': elem.text
                    })
    
    def _extract_attachments(self, root: ET.Element, detail: Dict[str, Any]) -> None:
        """ë³„í‘œ/ë³„ì²¨ ì¶”ì¶œ"""
        # ë³„í‘œ
        for table in root.findall('.//ë³„í‘œ'):
            attachment = {
                'type': 'ë³„í‘œ',
                'number': table.findtext('ë³„í‘œë²ˆí˜¸', ''),
                'title': table.findtext('ë³„í‘œì œëª©', ''),
                'content': self._get_all_text(table)
            }
            if attachment['content'] or attachment['title']:
                detail['attachments'].append(attachment)
        
        # ë³„ì§€
        for form in root.findall('.//ë³„ì§€'):
            attachment = {
                'type': 'ë³„ì§€',
                'number': form.findtext('ë³„ì§€ë²ˆí˜¸', ''),
                'title': form.findtext('ë³„ì§€ì œëª©', ''),
                'content': self._get_all_text(form)
            }
            if attachment['content'] or attachment['title']:
                detail['attachments'].append(attachment)
    
    def _extract_pdf_attachments_enhanced(self, root: ET.Element, detail: Dict[str, Any]) -> None:
        """PDF ì²¨ë¶€íŒŒì¼ ì¶”ì¶œ - ìˆ˜ì •ëœ ë²„ì „"""
        # ë³„í‘œ/ë³„ì§€ ì •ë³´ì—ì„œ PDF URL íŒ¨í„´ ì¶”ì¶œ
        law_name = detail['law_name']
        law_msn = detail['law_msn']
        promulgation_date = detail.get('promulgation_date', '').replace('-', '').replace('.', '')
        enforcement_date = detail.get('enforcement_date', '').replace('-', '').replace('.', '')
        
        # ë²•ë ¹ëª…ì—ì„œ ê´„í˜¸ ì œê±° (URLì—ì„œ ë¬¸ì œ ì¼ìœ¼í‚¬ ìˆ˜ ìˆìŒ)
        clean_law_name = re.sub(r'\([^)]*\)', '', law_name).strip()
        
        # 1. XMLì—ì„œ ì§ì ‘ ì²¨ë¶€íŒŒì¼ ì •ë³´ ì¶”ì¶œ - ë‹¤ì–‘í•œ íƒœê·¸ í™•ì¸
        pdf_tags = ['ì²¨ë¶€íŒŒì¼', 'íŒŒì¼', 'file', 'attachment', 'ë³„í‘œíŒŒì¼', 'ë³„ì§€íŒŒì¼', 
                    'ë³„í‘œì„œì‹', 'ë³„ì§€ì„œì‹', 'ì²¨ë¶€', 'ë¶€ì†ì„œë¥˜']
        
        for tag in pdf_tags:
            for elem in root.findall(f'.//{tag}'):
                # íŒŒì¼ ì •ë³´ ì¶”ì¶œ
                file_info = self._extract_file_info_from_element(elem)
                if file_info and (file_info.get('is_pdf') or 'ë³„í‘œ' in file_info.get('name', '') or 'ë³„ì§€' in file_info.get('name', '')):
                    pdf_info = {
                        'file_seq': file_info.get('seq', ''),
                        'file_name': file_info.get('name', ''),
                        'type': file_info.get('type', 'ì²¨ë¶€íŒŒì¼'),
                        'url': file_info.get('url', ''),
                        'direct_url': False
                    }
                    
                    # URLì´ ì—†ìœ¼ë©´ ìƒì„±
                    if not pdf_info['url'] and file_info.get('seq'):
                        pdf_info['url'] = self._build_pdf_url(law_msn, file_info['seq'])
                    
                    if pdf_info['url'] or pdf_info['file_name']:
                        detail['attachment_pdfs'].append(pdf_info)
                        self.logger.debug(f"XMLì—ì„œ PDF ë°œê²¬: {pdf_info['file_name']}")
        
        # 2. ë³„í‘œ/ë³„ì§€ ë‚´ìš©ì—ì„œ íŒŒì¼ ì •ë³´ ì¶”ì¶œ
        for attachment in detail.get('attachments', []):
            # ë³„í‘œ/ë³„ì§€ ë‚´ìš©ì— íŒŒì¼ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
            content = attachment.get('content', '')
            if 'íŒŒì¼' in content or '.pdf' in content.lower() or 'PDF' in content:
                att_type = attachment['type']
                att_num = attachment['number']
                
                if att_type and att_num:
                    # PDF ì •ë³´ ìƒì„±
                    pdf_info = {
                        'file_seq': '',
                        'file_name': f"{clean_law_name}_{att_type}{att_num}.pdf",
                        'type': att_type,
                        'url': '',
                        'direct_url': True
                    }
                    
                    # URL ìƒì„±
                    pdf_urls = self._build_attachment_pdf_urls(clean_law_name, att_type, att_num, 
                                                             promulgation_date, enforcement_date, law_msn)
                    if pdf_urls:
                        pdf_info['url'] = pdf_urls[0]
                        pdf_info['alternative_urls'] = pdf_urls[1:]
                    
                    # ì¤‘ë³µ ì²´í¬
                    if not any(p['file_name'] == pdf_info['file_name'] for p in detail['attachment_pdfs']):
                        detail['attachment_pdfs'].append(pdf_info)
                        self.logger.debug(f"ë³„í‘œ/ë³„ì§€ì—ì„œ PDF ì¶”ì •: {pdf_info['file_name']}")
        
        # 3. ë³„í‘œ/ë³„ì§€ê°€ ìˆì§€ë§Œ PDF ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°, ê¸°ë³¸ URL ìƒì„±
        if detail['attachments'] and not detail['attachment_pdfs']:
            for attachment in detail['attachments']:
                att_type = attachment['type']
                att_num = attachment['number']
                
                if att_type and att_num:
                    pdf_info = {
                        'file_seq': '',
                        'file_name': f"{clean_law_name}_{att_type}{att_num}.pdf",
                        'type': att_type,
                        'url': '',
                        'direct_url': True
                    }
                    
                    # ë‹¤ì–‘í•œ ë‚ ì§œë¡œ ì‹œë„
                    pdf_urls = self._build_attachment_pdf_urls(clean_law_name, att_type, att_num,
                                                             promulgation_date, enforcement_date, law_msn)
                    if pdf_urls:
                        pdf_info['url'] = pdf_urls[0]
                        pdf_info['alternative_urls'] = pdf_urls[1:]
                        detail['attachment_pdfs'].append(pdf_info)
        
        # ë¡œê·¸ ì¶œë ¥
        if detail['attachment_pdfs']:
            self.logger.info(f"PDF ì²¨ë¶€íŒŒì¼ {len(detail['attachment_pdfs'])}ê°œ ë°œê²¬: {law_name}")
        elif detail['attachments']:
            self.logger.warning(f"ë³„í‘œ/ë³„ì§€ëŠ” ìˆì§€ë§Œ PDF ì •ë³´ ì—†ìŒ: {law_name}")
    
    def _extract_file_info_from_element(self, elem: ET.Element) -> Dict[str, Any]:
        """XML ìš”ì†Œì—ì„œ íŒŒì¼ ì •ë³´ ì¶”ì¶œ"""
        file_info = {}
        
        # ë‹¤ì–‘í•œ ì†ì„±ëª… í™•ì¸
        seq_names = ['íŒŒì¼ìˆœë²ˆ', 'ìˆœë²ˆ', 'seq', 'fileSeq', 'file_seq', 'ì¼ë ¨ë²ˆí˜¸']
        name_names = ['íŒŒì¼ëª…', 'ëª…ì¹­', 'name', 'fileName', 'file_name', 'íŒŒì¼ì´ë¦„']
        type_names = ['íŒŒì¼ìœ í˜•', 'ìœ í˜•', 'type', 'fileType', 'file_type', 'ì¢…ë¥˜']
        url_names = ['url', 'URL', 'ì£¼ì†Œ', 'link', 'ë§í¬', 'ë‹¤ìš´ë¡œë“œì£¼ì†Œ']
        
        # ì†ì„± ì¶”ì¶œ
        for seq_name in seq_names:
            if elem.findtext(seq_name):
                file_info['seq'] = elem.findtext(seq_name)
                break
        
        for name_name in name_names:
            if elem.findtext(name_name):
                file_info['name'] = elem.findtext(name_name)
                break
        
        for type_name in type_names:
            if elem.findtext(type_name):
                file_info['type'] = elem.findtext(type_name)
                break
        
        for url_name in url_names:
            if elem.findtext(url_name):
                file_info['url'] = elem.findtext(url_name)
                break
        
        # PDF ì—¬ë¶€ í™•ì¸
        if file_info.get('name', '').lower().endswith('.pdf'):
            file_info['is_pdf'] = True
        elif file_info.get('type', '').upper() == 'PDF':
            file_info['is_pdf'] = True
        else:
            file_info['is_pdf'] = False
        
        # ë³„í‘œ/ë³„ì§€ ìœ í˜• ì¶”ì¶œ
        if file_info.get('name'):
            if 'ë³„í‘œ' in file_info['name']:
                file_info['type'] = 'ë³„í‘œ'
            elif 'ë³„ì§€' in file_info['name']:
                file_info['type'] = 'ë³„ì§€'
            elif 'ë³„ì²¨' in file_info['name']:
                file_info['type'] = 'ë³„ì²¨'
            elif 'ì„œì‹' in file_info['name']:
                file_info['type'] = 'ì„œì‹'
        
        return file_info if (file_info.get('seq') or file_info.get('name')) else {}
    
    def _build_attachment_pdf_urls(self, law_name: str, attachment_type: str, 
                                   attachment_number: str, promulgation_date: str,
                                   enforcement_date: str, law_msn: str) -> List[str]:
        """ë‹¤ì–‘í•œ PDF URL íŒ¨í„´ ìƒì„± - ê°œì„ ëœ ë²„ì „"""
        urls = []
        
        # URL ì•ˆì „ ë¬¸ìë¡œ ë³€í™˜
        import urllib.parse
        
        # ë‚ ì§œ í˜•ì‹ í†µì¼ (YYYYMMDD)
        dates_to_try = []
        if promulgation_date:
            dates_to_try.append(promulgation_date.replace('-', '').replace('.', ''))
        if enforcement_date and enforcement_date != promulgation_date:
            dates_to_try.append(enforcement_date.replace('-', '').replace('.', ''))
        
        # ë‚ ì§œê°€ ì—†ìœ¼ë©´ ìµœê·¼ ë‚ ì§œ ì‚¬ìš©
        if not dates_to_try:
            dates_to_try.append(datetime.now().strftime('%Y%m%d'))
        
        for date_str in dates_to_try:
            # 1. ë²•ì œì²˜ í‘œì¤€ íŒ¨í„´ (ê°€ì¥ ì¼ë°˜ì )
            base_pattern = f"https://www.law.go.kr/ë²•ë ¹ë³„í‘œì„œì‹/({law_name},{date_str},{attachment_type}{attachment_number})"
            urls.append(base_pattern)
            
            # 2. URL ì¸ì½”ë”©ëœ ë²„ì „
            encoded_pattern = f"https://www.law.go.kr/ë²•ë ¹ë³„í‘œì„œì‹/({urllib.parse.quote(law_name)},{date_str},{urllib.parse.quote(attachment_type)}{attachment_number})"
            urls.append(encoded_pattern)
            
            # 3. ê³µë°± ì œê±° ë²„ì „
            no_space_law = law_name.replace(' ', '')
            no_space_pattern = f"https://www.law.go.kr/ë²•ë ¹ë³„í‘œì„œì‹/({no_space_law},{date_str},{attachment_type}{attachment_number})"
            urls.append(no_space_pattern)
        
        # 4. ë²•ì œì²˜ ë‹¤ìš´ë¡œë“œ API íŒ¨í„´ (íŒŒì¼ ì‹œí€€ìŠ¤ ê¸°ë°˜)
        if law_msn:
            download_api = f"https://www.law.go.kr/flDownload.do?type=ATTACHED_FILE&lawSeq={law_msn}&flNm={urllib.parse.quote(law_name)}_{attachment_type}{attachment_number}.pdf"
            urls.append(download_api)
        
        # 5. ì§ì ‘ íŒŒì¼ ì ‘ê·¼ íŒ¨í„´
        if dates_to_try:
            year = dates_to_try[0][:4]
            direct_file = f"https://www.law.go.kr/files/{attachment_type}/{year}/{urllib.parse.quote(law_name)}_{attachment_type}{attachment_number}.pdf"
            urls.append(direct_file)
        
        return urls
    
    def _determine_attachment_type(self, filename: str) -> str:
        """íŒŒì¼ëª…ì—ì„œ ì²¨ë¶€íŒŒì¼ ìœ í˜• ì¶”ì¶œ"""
        if 'ë³„í‘œ' in filename:
            return 'ë³„í‘œ'
        elif 'ë³„ì§€' in filename:
            return 'ë³„ì§€'
        elif 'ë³„ì²¨' in filename:
            return 'ë³„ì²¨'
        elif 'ì„œì‹' in filename:
            return 'ì„œì‹'
        else:
            return 'ì²¨ë¶€íŒŒì¼'
    
    def _build_pdf_url(self, law_msn: str, file_seq: str) -> str:
        """PDF ë‹¤ìš´ë¡œë“œ URL ìƒì„± (ê¸°ë³¸ APIìš©)"""
        # ë²•ì œì²˜ PDF ë‹¤ìš´ë¡œë“œ URL íŒ¨í„´
        return f"{self.config.PDF_DOWNLOAD_URL}?flSeq={file_seq}&flNm=&type=ATTACHED_FILE&lawSeq={law_msn}"
    
    def download_pdf_attachments(self, law_detail: Dict[str, Any]) -> List[Dict[str, Any]]:
        """PDF ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ - ì™„ì „ ê°œì„  ë²„ì „"""
        downloaded_pdfs = []
        
        for pdf_info in law_detail.get('attachment_pdfs', []):
            try:
                self.logger.info(f"PDF ë‹¤ìš´ë¡œë“œ ì‹œë„: {pdf_info['file_name']}")
                
                # ì§ì ‘ URLì¸ ê²½ìš° ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„
                if pdf_info.get('direct_url'):
                    urls_to_try = [pdf_info['url']] + pdf_info.get('alternative_urls', [])
                    
                    success = False
                    for attempt, url in enumerate(urls_to_try, 1):
                        try:
                            self.logger.debug(f"ì‹œë„ {attempt}/{len(urls_to_try)}: {url}")
                            
                            # User-Agent ë° í—¤ë” ì„¤ì •
                            headers = {
                                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                                'Referer': 'https://www.law.go.kr/',
                                'Accept': 'application/pdf,application/octet-stream,*/*;q=0.9',
                                'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
                                'Accept-Encoding': 'gzip, deflate, br',
                                'Connection': 'keep-alive',
                                'Cache-Control': 'no-cache',
                                'Pragma': 'no-cache'
                            }
                            
                            # ì„¸ì…˜ ì¿ í‚¤ ì„¤ì •
                            self.session.cookies.set('JSESSIONID', 'dummy', domain='.law.go.kr')
                            
                            # GET ìš”ì²­
                            response = self.session.get(
                                url,
                                headers=headers,
                                timeout=30,
                                allow_redirects=True,
                                stream=True,
                                verify=True
                            )
                            
                            # ì‘ë‹µ í™•ì¸
                            if response.status_code == 200:
                                content_type = response.headers.get('Content-Type', '').lower()
                                content_length = int(response.headers.get('Content-Length', 0))
                                
                                # PDF í™•ì¸
                                if 'pdf' in content_type or content_length > 1000:
                                    # ì „ì²´ ì»¨í…ì¸  ë‹¤ìš´ë¡œë“œ
                                    content = b''
                                    for chunk in response.iter_content(chunk_size=8192):
                                        if chunk:
                                            content += chunk
                                    
                                    # PDF ì‹œê·¸ë‹ˆì²˜ í™•ì¸
                                    if content[:4] == b'%PDF' or b'%PDF' in content[:1024]:
                                        pdf_data = {
                                            'file_name': pdf_info['file_name'],
                                            'type': pdf_info['type'],
                                            'content': content,
                                            'size': len(content),
                                            'url_used': url
                                        }
                                        downloaded_pdfs.append(pdf_data)
                                        self.logger.info(f"âœ… PDF ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {pdf_info['file_name']} ({len(content):,} bytes)")
                                        success = True
                                        break
                                    else:
                                        self.logger.debug(f"PDF ì•„ë‹˜ - ì‹œê·¸ë‹ˆì²˜ ë¶ˆì¼ì¹˜")
                                else:
                                    self.logger.debug(f"PDF ì•„ë‹˜ - Content-Type: {content_type}")
                            
                            elif response.status_code == 404:
                                self.logger.debug(f"404 Not Found: {url}")
                            else:
                                self.logger.debug(f"HTTP {response.status_code}: {url}")
                                
                        except requests.exceptions.Timeout:
                            self.logger.debug(f"íƒ€ì„ì•„ì›ƒ: {url}")
                        except requests.exceptions.ConnectionError:
                            self.logger.debug(f"ì—°ê²° ì˜¤ë¥˜: {url}")
                        except Exception as e:
                            self.logger.debug(f"ì˜ˆì™¸ ë°œìƒ: {e}")
                    
                    if not success:
                        self.logger.warning(f"âŒ ëª¨ë“  ì‹œë„ ì‹¤íŒ¨: {pdf_info['file_name']}")
                        # ì‹¤íŒ¨ ì •ë³´ ê¸°ë¡
                        failed_info = {
                            'file_name': pdf_info['file_name'],
                            'type': pdf_info['type'],
                            'content': None,
                            'size': 0,
                            'error': 'Download failed after all attempts'
                        }
                        # downloaded_pdfs.append(failed_info)  # ì‹¤íŒ¨í•œ ê²ƒì€ ì¶”ê°€í•˜ì§€ ì•ŠìŒ
                
                else:
                    # API ê¸°ë°˜ ë‹¤ìš´ë¡œë“œ
                    try:
                        response = self.session.get(
                            pdf_info['url'],
                            timeout=30,
                            stream=True
                        )
                        
                        if response.status_code == 200 and response.content[:4] == b'%PDF':
                            pdf_data = {
                                'file_name': pdf_info['file_name'],
                                'type': pdf_info['type'],
                                'content': response.content,
                                'size': len(response.content)
                            }
                            downloaded_pdfs.append(pdf_data)
                            self.logger.info(f"âœ… API PDF ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {pdf_info['file_name']}")
                        else:
                            self.logger.warning(f"âŒ API PDF ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {pdf_info['file_name']}")
                            
                    except Exception as e:
                        self.logger.error(f"API PDF ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
                        
            except Exception as e:
                self.logger.error(f"PDF ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {pdf_info['file_name']} - {e}")
        
        # ê²°ê³¼ ìš”ì•½
        if downloaded_pdfs:
            total_size = sum(pdf['size'] for pdf in downloaded_pdfs)
            self.logger.info(f"ğŸ“„ ì´ {len(downloaded_pdfs)}ê°œ PDF ë‹¤ìš´ë¡œë“œ ì™„ë£Œ (ì´ {total_size:,} bytes)")
        
        return downloaded_pdfs
    
    def _extract_full_text(self, root: ET.Element) -> str:
        """ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        return self._get_all_text(root)
    
    def _get_all_text(self, elem: ET.Element) -> str:
        """ìš”ì†Œì˜ ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        texts = []
        
        if elem.text:
            texts.append(elem.text.strip())
            
        for child in elem:
            child_text = self._get_all_text(child)
            if child_text:
                texts.append(child_text)
                
            if child.tail:
                texts.append(child.tail.strip())
                
        return ' '.join(texts)
    
    def _remove_duplicates(self, laws: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì¤‘ë³µ ì œê±°"""
        seen = set()
        unique_laws = []
        
        for law in laws:
            law_id = law['law_id']
            if law_id not in seen:
                seen.add(law_id)
                unique_laws.append(law)
                
        return unique_laws


# ===== ë²•ë ¹ ë‚´ë³´ë‚´ê¸° í´ë˜ìŠ¤ =====
class LawExporter:
    """ë²•ë ¹ ë‚´ë³´ë‚´ê¸° í´ë˜ìŠ¤ - PDF ì§€ì› ì¶”ê°€"""
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
    
    def export_to_zip(self, laws_dict: Dict[str, Dict[str, Any]], 
                     include_pdfs: bool = False) -> bytes:
        """ZIP íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸° - PDF í¬í•¨ ì˜µì…˜ ì¶”ê°€"""
        zip_buffer = BytesIO()
        
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            # ë©”íƒ€ë°ì´í„°
            metadata = {
                'collection_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'total_laws': len(laws_dict),
                'admin_rule_count': sum(1 for law in laws_dict.values() if law.get('is_admin_rule', False)),
                'pdf_count': sum(len(law.get('attachment_pdfs', [])) for law in laws_dict.values()),
                'laws': laws_dict
            }
            
            # ì „ì²´ JSON
            zip_file.writestr(
                'all_laws.json',
                json.dumps(metadata, ensure_ascii=False, indent=2)
            )
            
            # ì „ì²´ Markdown
            all_laws_md = self._create_all_laws_markdown(laws_dict)
            zip_file.writestr('all_laws.md', all_laws_md)
            
            # ê°œë³„ íŒŒì¼
            for law_id, law in laws_dict.items():
                safe_name = self._sanitize_filename(law['law_name'])
                
                # JSON
                zip_file.writestr(
                    f'laws/{safe_name}.json',
                    json.dumps(law, ensure_ascii=False, indent=2)
                )
                
                # í…ìŠ¤íŠ¸
                text_content = self._format_law_text(law)
                zip_file.writestr(f'laws/{safe_name}.txt', text_content)
                
                # Markdown
                md_content = self._format_law_markdown(law)
                zip_file.writestr(f'laws/{safe_name}.md', md_content)
                
                # PDF ì²¨ë¶€íŒŒì¼ (ì˜µì…˜)
                if include_pdfs and law.get('downloaded_pdfs'):
                    for pdf in law['downloaded_pdfs']:
                        pdf_name = self._sanitize_filename(pdf['file_name'])
                        zip_file.writestr(
                            f'laws/{safe_name}/attachments/{pdf_name}',
                            pdf['content']
                        )
            
            # README
            readme = self._create_readme(laws_dict, include_pdfs)
            zip_file.writestr('README.md', readme)
        
        zip_buffer.seek(0)
        return zip_buffer.getvalue()
    
    def export_single_file(self, laws_dict: Dict[str, Dict[str, Any]], 
                          format: str = 'json') -> str:
        """ë‹¨ì¼ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸° - ëª¨ë“  í˜•ì‹ ì§€ì›"""
        exporters = {
            'json': self._export_as_json,
            'markdown': self._export_as_markdown,
            'text': self._export_as_text
        }
        
        exporter = exporters.get(format.lower(), self._export_as_json)
        return exporter(laws_dict)
    
    def _sanitize_filename(self, filename: str) -> str:
        """íŒŒì¼ëª… ì•ˆì „í•˜ê²Œ ë³€í™˜"""
        return re.sub(r'[\\/*?:"<>|]', '_', filename)
    
    def _export_as_json(self, laws_dict: Dict[str, Dict[str, Any]]) -> str:
        """JSON í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        data = {
            'collection_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'total_laws': len(laws_dict),
            'laws': laws_dict
        }
        return json.dumps(data, ensure_ascii=False, indent=2)
    
    def _export_as_markdown(self, laws_dict: Dict[str, Dict[str, Any]]) -> str:
        """Markdown í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        return self._create_all_laws_markdown(laws_dict)
    
    def _export_as_text(self, laws_dict: Dict[str, Dict[str, Any]]) -> str:
        """í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        lines = []
        lines.append("ë²•ë ¹ ìˆ˜ì§‘ ê²°ê³¼")
        lines.append(f"ìˆ˜ì§‘ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"ì´ ë²•ë ¹ ìˆ˜: {len(laws_dict)}ê°œ")
        lines.append("=" * 80 + "\n")
        
        for law_id, law in laws_dict.items():
            lines.append(self._format_law_text(law))
            lines.append("\n" + "=" * 80 + "\n")
            
        return '\n'.join(lines)
    
    def _format_law_text(self, law: Dict[str, Any]) -> str:
        """ë²•ë ¹ì„ í…ìŠ¤íŠ¸ë¡œ í¬ë§·"""
        lines = []
        
        # í—¤ë”
        lines.append(f"ë²•ë ¹ëª…: {law['law_name']}")
        lines.append(f"ë²•ì¢…êµ¬ë¶„: {law.get('law_type', '')}")
        if law.get('department'):
            lines.append(f"ì†Œê´€ë¶€ì²˜: {law.get('department', '')}")
        lines.append(f"ê³µí¬ì¼ì: {law.get('promulgation_date', '')}")
        lines.append(f"ì‹œí–‰ì¼ì: {law.get('enforcement_date', '')}")
        
        # PDF ì²¨ë¶€íŒŒì¼ ì •ë³´
        if law.get('attachment_pdfs'):
            lines.append(f"PDF ì²¨ë¶€íŒŒì¼: {len(law['attachment_pdfs'])}ê°œ")
        
        lines.append("-" * 60)
        
        # ì¡°ë¬¸
        if law.get('articles'):
            lines.append("\nã€ì¡° ë¬¸ã€‘\n")
            for article in law['articles']:
                lines.append(f"{article['number']} {article.get('title', '')}")
                lines.append(article['content'])
                
                if article.get('paragraphs'):
                    for para in article['paragraphs']:
                        lines.append(f"  {para['number']} {para['content']}")
                lines.append("")
        
        # ë¶€ì¹™
        if law.get('supplementary_provisions'):
            lines.append("\nã€ë¶€ ì¹™ã€‘\n")
            for provision in law['supplementary_provisions']:
                if provision.get('promulgation_date'):
                    lines.append(f"ë¶€ì¹™ <{provision['promulgation_date']}>")
                lines.append(provision['content'])
                lines.append("")
        
        # ë³„í‘œ
        if law.get('attachments'):
            lines.append("\nã€ë³„í‘œ/ë³„ì²¨ã€‘\n")
            for attachment in law['attachments']:
                lines.append(f"[{attachment['type']}] {attachment.get('title', '')}")
                lines.append(attachment['content'])
                lines.append("")
        
        # PDF ì²¨ë¶€íŒŒì¼ ëª©ë¡
        if law.get('attachment_pdfs'):
            lines.append("\nã€PDF ì²¨ë¶€íŒŒì¼ã€‘\n")
            for pdf in law['attachment_pdfs']:
                lines.append(f"- {pdf['file_name']} ({pdf['type']})")
        
        # ì›ë¬¸ (ì¡°ë¬¸ì´ ì—†ëŠ” ê²½ìš°)
        if not law.get('articles') and law.get('raw_content'):
            lines.append("\nã€ì› ë¬¸ã€‘\n")
            lines.append(law['raw_content'])
        
        return '\n'.join(lines)
    
    def _format_law_markdown(self, law: Dict[str, Any]) -> str:
        """ë²•ë ¹ì„ Markdownìœ¼ë¡œ í¬ë§·"""
        lines = []
        
        # ì œëª©
        lines.append(f"# {law['law_name']}\n")
        
        # ê¸°ë³¸ ì •ë³´
        lines.append("## ğŸ“‹ ê¸°ë³¸ ì •ë³´\n")
        lines.append(f"- **ë²•ì¢…êµ¬ë¶„**: {law.get('law_type', '')}")
        if law.get('department'):
            lines.append(f"- **ì†Œê´€ë¶€ì²˜**: {law.get('department', '')}")
        lines.append(f"- **ê³µí¬ì¼ì**: {law.get('promulgation_date', '')}")
        lines.append(f"- **ì‹œí–‰ì¼ì**: {law.get('enforcement_date', '')}")
        
        # PDF ì²¨ë¶€íŒŒì¼ ì •ë³´
        if law.get('attachment_pdfs'):
            lines.append(f"- **PDF ì²¨ë¶€íŒŒì¼**: {len(law['attachment_pdfs'])}ê°œ")
        
        lines.append("")
        
        # ì¡°ë¬¸
        if law.get('articles'):
            lines.append("## ğŸ“– ì¡°ë¬¸\n")
            for article in law['articles']:
                lines.append(f"### {article['number']}")
                if article.get('title'):
                    lines.append(f"**{article['title']}**\n")
                lines.append(article['content'])
                
                if article.get('paragraphs'):
                    for para in article['paragraphs']:
                        lines.append(f"\n> {para['number']} {para['content']}")
                lines.append("")
        
        # ë¶€ì¹™
        if law.get('supplementary_provisions'):
            lines.append("## ğŸ“Œ ë¶€ì¹™\n")
            for provision in law['supplementary_provisions']:
                if provision.get('promulgation_date'):
                    lines.append(f"### ë¶€ì¹™ <{provision['promulgation_date']}>")
                lines.append(provision['content'])
                lines.append("")
        
        # ë³„í‘œ
        if law.get('attachments'):
            lines.append("## ğŸ“ ë³„í‘œ/ë³„ì²¨\n")
            for attachment in law['attachments']:
                lines.append(f"### [{attachment['type']}] {attachment.get('title', '')}")
                lines.append(attachment['content'])
                lines.append("")
        
        # PDF ì²¨ë¶€íŒŒì¼
        if law.get('attachment_pdfs'):
            lines.append("## ğŸ“„ PDF ì²¨ë¶€íŒŒì¼\n")
            for pdf in law['attachment_pdfs']:
                lines.append(f"- **{pdf['file_name']}** ({pdf['type']})")
                if law.get('downloaded_pdfs'):
                    lines.append("  - âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                else:
                    lines.append("  - â³ ë¯¸ë‹¤ìš´ë¡œë“œ")
            lines.append("")
        
        return '\n'.join(lines)
    
    def _create_all_laws_markdown(self, laws_dict: Dict[str, Dict[str, Any]]) -> str:
        """ì „ì²´ ë²•ë ¹ Markdown ìƒì„±"""
        lines = []
        
        # í—¤ë”
        lines.append("# ğŸ“š ë²•ë ¹ ìˆ˜ì§‘ ê²°ê³¼\n")
        lines.append(f"**ìˆ˜ì§‘ ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"**ì´ ë²•ë ¹ ìˆ˜**: {len(laws_dict)}ê°œ")
        
        # í†µê³„
        admin_rule_count = sum(1 for law in laws_dict.values() if law.get('is_admin_rule', False))
        pdf_count = sum(len(law.get('attachment_pdfs', [])) for law in laws_dict.values())
        
        if admin_rule_count > 0:
            lines.append(f"**í–‰ì •ê·œì¹™ ìˆ˜**: {admin_rule_count}ê°œ")
        if pdf_count > 0:
            lines.append(f"**PDF ì²¨ë¶€íŒŒì¼ ì´ê³„**: {pdf_count}ê°œ")
        
        lines.append("")
        
        # ëª©ì°¨
        lines.append("## ğŸ“‘ ëª©ì°¨\n")
        for idx, (law_id, law) in enumerate(laws_dict.items(), 1):
            anchor = self._sanitize_filename(law['law_name'])
            type_emoji = "ğŸ“‹" if law.get('is_admin_rule', False) else "ğŸ“–"
            pdf_mark = " ğŸ“„" if law.get('attachment_pdfs') else ""
            lines.append(f"{idx}. {type_emoji} [{law['law_name']}](#{anchor}){pdf_mark}")
        lines.append("\n---\n")
        
        # ê° ë²•ë ¹
        for law_id, law in laws_dict.items():
            lines.append(self._format_law_markdown(law))
            lines.append("\n---\n")
            
        return '\n'.join(lines)
    
    def _create_readme(self, laws_dict: Dict[str, Dict[str, Any]], 
                      include_pdfs: bool = False) -> str:
        """README ìƒì„±"""
        # í†µê³„ ê³„ì‚°
        total_articles = sum(len(law.get('articles', [])) for law in laws_dict.values())
        total_provisions = sum(len(law.get('supplementary_provisions', [])) for law in laws_dict.values())
        total_attachments = sum(len(law.get('attachments', [])) for law in laws_dict.values())
        admin_rule_count = sum(1 for law in laws_dict.values() if law.get('is_admin_rule', False))
        pdf_count = sum(len(law.get('attachment_pdfs', [])) for law in laws_dict.values())
        
        content = f"""# ë²•ë ¹ ìˆ˜ì§‘ ê²°ê³¼

ìˆ˜ì§‘ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ì´ ë²•ë ¹ ìˆ˜: {len(laws_dict)}ê°œ

## ğŸ“ íŒŒì¼ êµ¬ì¡°

- `all_laws.json`: ì „ì²´ ë²•ë ¹ ë°ì´í„° (JSON)
- `all_laws.md`: ì „ì²´ ë²•ë ¹ í†µí•© ë¬¸ì„œ (Markdown)
- `laws/`: ê°œë³„ ë²•ë ¹ íŒŒì¼
  - `*.json`: ë²•ë ¹ë³„ ìƒì„¸ ë°ì´í„°
  - `*.txt`: ë²•ë ¹ë³„ í…ìŠ¤íŠ¸
  - `*.md`: ë²•ë ¹ë³„ Markdown"""

        if include_pdfs and pdf_count > 0:
            content += """
  - `*/attachments/`: PDF ì²¨ë¶€íŒŒì¼ (ë³„í‘œ/ë³„ì²¨)"""

        content += f"""
- `README.md`: ì´ íŒŒì¼

## ğŸ“Š í†µê³„

- ì´ ì¡°ë¬¸ ìˆ˜: {total_articles:,}ê°œ
- ì´ ë¶€ì¹™ ìˆ˜: {total_provisions}ê°œ
- ì´ ë³„í‘œ/ë³„ì²¨ ìˆ˜: {total_attachments}ê°œ
- í–‰ì •ê·œì¹™ ìˆ˜: {admin_rule_count}ê°œ
- PDF ì²¨ë¶€íŒŒì¼: {pdf_count}ê°œ

## ğŸ“– ìˆ˜ì§‘ëœ ë²•ë ¹ ëª©ë¡

"""
        
        # ì¼ë°˜ ë²•ë ¹ê³¼ í–‰ì •ê·œì¹™ ë¶„ë¦¬
        general_laws = []
        admin_rules = []
        
        for law_id, law in laws_dict.items():
            if law.get('is_admin_rule', False):
                admin_rules.append((law_id, law))
            else:
                general_laws.append((law_id, law))
        
        # ì¼ë°˜ ë²•ë ¹ ëª©ë¡
        if general_laws:
            content += "\n### ğŸ“– ì¼ë°˜ ë²•ë ¹\n\n"
            for law_id, law in general_laws:
                content += f"#### {law['law_name']}\n"
                content += f"- ë²•ì¢…êµ¬ë¶„: {law.get('law_type', '')}\n"
                content += f"- ì‹œí–‰ì¼ì: {law.get('enforcement_date', '')}\n"
                content += f"- ì¡°ë¬¸: {len(law.get('articles', []))}ê°œ\n"
                if law.get('attachment_pdfs'):
                    content += f"- PDF ì²¨ë¶€: {len(law['attachment_pdfs'])}ê°œ\n"
                content += "\n"
        
        # í–‰ì •ê·œì¹™ ëª©ë¡
        if admin_rules:
            content += "\n### ğŸ“‹ í–‰ì •ê·œì¹™\n\n"
            for law_id, law in admin_rules:
                content += f"#### {law['law_name']}\n"
                content += f"- ìœ í˜•: {law.get('law_type', '')}\n"
                if law.get('department'):
                    content += f"- ì†Œê´€ë¶€ì²˜: {law.get('department', '')}\n"
                content += f"- ì‹œí–‰ì¼ì: {law.get('enforcement_date', '')}\n"
                content += f"- ì¡°ë¬¸: {len(law.get('articles', []))}ê°œ\n"
                if law.get('attachment_pdfs'):
                    content += f"- PDF ì²¨ë¶€: {len(law['attachment_pdfs'])}ê°œ\n"
                content += "\n"
            
        return content


# ===== Streamlit UI í•¨ìˆ˜ë“¤ =====
def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    defaults = {
        'mode': 'direct',
        'extracted_laws': [],
        'search_results': [],
        'selected_laws': [],
        'collected_laws': {},
        'file_processed': False,
        'openai_api_key': None,
        'use_ai': False,
        'oc_code': '',
        'include_pdfs': False  # PDF ë‹¤ìš´ë¡œë“œ ì˜µì…˜
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value


def show_sidebar():
    """ì‚¬ì´ë“œë°” UI - ê°œì„ ëœ API í‚¤ ì²˜ë¦¬"""
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # ê¸°ê´€ì½”ë“œ ì…ë ¥ - ê³ ìœ  í‚¤ ì‚¬ìš©
        oc_code = st.text_input(
            "ê¸°ê´€ì½”ë“œ (OC)",
            value=st.session_state.get('oc_code', ''),
            placeholder="ì´ë©”ì¼ @ ì•ë¶€ë¶„",
            help="ì˜ˆ: test@korea.kr â†’ test",
            key="sidebar_oc_code"  # ê³ ìœ  í‚¤ ì¶”ê°€
        )
        
        # ê°’ì´ ë³€ê²½ë˜ë©´ ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
        if oc_code != st.session_state.get('oc_code', ''):
            st.session_state.oc_code = oc_code
        
        st.divider()
        
        # AI ì„¤ì • (ê°œì„ ëœ ë²„ì „)
        with st.expander("ğŸ¤– AI ì„¤ì • (ì„ íƒì‚¬í•­)", expanded=False):
            st.markdown("**ChatGPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë²•ë ¹ëª… ì¶”ì¶œ ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤**")
            
            # OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ í™•ì¸
            try:
                import openai
                openai_available = True
            except ImportError:
                openai_available = False
                st.warning("âš ï¸ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                st.info("ì„¤ì¹˜í•˜ë ¤ë©´: `pip install openai`")
            
            if openai_available:
                # í˜„ì¬ API í‚¤ ìƒíƒœ í‘œì‹œ
                if st.session_state.get('use_ai', False) and st.session_state.get('openai_api_key'):
                    st.success("âœ… AI ê¸°ëŠ¥ í™œì„±í™”ë¨")
                    st.caption(f"í˜„ì¬ API í‚¤: {st.session_state.openai_api_key[:10]}...")
                    
                    if st.button("ğŸ”„ API í‚¤ ì¬ì„¤ì •", type="secondary"):
                        st.session_state.openai_api_key = None
                        st.session_state.use_ai = False
                        st.rerun()
                else:
                    # API í‚¤ ì…ë ¥
                    api_key_input = st.text_input(
                        "OpenAI API Key",
                        type="password",
                        value="",
                        key="openai_key_new_input",  # ê³ ìœ  í‚¤
                        help="https://platform.openai.com/api-keys ì—ì„œ ë°œê¸‰",
                        placeholder="sk-..."
                    )
                    
                    if st.button("ğŸ”‘ API í‚¤ ì„¤ì •", type="primary"):
                        if api_key_input:
                            # í‚¤ ì •ë¦¬ ë° ê²€ì¦
                            cleaned_key = api_key_input.strip()
                            
                            if cleaned_key.startswith(('sk-', 'sess-')) and len(cleaned_key) > 40:
                                with st.spinner("API í‚¤ ê²€ì¦ ì¤‘..."):
                                    try:
                                        from openai import OpenAI
                                        # í…ŒìŠ¤íŠ¸ìš© í´ë¼ì´ì–¸íŠ¸ ìƒì„±
                                        test_client = OpenAI(api_key=cleaned_key)
                                        
                                        # ë²„ì „ ë…ë¦½ì ì¸ API í…ŒìŠ¤íŠ¸
                                        success = False
                                        try:
                                            # ê°€ì¥ ê°„ë‹¨í•œ API í˜¸ì¶œ - chat completion
                                            test_response = test_client.chat.completions.create(
                                                model="gpt-3.5-turbo",
                                                messages=[{"role": "user", "content": "test"}],
                                                max_tokens=1
                                            )
                                            success = True
                                        except Exception as chat_error:
                                            # chat API ì‹¤íŒ¨ ì‹œ models API ì‹œë„
                                            try:
                                                # ì‹ ë²„ì „ API í˜¸í™˜
                                                test_response = test_client.models.list()
                                                if test_response and hasattr(test_response, 'data'):
                                                    success = True
                                            except:
                                                # êµ¬ë²„ì „ API í˜¸í™˜
                                                try:
                                                    # ê°„ë‹¨í•œ ì™„ë£Œ í…ŒìŠ¤íŠ¸
                                                    test_response = test_client.completions.create(
                                                        model="text-davinci-003",
                                                        prompt="test",
                                                        max_tokens=1
                                                    )
                                                    success = True
                                                except:
                                                    success = False
                                        
                                        if success:
                                            # ì„±ê³µí•˜ë©´ ì„¸ì…˜ì— ì €ì¥
                                            st.session_state.openai_api_key = cleaned_key
                                            st.session_state.use_ai = True
                                            st.success("âœ… API í‚¤ê°€ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                            logger.info(f"API í‚¤ ì„¤ì • ë° ê²€ì¦ ì™„ë£Œ")
                                            st.rerun()
                                        else:
                                            raise Exception("API í‚¤ ê²€ì¦ ì‹¤íŒ¨")
                                        
                                    except Exception as e:
                                        error_msg = str(e)
                                        if "401" in error_msg or "Incorrect API key" in error_msg:
                                            st.error("âŒ API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                                            st.info("ì˜¬ë°”ë¥¸ OpenAI API í‚¤ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
                                        elif "429" in error_msg:
                                            st.warning("âš ï¸ API ì‚¬ìš© í•œë„ ì´ˆê³¼. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                                        else:
                                            st.error(f"âŒ API í‚¤ ê²€ì¦ ì‹¤íŒ¨: {error_msg}")
                                        
                                        logger.error(f"API í‚¤ ê²€ì¦ ì‹¤íŒ¨: {e}")
                            else:
                                st.error("âŒ ì˜¬ë°”ë¥¸ í˜•ì‹ì˜ API í‚¤ê°€ ì•„ë‹™ë‹ˆë‹¤.")
                                st.info("'sk-' ë˜ëŠ” 'sess-'ë¡œ ì‹œì‘í•˜ëŠ” í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                        else:
                            st.warning("API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        st.divider()
        
        # PDF ë‹¤ìš´ë¡œë“œ ì˜µì…˜
        st.subheader("ğŸ“„ PDF ì˜µì…˜")
        include_pdfs = st.checkbox(
            "ë³„í‘œ/ë³„ì²¨ PDF ë‹¤ìš´ë¡œë“œ",
            value=st.session_state.get('include_pdfs', False),
            help="ë²•ë ¹ì˜ ë³„í‘œ, ë³„ì²¨ ë“±ì´ PDFë¡œ ì œê³µë˜ëŠ” ê²½ìš° í•¨ê»˜ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.",
            key="sidebar_include_pdfs"  # ê³ ìœ  í‚¤
        )
        
        if include_pdfs != st.session_state.get('include_pdfs', False):
            st.session_state.include_pdfs = include_pdfs
        
        st.divider()
        
        # ëª¨ë“œ ì„ íƒ
        st.subheader("ğŸ¯ ìˆ˜ì§‘ ë°©ì‹")
        mode = st.radio(
            "ë°©ì‹ ì„ íƒ",
            ["ì§ì ‘ ê²€ìƒ‰", "íŒŒì¼ ì—…ë¡œë“œ"],
            help="ì§ì ‘ ê²€ìƒ‰: ë²•ë ¹ëª…ì„ ì…ë ¥í•˜ì—¬ ê²€ìƒ‰\níŒŒì¼ ì—…ë¡œë“œ: íŒŒì¼ì—ì„œ ë²•ë ¹ ì¶”ì¶œ",
            key="sidebar_mode"  # ê³ ìœ  í‚¤
        )
        st.session_state.mode = 'direct' if mode == "ì§ì ‘ ê²€ìƒ‰" else 'file'
        
        # í…ŒìŠ¤íŠ¸ ë²„íŠ¼ ì¶”ê°€
        st.divider()
        st.subheader("ğŸ§ª í…ŒìŠ¤íŠ¸")
        
        if st.button("í–‰ì •ê·œì¹™ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸", type="secondary", use_container_width=True):
            if not st.session_state.get('oc_code', ''):
                st.error("ê¸°ê´€ì½”ë“œë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”!")
            else:
                test_admin_rule_search(st.session_state.oc_code)
        
        # ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ”„ ì´ˆê¸°í™”", type="secondary", use_container_width=True):
            keys_to_keep = ['mode']  # ìµœì†Œí•œì˜ í‚¤ë§Œ ìœ ì§€
            for key in list(st.session_state.keys()):
                if key not in keys_to_keep:
                    del st.session_state[key]
            st.rerun()
        
        return st.session_state.get('oc_code', '')


def test_admin_rule_search(oc_code: str):
    """í–‰ì •ê·œì¹™ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ - PDF ë””ë²„ê¹… ì •ë³´ ì¶”ê°€"""
    with st.spinner("í–‰ì •ê·œì¹™ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì¤‘..."):
        collector = LawCollectorAPI(oc_code)
        
        # í…ŒìŠ¤íŠ¸í•  í–‰ì •ê·œì¹™ë“¤
        test_rules = [
            "ê¸ˆìœµê¸°ê´€ê²€ì‚¬ë°ì œì¬ì—ê´€í•œê·œì •",
            "ì—¬ì‹ ì „ë¬¸ê¸ˆìœµì—…ê°ë…ê·œì •",
            "ì—¬ì‹ ì „ë¬¸ê¸ˆìœµì—…ê°ë…ì—…ë¬´ì‹œí–‰ì„¸ì¹™"
        ]
        
        for rule_name in test_rules:
            st.write(f"\nğŸ” ê²€ìƒ‰ ì¤‘: {rule_name}")
            
            # ì‹¤ì œ ê²€ìƒ‰ ë©”ì„œë“œ í…ŒìŠ¤íŠ¸
            found = collector.search_single_law(rule_name)
            if found:
                st.success(f"âœ… {len(found)}ê°œ ë°œê²¬!")
                for item in found:
                    type_emoji = "ğŸ“‹" if item.get('is_admin_rule') else "ğŸ“–"
                    st.write(f"    {type_emoji} {item['law_name']} ({item['law_type']})")
                    
                    # PDF ì²¨ë¶€íŒŒì¼ í™•ì¸ - ìƒì„¸ í…ŒìŠ¤íŠ¸
                    if found and st.session_state.get('include_pdfs', False):
                        with st.expander(f"PDF í…ŒìŠ¤íŠ¸: {item['law_name']}"):
                            detail = collector._get_law_detail(
                                item['law_id'], 
                                item['law_msn'], 
                                item['law_name'], 
                                item.get('is_admin_rule', False)
                            )
                            if detail:
                                if detail.get('attachment_pdfs'):
                                    st.info(f"ğŸ“„ PDF ë°œê²¬: {len(detail['attachment_pdfs'])}ê°œ")
                                    
                                    # PDF ì •ë³´ í‘œì‹œ
                                    for pdf in detail['attachment_pdfs']:
                                        st.write(f"**íŒŒì¼ëª…**: {pdf['file_name']}")
                                        st.write(f"**ìœ í˜•**: {pdf['type']}")
                                        st.write(f"**URL**: `{pdf['url']}`")
                                        
                                        # ë‹¤ìš´ë¡œë“œ í…ŒìŠ¤íŠ¸
                                        if st.button(f"ë‹¤ìš´ë¡œë“œ í…ŒìŠ¤íŠ¸: {pdf['file_name']}", key=f"test_dl_{pdf['file_name']}"):
                                            downloaded = collector.download_pdf_attachments({'attachment_pdfs': [pdf]})
                                            if downloaded:
                                                st.success(f"âœ… ë‹¤ìš´ë¡œë“œ ì„±ê³µ! ({downloaded[0]['size']:,} bytes)")
                                            else:
                                                st.error("âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
                                                if pdf.get('alternative_urls'):
                                                    st.write("ëŒ€ì²´ URLë“¤:")
                                                    for alt_url in pdf['alternative_urls']:
                                                        st.code(alt_url)
                                else:
                                    st.warning("ğŸ“„ PDF ì²¨ë¶€íŒŒì¼ ì—†ìŒ")
                                    
                                # ë³„í‘œ/ë³„ì§€ ì •ë³´
                                if detail.get('attachments'):
                                    st.write(f"**ë³„í‘œ/ë³„ì§€**: {len(detail['attachments'])}ê°œ")
                                    for att in detail['attachments']:
                                        st.write(f"- {att['type']} {att.get('number', '')}: {att.get('title', '')}")
            else:
                st.warning(f"âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            
            time.sleep(0.5)


def handle_direct_search_mode(oc_code: str):
    """ì§ì ‘ ê²€ìƒ‰ ëª¨ë“œ ì²˜ë¦¬"""
    st.header("ğŸ” ì§ì ‘ ê²€ìƒ‰ ëª¨ë“œ")
    
    law_name = st.text_input(
        "ë²•ë ¹ëª…",
        placeholder="ì˜ˆ: ë¯¼ë²•, ìƒë²•, ê¸ˆìœµê°ë…ê·œì •",
        help="ê²€ìƒ‰í•  ë²•ë ¹ëª…ì„ ì…ë ¥í•˜ì„¸ìš” (í–‰ì •ê·œì¹™ë„ ê²€ìƒ‰ ê°€ëŠ¥)"
    )
    
    if st.button("ğŸ” ê²€ìƒ‰", type="primary", use_container_width=True):
        if not oc_code:
            st.error("ê¸°ê´€ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        elif not law_name:
            st.error("ë²•ë ¹ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        else:
            with st.spinner(f"'{law_name}' ê²€ìƒ‰ ì¤‘..."):
                collector = LawCollectorAPI(oc_code)
                results = collector.search_single_law(law_name)
                
                if results:
                    st.success(f"{len(results)}ê°œì˜ ë²•ë ¹ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                    
                    # í–‰ì •ê·œì¹™ ê°œìˆ˜ í‘œì‹œ
                    admin_count = sum(1 for r in results if r.get('is_admin_rule'))
                    if admin_count > 0:
                        st.info(f"ğŸ“‹ ì´ ì¤‘ {admin_count}ê°œëŠ” í–‰ì •ê·œì¹™ì…ë‹ˆë‹¤.")
                    
                    st.session_state.search_results = results
                else:
                    st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    st.info("ğŸ’¡ Tip: ë„ì–´ì“°ê¸°ë¥¼ ì¡°ì •í•˜ê±°ë‚˜ ê¸°ê´€ì½”ë“œë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.")
                    st.session_state.search_results = []


def handle_file_upload_mode(oc_code: str):
    """íŒŒì¼ ì—…ë¡œë“œ ëª¨ë“œ ì²˜ë¦¬"""
    st.header("ğŸ“„ íŒŒì¼ ì—…ë¡œë“œ ëª¨ë“œ")
    
    # AI ìƒíƒœ í‘œì‹œ (ìˆ˜ì •)
    if st.session_state.use_ai and st.session_state.openai_api_key:
        st.info(f"ğŸ¤– AI ê°•í™” ëª¨ë“œ í™œì„±í™”")
    else:
        st.info("ğŸ’¡ AI ì„¤ì •ì„ í†µí•´ ë²•ë ¹ëª… ì¶”ì¶œ ì •í™•ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    
    uploaded_file = st.file_uploader(
        "íŒŒì¼ ì„ íƒ",
        type=['pdf', 'xlsx', 'xls', 'md', 'txt'],
        help="PDF, Excel, Markdown, í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì§€ì›í•©ë‹ˆë‹¤"
    )
    
    if uploaded_file and not st.session_state.file_processed:
        st.subheader("ğŸ“‹ STEP 1: ë²•ë ¹ëª… ì¶”ì¶œ")
        
        with st.spinner("íŒŒì¼ì—ì„œ ë²•ë ¹ëª…ì„ ì¶”ì¶œí•˜ëŠ” ì¤‘..."):
            # API í‚¤ ì „ë‹¬ í™•ì¸
            logger.info(f"AI ì‚¬ìš© ì—¬ë¶€: {st.session_state.use_ai}")
            logger.info(f"API í‚¤ ì¡´ì¬: {bool(st.session_state.openai_api_key)}")
            
            extractor = EnhancedLawFileExtractor(
                use_ai=st.session_state.use_ai,
                api_key=st.session_state.openai_api_key
            )
            
            file_type = uploaded_file.name.split('.')[-1].lower()
            
            try:
                extracted_laws = extractor.extract_from_file(uploaded_file, file_type)
                
                if extracted_laws:
                    st.success(f"âœ… {len(extracted_laws)}ê°œì˜ ë²•ë ¹ëª…ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                    st.session_state.extracted_laws = extracted_laws
                    st.session_state.file_processed = True
                else:
                    st.warning("íŒŒì¼ì—ì„œ ë²•ë ¹ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    
            except Exception as e:
                st.error(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                logger.error(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}", exc_info=True)
    
    # ì¶”ì¶œëœ ë²•ë ¹ í‘œì‹œ
    if st.session_state.extracted_laws:
        display_extracted_laws(oc_code)


def display_extracted_laws(oc_code: str):
    """ì¶”ì¶œëœ ë²•ë ¹ í‘œì‹œ ë° í¸ì§‘"""
    st.subheader("âœï¸ STEP 2: ë²•ë ¹ëª… í™•ì¸ ë° í¸ì§‘")
    
    # ì¶”ì¶œëœ ë²•ë ¹ ëª©ë¡
    st.write("**ì¶”ì¶œëœ ë²•ë ¹ëª…:**")
    col1, col2 = st.columns([3, 1])
    with col1:
        for idx, law in enumerate(st.session_state.extracted_laws, 1):
            # í–‰ì •ê·œì¹™ í‚¤ì›Œë“œ ì²´í¬
            is_admin = any(k in law for k in LawPatterns.ADMIN_KEYWORDS)
            emoji = "ğŸ“‹" if is_admin else "ğŸ“–"
            st.write(f"{idx}. {emoji} {law}")
    
    with col2:
        st.metric("ì´ ë²•ë ¹", len(st.session_state.extracted_laws))
        admin_count = sum(1 for law in st.session_state.extracted_laws 
                         if any(k in law for k in LawPatterns.ADMIN_KEYWORDS))
        if admin_count > 0:
            st.metric("í–‰ì •ê·œì¹™", admin_count)
    
    # í¸ì§‘ ì˜ì—­
    edited_laws = []
    st.write("\n**ë²•ë ¹ëª… í¸ì§‘:**")
    
    for idx, law_name in enumerate(st.session_state.extracted_laws):
        col1, col2 = st.columns([4, 1])
        with col1:
            edited_name = st.text_input(
                f"ë²•ë ¹ {idx+1}",
                value=law_name,
                key=f"edit_{idx}"
            )
            if edited_name:
                edited_laws.append(edited_name)
        with col2:
            if st.button("ì‚­ì œ", key=f"del_{idx}"):
                st.session_state.extracted_laws.pop(idx)
                st.rerun()
    
    # ë²•ë ¹ëª… ì¶”ê°€
    st.subheader("ë²•ë ¹ëª… ì¶”ê°€")
    new_law = st.text_input("ìƒˆ ë²•ë ¹ëª… ì…ë ¥", key="new_law_input")
    if st.button("â• ì¶”ê°€") and new_law:
        st.session_state.extracted_laws.append(new_law)
        st.rerun()
    
    # ê²€ìƒ‰ ë²„íŠ¼
    if st.button("ğŸ” ë²•ë ¹ ê²€ìƒ‰", type="primary", use_container_width=True):
        if not oc_code:
            st.error("ê¸°ê´€ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        else:
            search_laws_from_list(oc_code, edited_laws or st.session_state.extracted_laws)


def search_laws_from_list(oc_code: str, law_names: List[str]):
    """ë²•ë ¹ ëª©ë¡ ê²€ìƒ‰"""
    collector = LawCollectorAPI(oc_code)
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    def update_progress(progress):
        progress_bar.progress(progress)
    
    with st.spinner("ë²•ë ¹ì„ ê²€ìƒ‰í•˜ëŠ” ì¤‘..."):
        results = collector.search_laws(law_names, progress_callback=update_progress)
    
    progress_bar.progress(1.0)
    status_text.text("ê²€ìƒ‰ ì™„ë£Œ!")
    
    if results:
        st.success(f"âœ… ì´ {len(results)}ê°œì˜ ë²•ë ¹ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
        
        # í–‰ì •ê·œì¹™ í†µê³„
        admin_count = sum(1 for r in results if r.get('is_admin_rule'))
        if admin_count > 0:
            st.info(f"ğŸ“‹ ì´ ì¤‘ {admin_count}ê°œëŠ” í–‰ì •ê·œì¹™ì…ë‹ˆë‹¤.")
        
        st.session_state.search_results = results
    else:
        st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")


def display_search_results_and_collect(oc_code: str):
    """ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ ë° ìˆ˜ì§‘"""
    if not st.session_state.search_results:
        return
        
    st.subheader("ğŸ“‘ ê²€ìƒ‰ ê²°ê³¼")
    
    # ì „ì²´ ì„ íƒ
    select_all = st.checkbox("ì „ì²´ ì„ íƒ")
    
    # í…Œì´ë¸” í—¤ë”
    cols = st.columns([1, 1, 3, 2, 2, 2])
    headers = ["ì„ íƒ", "ìœ í˜•", "ë²•ë ¹ëª…", "ë²•ì¢…êµ¬ë¶„", "ì‹œí–‰ì¼ì", "ê²€ìƒ‰ì–´"]
    for col, header in zip(cols, headers):
        col.markdown(f"**{header}**")
    
    st.divider()
    
    # ê²°ê³¼ í‘œì‹œ
    selected_indices = []
    for idx, law in enumerate(st.session_state.search_results):
        cols = st.columns([1, 1, 3, 2, 2, 2])
        
        with cols[0]:
            # ë¹ˆ ë ˆì´ë¸” ê²½ê³  í•´ê²°: label_visibility ì‚¬ìš©
            if st.checkbox("ì„ íƒ", key=f"sel_{idx}", value=select_all, label_visibility="collapsed"):
                selected_indices.append(idx)
        
        with cols[1]:
            # ìœ í˜• ì•„ì´ì½˜
            if law.get('is_admin_rule'):
                st.write("ğŸ“‹")  # í–‰ì •ê·œì¹™
            else:
                st.write("ğŸ“–")  # ì¼ë°˜ ë²•ë ¹
        
        with cols[2]:
            st.write(law['law_name'])
        
        with cols[3]:
            st.write(law.get('law_type', ''))
        
        with cols[4]:
            st.write(law.get('enforcement_date', ''))
        
        with cols[5]:
            st.write(law.get('search_query', ''))
    
    # ì„ íƒëœ ë²•ë ¹ ì €ì¥
    st.session_state.selected_laws = [
        st.session_state.search_results[i] for i in selected_indices
    ]
    
    if st.session_state.selected_laws:
        st.success(f"{len(st.session_state.selected_laws)}ê°œ ë²•ë ¹ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤")
        
        # ì„ íƒëœ í–‰ì •ê·œì¹™ ê°œìˆ˜
        selected_admin = sum(1 for law in st.session_state.selected_laws 
                           if law.get('is_admin_rule'))
        if selected_admin > 0:
            st.info(f"ğŸ“‹ ì„ íƒëœ í–‰ì •ê·œì¹™: {selected_admin}ê°œ")
        
        # ìˆ˜ì§‘ ë²„íŠ¼
        if st.button("ğŸ“¥ ì„ íƒí•œ ë²•ë ¹ ìˆ˜ì§‘", type="primary", use_container_width=True):
            collect_selected_laws(oc_code)


def collect_selected_laws(oc_code: str):
    """ì„ íƒëœ ë²•ë ¹ ìˆ˜ì§‘ - PDF ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ ê°•í™”"""
    collector = LawCollectorAPI(oc_code)
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    def update_progress(progress):
        progress_bar.progress(progress)
        
    with st.spinner("ë²•ë ¹ ìƒì„¸ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì¤‘..."):
        collected = collector.collect_law_details(
            st.session_state.selected_laws,
            progress_callback=update_progress
        )
    
    # PDF ë‹¤ìš´ë¡œë“œ (ì˜µì…˜)
    if st.session_state.get('include_pdfs', False):
        status_text.text("PDF ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        
        total_pdf_count = sum(len(law.get('attachment_pdfs', [])) for law in collected.values())
        if total_pdf_count > 0:
            st.info(f"ğŸ“„ ì´ {total_pdf_count}ê°œì˜ PDF íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
            
            pdf_progress = st.progress(0)
            downloaded_count = 0
            failed_count = 0
            
            for law_idx, (law_id, law_detail) in enumerate(collected.items()):
                if law_detail.get('attachment_pdfs'):
                    st.write(f"ğŸ“– {law_detail['law_name']}ì˜ PDF ë‹¤ìš´ë¡œë“œ ì¤‘...")
                    
                    # PDF ë‹¤ìš´ë¡œë“œ ì‹œë„
                    downloaded_pdfs = collector.download_pdf_attachments(law_detail)
                    
                    if downloaded_pdfs:
                        law_detail['downloaded_pdfs'] = downloaded_pdfs
                        downloaded_count += len(downloaded_pdfs)
                        st.success(f"âœ… {len(downloaded_pdfs)}ê°œ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                    else:
                        failed_count += len(law_detail.get('attachment_pdfs', []))
                        st.warning(f"âš ï¸ PDF ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
                    
                    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                    pdf_progress.progress((law_idx + 1) / len(collected))
            
            # ê²°ê³¼ ìš”ì•½
            if downloaded_count > 0:
                st.success(f"ğŸ“„ ì´ {downloaded_count}ê°œì˜ PDF íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí–ˆìŠµë‹ˆë‹¤!")
            if failed_count > 0:
                st.warning(f"âš ï¸ {failed_count}ê°œì˜ PDF íŒŒì¼ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                with st.expander("ğŸ’¡ PDF ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ í•´ê²° ë°©ë²•"):
                    st.write("1. ë²•ì œì²˜ ì‚¬ì´íŠ¸ì—ì„œ ì§ì ‘ í™•ì¸í•´ë³´ì„¸ìš”.")
                    st.write("2. ë³„í‘œ/ë³„ì§€ ë²ˆí˜¸ê°€ ì •í™•í•œì§€ í™•ì¸í•˜ì„¸ìš”.")
                    st.write("3. ìµœì‹  ê°œì •ëœ ë²•ë ¹ì˜ ê²½ìš° ì•„ì§ PDFê°€ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.info("ğŸ“„ PDF ì²¨ë¶€íŒŒì¼ì´ ì—†ëŠ” ë²•ë ¹ë“¤ì…ë‹ˆë‹¤.")
    
    progress_bar.progress(1.0)
    
    success_count = len(collected)
    total_count = len(st.session_state.selected_laws)
    status_text.text(f"ìˆ˜ì§‘ ì™„ë£Œ! (ì„±ê³µ: {success_count}/{total_count})")
    
    if success_count < total_count:
        failed_laws = [law['law_name'] for law in st.session_state.selected_laws 
                      if law['law_id'] not in collected]
        with st.expander("âŒ ìˆ˜ì§‘ ì‹¤íŒ¨í•œ ë²•ë ¹"):
            for law_name in failed_laws:
                st.write(f"- {law_name}")
    
    st.session_state.collected_laws = collected
    
    # í†µê³„ í‘œì‹œ
    display_collection_stats(collected)


def display_collection_stats(collected_laws: Dict[str, Dict[str, Any]]):
    """ìˆ˜ì§‘ í†µê³„ í‘œì‹œ - PDF í†µê³„ ì¶”ê°€"""
    total_articles = sum(len(law.get('articles', [])) for law in collected_laws.values())
    total_provisions = sum(len(law.get('supplementary_provisions', [])) for law in collected_laws.values())
    total_attachments = sum(len(law.get('attachments', [])) for law in collected_laws.values())
    admin_rule_count = sum(1 for law in collected_laws.values() if law.get('is_admin_rule', False))
    pdf_count = sum(len(law.get('attachment_pdfs', [])) for law in collected_laws.values())
    downloaded_pdf_count = sum(len(law.get('downloaded_pdfs', [])) for law in collected_laws.values())
    
    col1, col2, col3, col4, col5 = st.columns(5)
    with col1:
        st.metric("ì´ ì¡°ë¬¸", f"{total_articles:,}ê°œ")
    with col2:
        st.metric("ì´ ë¶€ì¹™", f"{total_provisions}ê°œ")
    with col3:
        st.metric("ì´ ë³„í‘œ/ë³„ì²¨", f"{total_attachments}ê°œ")
    with col4:
        st.metric("í–‰ì •ê·œì¹™", f"{admin_rule_count}ê°œ")
    with col5:
        if st.session_state.include_pdfs:
            st.metric("PDF ë‹¤ìš´ë¡œë“œ", f"{downloaded_pdf_count}/{pdf_count}ê°œ")
        else:
            st.metric("PDF ë°œê²¬", f"{pdf_count}ê°œ")


def display_download_section():
    """ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ í‘œì‹œ - ëª¨ë“  í˜•ì‹ ì§€ì›"""
    if not st.session_state.collected_laws:
        return
        
    st.header("ğŸ’¾ ë‹¤ìš´ë¡œë“œ")
    
    exporter = LawExporter()
    
    # ë‹¤ìš´ë¡œë“œ ì˜µì…˜
    st.subheader("ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì˜µì…˜")
    download_option = st.radio(
        "ë‹¤ìš´ë¡œë“œ ë°©ì‹ ì„ íƒ",
        ["ê°œë³„ íŒŒì¼ (ZIP)", "í†µí•© íŒŒì¼ (ë‹¨ì¼)"],
        help="ê°œë³„ íŒŒì¼: ê° ë²•ë ¹ë³„ë¡œ íŒŒì¼ ìƒì„±\ní†µí•© íŒŒì¼: ëª¨ë“  ë²•ë ¹ì„ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ"
    )
    
    if download_option == "ê°œë³„ íŒŒì¼ (ZIP)":
        # ZIP ë‹¤ìš´ë¡œë“œ
        include_pdfs_in_zip = False
        if st.session_state.include_pdfs:
            pdf_count = sum(len(law.get('downloaded_pdfs', [])) for law in st.session_state.collected_laws.values())
            if pdf_count > 0:
                include_pdfs_in_zip = st.checkbox(
                    f"ZIPì— PDF íŒŒì¼ í¬í•¨ ({pdf_count}ê°œ)",
                    value=True,
                    help="ë‹¤ìš´ë¡œë“œí•œ PDF íŒŒì¼ì„ ZIPì— í¬í•¨í•©ë‹ˆë‹¤"
                )
        
        zip_data = exporter.export_to_zip(
            st.session_state.collected_laws,
            include_pdfs=include_pdfs_in_zip
        )
        
        label = "ğŸ“¦ ZIP ë‹¤ìš´ë¡œë“œ (JSON+TXT+MD"
        if include_pdfs_in_zip:
            label += "+PDF)"
        else:
            label += ")"
        
        st.download_button(
            label=label,
            data=zip_data,
            file_name=f"laws_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
            mime="application/zip",
            use_container_width=True
        )
    else:
        # í†µí•© íŒŒì¼ - ëª…í™•í•œ í˜•ì‹ ì„ íƒ
        st.info("ğŸ“Œ ë‹¨ì¼ íŒŒì¼ë¡œ ëª¨ë“  ë²•ë ¹ì„ í†µí•©í•˜ì—¬ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.")
        
        # í˜•ì‹ë³„ ì„¤ëª… ì¶”ê°€
        format_descriptions = {
            "JSON": "êµ¬ì¡°í™”ëœ ë°ì´í„° í˜•ì‹ (í”„ë¡œê·¸ë˜ë° í™œìš©ì— ì í•©)",
            "Markdown": "ì½ê¸° ì‰¬ìš´ ë¬¸ì„œ í˜•ì‹ (GitHub, ë…¸ì…˜ ë“±ì— ì í•©)",
            "Text": "ìˆœìˆ˜ í…ìŠ¤íŠ¸ í˜•ì‹ (ë©”ëª¨ì¥ ë“±ì—ì„œ ì—´ê¸° ê°€ëŠ¥)"
        }
        
        file_format = st.selectbox(
            "íŒŒì¼ í˜•ì‹ ì„ íƒ",
            ["JSON", "Markdown", "Text"],
            help="ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ í˜•ì‹ì„ ì„ íƒí•˜ì„¸ìš”"
        )
        
        st.caption(f"ğŸ’¡ {format_descriptions[file_format]}")
        
        # í˜•ì‹ë³„ ë‚´ë³´ë‚´ê¸° ì²˜ë¦¬
        if file_format == "JSON":
            content = exporter.export_single_file(st.session_state.collected_laws, 'json')
            mime = "application/json"
            ext = "json"
        elif file_format == "Markdown":
            content = exporter.export_single_file(st.session_state.collected_laws, 'markdown')
            mime = "text/markdown"
            ext = "md"
        else:  # Text
            content = exporter.export_single_file(st.session_state.collected_laws, 'text')
            mime = "text/plain"
            ext = "txt"
        
        # íŒŒì¼ í¬ê¸° í‘œì‹œ
        file_size = len(content.encode('utf-8'))
        st.caption(f"ğŸ“Š ì˜ˆìƒ íŒŒì¼ í¬ê¸°: {file_size:,} bytes")
        
        st.download_button(
            label=f"ğŸ’¾ {file_format} í†µí•© íŒŒì¼ ë‹¤ìš´ë¡œë“œ (.{ext})",
            data=content,
            file_name=f"all_laws_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{ext}",
            mime=mime,
            use_container_width=True
        )
        
        # ë¯¸ë¦¬ë³´ê¸° ì˜µì…˜
        with st.expander("ğŸ“„ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 1000ì)"):
            st.text(content[:1000] + "..." if len(content) > 1000 else content)
    
    # ìˆ˜ì§‘ ê²°ê³¼ ìƒì„¸
    with st.expander("ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìƒì„¸"):
        for law_id, law in st.session_state.collected_laws.items():
            emoji = "ğŸ“‹" if law.get('is_admin_rule', False) else "ğŸ“–"
            st.subheader(f"{emoji} {law['law_name']}")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.write(f"ì¡°ë¬¸: {len(law.get('articles', []))}ê°œ")
            with col2:
                st.write(f"ë¶€ì¹™: {len(law.get('supplementary_provisions', []))}ê°œ")
            with col3:
                st.write(f"ë³„í‘œ: {len(law.get('attachments', []))}ê°œ")
            with col4:
                pdf_info = ""
                if law.get('attachment_pdfs'):
                    pdf_count = len(law.get('attachment_pdfs', []))
                    downloaded = len(law.get('downloaded_pdfs', []))
                    if downloaded > 0:
                        pdf_info = f"PDF: {downloaded}/{pdf_count}ê°œ âœ…"
                    else:
                        pdf_info = f"PDF: {pdf_count}ê°œ â³"
                    st.write(pdf_info)
            
            # ìƒ˜í”Œ ì¡°ë¬¸
            if law.get('articles'):
                st.write("**ìƒ˜í”Œ ì¡°ë¬¸:**")
                sample = law['articles'][0]
                st.text(f"{sample['number']} {sample.get('title', '')}")
                st.text(sample['content'][:200] + "...")
            
            # PDF ëª©ë¡
            if law.get('attachment_pdfs'):
                st.write("**PDF ì²¨ë¶€íŒŒì¼:**")
                for pdf in law['attachment_pdfs']:
                    status = "âœ…" if law.get('downloaded_pdfs') else "â³"
                    st.write(f"  - {pdf['file_name']} {status}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    initialize_session_state()
    
    # ì œëª©
    st.title("ğŸ“š ë²•ì œì²˜ ë²•ë ¹ ìˆ˜ì§‘ê¸°")
    st.markdown("ë²•ì œì²˜ Open APIë¥¼ í™œìš©í•œ ë²•ë ¹ ìˆ˜ì§‘ ë„êµ¬ (v6.6)")
    st.markdown("**âœ¨ ë²„ê·¸ ìˆ˜ì • ì™„ë£Œ: ë²•ë ¹ëª… ë¶„ë¦¬, ì¤‘ë³µ ì œê±°, PDF ë‹¤ìš´ë¡œë“œ ê°œì„ !**")
    
    # ì‚¬ì´ë“œë°”
    oc_code = show_sidebar()
    
    # ëª¨ë“œë³„ ì²˜ë¦¬
    if st.session_state.mode == 'direct':
        handle_direct_search_mode(oc_code)
    else:
        handle_file_upload_mode(oc_code)
    
    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
    if st.session_state.search_results:
        display_search_results_and_collect(oc_code)
    
    # ë‹¤ìš´ë¡œë“œ ì„¹ì…˜
    display_download_section()


if __name__ == "__main__":
    main()
