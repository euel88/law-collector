"""
ë²•ì œì²˜ ë²•ë ¹ ìˆ˜ì§‘ê¸° - ìµœì¢… í†µí•© ë²„ì „
ì§ì ‘ ê²€ìƒ‰ + íŒŒì¼ ì—…ë¡œë“œ + ê°œì„ ëœ ë²•ë ¹ëª… ì¶”ì¶œ
"""

import streamlit as st
import requests
import xml.etree.ElementTree as ET
import json
import time
import re
from datetime import datetime
from io import BytesIO
import base64
import urllib3
import zipfile
import pandas as pd
import openpyxl
import PyPDF2
import pdfplumber
from typing import List, Set, Dict, Optional, Tuple, Any

# SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë²•ì œì²˜ ë²•ë ¹ ìˆ˜ì§‘ê¸°",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'mode' not in st.session_state:
    st.session_state.mode = 'direct'  # 'direct' or 'file'
if 'extracted_laws' not in st.session_state:
    st.session_state.extracted_laws = []
if 'search_results' not in st.session_state:
    st.session_state.search_results = []
if 'selected_laws' not in st.session_state:
    st.session_state.selected_laws = []
if 'collected_laws' not in st.session_state:
    st.session_state.collected_laws = {}
if 'file_processed' not in st.session_state:
    st.session_state.file_processed = False
if 'openai_api_key' not in st.session_state:
    st.session_state.openai_api_key = None
if 'use_ai' not in st.session_state:
    st.session_state.use_ai = False


class EnhancedLawFileExtractor:
    """ê°œì„ ëœ íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œí•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        # ì œì™¸í•  í‚¤ì›Œë“œ (ì¹´í…Œê³ ë¦¬, ì„¤ëª… ë“±)
        self.exclude_keywords = [
            'ìƒí•˜ìœ„ë²•', 'í–‰ì •ê·œì¹™', 'ë²•ë ¹', 'ì‹œí–‰ë ¹', 'ì‹œí–‰ê·œì¹™', 'ëŒ€í†µë ¹ë ¹', 
            'ì´ë¦¬ë ¹', 'ë¶€ë ¹', 'ê´€í•œ ê·œì •', 'ìƒìœ„ë²•', 'í•˜ìœ„ë²•', 'ê´€ë ¨ë²•ë ¹'
        ]
        
        # ê°œì„ ëœ ë²•ë ¹ëª… íŒ¨í„´ - í–‰ì •ê·œì¹™ ìš°ì„  ë°°ì¹˜
        self.law_patterns = [
            # ì‹œí–‰ ë‚ ì§œ íŒ¨í„´ì„ ëª¨ë“  íŒ¨í„´ì— í¬í•¨
            # íŒ¨í„´ 0: ë²•ë¥ ëª… + ì‹œí–‰ ì •ë³´ê°€ í•¨ê»˜ ìˆëŠ” ê²½ìš° (ìµœìš°ì„ )
            r'([ê°€-í£]+(?:\s+[ê°€-í£]+)*(?:ë²•|ë²•ë¥ |ê·œì •|ê·œì¹™|ì„¸ì¹™|ë¶„ë¥˜))\s*\[ì‹œí–‰\s*\d{4}\.\s*\d{1,2}\.\s*\d{1,2}\.\]',
            
            # íŒ¨í„´ 1: ë…ë¦½ì ì¸ ê·œì •/ì„¸ì¹™ (í–‰ì •ê·œì¹™) 
            r'^([ê°€-í£]+(?:(?:\s+ë°\s+)|(?:\s+))?[ê°€-í£]*(?:ì—\s*ê´€í•œ\s*)?(?:ê·œì •|ì—…ë¬´ê·œì •|ê°ë…ê·œì •|ìš´ì˜ê·œì •|ê´€ë¦¬ê·œì •))(?:\s|$)',
            
            # íŒ¨í„´ 2: ì‹œí–‰ì„¸ì¹™ (ë…ë¦½ì )
            r'^([ê°€-í£]+(?:(?:\s+ë°\s+)|(?:\s+))?[ê°€-í£]*(?:ì—…ë¬´)?ì‹œí–‰ì„¸ì¹™)(?:\s|$)',
            
            # íŒ¨í„´ 3: ë¶™ì–´ìˆëŠ” í˜•íƒœì˜ ê·œì • ì²˜ë¦¬
            r'([ê°€-í£]+(?:ê²€ì‚¬ë°ì œì¬ì—ê´€í•œ|ì—ê´€í•œ)?ê·œì •)(?:\s|$)',
            
            # íŒ¨í„´ 4: ì¼ë°˜ì ì¸ ë²•ë¥ ëª… 
            r'^([ê°€-í£]+(?:\s+[ê°€-í£]+)*(?:ì—\s*ê´€í•œ\s*)?(?:íŠ¹ë³„|ê¸°ë³¸|ê´€ë¦¬|ì´‰ì§„|ì§€ì›|ìœ¡ì„±|ì§„í¥|ë³´í˜¸|ê·œì œ|ë°©ì§€)?ë²•(?:ë¥ )?)(?:\s|$)',
            
            # íŒ¨í„´ 5: ì‹œí–‰ë ¹ 
            r'^([ê°€-í£]+(?:\s+[ê°€-í£]+)*ë²•(?:ë¥ )?)\s+ì‹œí–‰ë ¹(?:\s|$)',
            
            # íŒ¨í„´ 6: ì‹œí–‰ê·œì¹™ 
            r'^([ê°€-í£]+(?:\s+[ê°€-í£]+)*ë²•(?:ë¥ )?)\s+ì‹œí–‰ê·œì¹™(?:\s|$)',
            
            # íŒ¨í„´ 7: ê·œì • + ì‹œí–‰ì„¸ì¹™ ì¡°í•©
            r'^([ê°€-í£]+(?:\s+[ê°€-í£]+)*(?:ì—\s*ê´€í•œ\s*)?ê·œì •\s+ì‹œí–‰ì„¸ì¹™)(?:\s|$)',
            
            # íŒ¨í„´ 8: ë¶„ë¥˜ (í•œêµ­í‘œì¤€ì‚°ì—…ë¶„ë¥˜ ë“±)
            r'^([ê°€-í£]+(?:\s+[ê°€-í£]+)*ë¶„ë¥˜)(?:\s|$)',
            
            # íŒ¨í„´ 9: ê³ ì‹œ, í›ˆë ¹, ì˜ˆê·œ
            r'^([ê°€-í£]+(?:\s+[ê°€-í£]+)*(?:ì—\s*ê´€í•œ\s*)?(?:ê³ ì‹œ|í›ˆë ¹|ì˜ˆê·œ|ì§€ì¹¨))(?:\s|$)',
        ]
        
        # AI ì„¤ì • í™•ì¸
        self.use_ai = st.session_state.get('use_ai', False)
        self.api_key = st.session_state.get('openai_api_key', None)
        
    def extract_from_pdf(self, file) -> List[str]:
        """PDF íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ - ê°œì„ ëœ ë²„ì „"""
        all_text = ""
        
        try:
            # pdfplumberë¡œ ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            with pdfplumber.open(file) as pdf:
                for page in pdf.pages:
                    text = page.extract_text()
                    if text:
                        all_text += text + "\n"
        except:
            # ì‹¤íŒ¨ ì‹œ PyPDF2ë¡œ ì‹œë„
            try:
                file.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
                pdf_reader = PyPDF2.PdfReader(file)
                for page in pdf_reader.pages:
                    text = page.extract_text()
                    all_text += text + "\n"
            except Exception as e:
                st.error(f"PDF ì½ê¸° ì˜¤ë¥˜: {str(e)}")
                return []
        
        # ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ - ê°œì„ ëœ ë¡œì§
        laws = self._extract_laws_from_pdf_structure(all_text)
        
        # AI ê¸°ë°˜ ì¶”ì¶œì´ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì‚¬ìš©
        if self.use_ai and self.api_key:
            laws = self._enhance_with_ai(all_text, laws)
        
        return sorted(list(laws))
    
    def _enhance_with_ai(self, text: str, initial_laws: Set[str]) -> Set[str]:
        """ChatGPT APIë¥¼ í™œìš©í•œ ë²•ë ¹ëª… ì¶”ì¶œ ê°œì„ """
        try:
            import openai
            openai.api_key = self.api_key
            
            # í…ìŠ¤íŠ¸ ìƒ˜í”Œ (í† í° ì œí•œì„ ìœ„í•´ 2000ìë¡œ ì œí•œ)
            sample_text = text[:2000]
            
            prompt = f"""ë‹¤ìŒì€ ë²•ë ¹ ê´€ë ¨ PDFì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
ì´ í…ìŠ¤íŠ¸ì—ì„œ ì‹¤ì œ ë²•ë ¹ëª…ë§Œ ì •í™•íˆ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ì¤‘ìš”í•œ ê·œì¹™:
1. "ìƒí•˜ìœ„ë²•", "í–‰ì •ê·œì¹™", "ê´€ë ¨ë²•ë ¹" ê°™ì€ ì¹´í…Œê³ ë¦¬ëŠ” ì œì™¸í•˜ì„¸ìš”
2. ë²•ë ¹ëª…ì€ ì™„ì „í•œ í˜•íƒœë¡œ ì¶”ì¶œí•˜ì„¸ìš” (ì˜ˆ: "ê¸ˆìœµê¸°ê´€ ê²€ì‚¬ ë° ì œì¬ì— ê´€í•œ ê·œì •")
3. ì‹œí–‰ë ¹, ì‹œí–‰ê·œì¹™ì€ ê¸°ë³¸ ë²•ë¥ ê³¼ ë³„ë„ë¡œ êµ¬ë¶„í•˜ì„¸ìš”
4. ì¤‘ë³µì€ ì œê±°í•˜ì„¸ìš”
5. ì‹œí–‰ ë‚ ì§œ ì •ë³´ëŠ” ì œì™¸í•˜ì„¸ìš”

í…ìŠ¤íŠ¸:
{sample_text}

í˜„ì¬ ì¶”ì¶œëœ ë²•ë ¹ëª…:
{', '.join(list(initial_laws)[:10])}

ì •í™•í•œ ë²•ë ¹ëª…ì„ í•œ ì¤„ì— í•˜ë‚˜ì”© ì¶œë ¥í•˜ì„¸ìš”:"""
            
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ ë²•ë ¹ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë²•ë ¹ëª…ì„ ì •í™•íˆ ì‹ë³„í•˜ê³  ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=800
            )
            
            # AI ì‘ë‹µ íŒŒì‹±
            ai_laws = set()
            ai_response = response.choices[0].message.content.strip()
            
            for line in ai_response.split('\n'):
                line = line.strip()
                
                # ë²ˆí˜¸ë‚˜ ê¸°í˜¸ ì œê±°
                line = re.sub(r'^[\d\-\.\*\â€¢]+\s*', '', line)
                
                if line and self._is_valid_law_name(line):
                    ai_laws.add(line)
            
            # ê¸°ì¡´ ê²°ê³¼ì™€ AI ê²°ê³¼ ë³‘í•©
            if ai_laws:
                st.info(f"ğŸ¤– AIê°€ {len(ai_laws)}ê°œì˜ ë²•ë ¹ëª…ì„ ì¶”ê°€ë¡œ ë°œê²¬í–ˆìŠµë‹ˆë‹¤")
                return initial_laws.union(ai_laws)
            else:
                return initial_laws
                
        except ImportError:
            st.warning("âš ï¸ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í„°ë¯¸ë„ì—ì„œ 'pip install openai' ëª…ë ¹ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return initial_laws
        except Exception as e:
            st.warning(f"âš ï¸ AI ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return initial_laws
    
    def _extract_laws_from_text(self, text: str) -> Set[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ - ê°œì„ ëœ ë²„ì „"""
        laws = set()
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        # 1. ì—¬ëŸ¬ ì¤„ì— ê±¸ì³ ìˆëŠ” ë²•ë ¹ëª… ì²˜ë¦¬ë¥¼ ìœ„í•´ ë¶ˆí•„ìš”í•œ ì¤„ë°”ê¿ˆ ì œê±°
        text = self._preprocess_text(text)
        
        # ì¹´í…Œê³ ë¦¬ì™€ ë²•ë ¹ëª… ë¶„ë¦¬ë¥¼ ìœ„í•œ ì „ì²˜ë¦¬
        # "ìƒí•˜ìœ„ë²•", "í–‰ì •ê·œì¹™" ê°™ì€ ì¹´í…Œê³ ë¦¬ ì œê±°
        text = self._remove_categories(text)
        
        # 2. ëª¨ë“  íŒ¨í„´ìœ¼ë¡œ ë²•ë ¹ëª… ì¶”ì¶œ
        for pattern in self.law_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)
            for match in matches:
                law_name = self._clean_law_name(match)
                if self._is_valid_law_name(law_name):
                    laws.add(law_name)
        
        # 3. íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ì²˜ë¦¬ (í•©ì„±ì–´)
        laws.update(self._extract_compound_laws(text))
        
        # 4. ì¶”ê°€: ë¶™ì–´ìˆëŠ” í˜•íƒœì˜ í–‰ì •ê·œì¹™ ì²˜ë¦¬
        laws.update(self._extract_attached_regulations(text))
        
        # 5. ì¤‘ë³µ ë° ë¶€ë¶„ ë¬¸ìì—´ ì œê±°
        laws = self._remove_duplicates_and_substrings(laws)
        
        return laws
    
    def _preprocess_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        text = re.sub(r'\s+', ' ', text)
        
        # íŠ¹ì • íŒ¨í„´ ì‚¬ì´ì˜ ì¤„ë°”ê¿ˆ ì œê±° (ë²•ë ¹ëª…ì´ ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬ëœ ê²½ìš°)
        # ì˜ˆ: "ê¸ˆìœµê¸°ê´€\nê²€ì‚¬ ë° ì œì¬ì— ê´€í•œ ê·œì •"
        text = re.sub(r'([ê°€-í£]+)\s*\n\s*([ê°€-í£]+(?:\s+ë°\s+)?[ê°€-í£]*(?:ì—\s*ê´€í•œ)?)', r'\1 \2', text)
        
        # "ë°" ì£¼ë³€ì˜ ê³µë°± ì •ê·œí™”
        text = re.sub(r'\s*ë°\s*', ' ë° ', text)
        
        return text
    
    def _remove_categories(self, text: str) -> str:
        """ì¹´í…Œê³ ë¦¬ ë ˆì´ë¸” ì œê±°"""
        # ì¹´í…Œê³ ë¦¬ íŒ¨í„´ (ì¤„ì˜ ì‹œì‘ì´ë‚˜ ëì— ìˆëŠ” ì¹´í…Œê³ ë¦¬)
        categories = ['ìƒí•˜ìœ„ë²•', 'í–‰ì •ê·œì¹™', 'ê´€ë ¨ë²•ë ¹', 'ë²•ë ¹']
        
        # ê° ì¹´í…Œê³ ë¦¬ë¥¼ ì œê±°
        for category in categories:
            # ë…ë¦½ëœ ë¼ì¸ì— ìˆëŠ” ì¹´í…Œê³ ë¦¬ ì œê±°
            text = re.sub(rf'^\s*{category}\s*$', '', text, flags=re.MULTILINE)
            # ë²•ë ¹ëª… ì•ì— ë¶™ì€ ì¹´í…Œê³ ë¦¬ ì œê±°
            text = re.sub(rf'{category}\s+([ê°€-í£]+)', r'\1', text)
            # ë²•ë ¹ëª… ë’¤ì— ë¶™ì€ ì¹´í…Œê³ ë¦¬ ì œê±° 
            text = re.sub(rf'([ê°€-í£]+)\s+{category}\s+([ê°€-í£]+)', r'\1 \2', text)
        
        return text
    
    def _extract_laws_from_pdf_structure(self, text: str) -> Set[str]:
        """PDF êµ¬ì¡°ë¥¼ ê³ ë ¤í•œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        laws = set()
        
        # ì¤„ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        lines = text.split('\n')
        
        # ì‹œí–‰ ë‚ ì§œ íŒ¨í„´ ì •ì˜
        date_pattern = r'\[ì‹œí–‰\s*\d{4}\.\s*\d{1,2}\.\s*\d{1,2}\.\]'
        
        for i, line in enumerate(lines):
            line = line.strip()
            
            # ì‹œí–‰ ë‚ ì§œê°€ í¬í•¨ëœ ë¼ì¸ì€ ë²•ë ¹ëª…ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
            if re.search(date_pattern, line):
                # ì‹œí–‰ ë‚ ì§œ ì•ë¶€ë¶„ ì¶”ì¶œ
                law_match = re.match(r'(.+?)\s*\[ì‹œí–‰', line)
                if law_match:
                    law_name = law_match.group(1).strip()
                    
                    # ì¹´í…Œê³ ë¦¬ ì œê±°
                    categories = ['ìƒí•˜ìœ„ë²•', 'í–‰ì •ê·œì¹™', 'ê´€ë ¨ë²•ë ¹', 'ë²•ë ¹']
                    for cat in categories:
                        law_name = law_name.replace(cat, '').strip()
                    
                    if self._is_valid_law_name(law_name):
                        laws.add(law_name)
            
            # ì‹œí–‰ ë‚ ì§œê°€ ì—†ëŠ” ê²½ìš° ê¸°ì¡´ íŒ¨í„´ ì‚¬ìš©
            else:
                # ì¹´í…Œê³ ë¦¬ ë¼ì¸ ìŠ¤í‚µ
                if line in ['ìƒí•˜ìœ„ë²•', 'í–‰ì •ê·œì¹™', 'ê´€ë ¨ë²•ë ¹', 'ë²•ë ¹']:
                    continue
                
                # ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ
                processed_line = self._preprocess_text(line)
                line_laws = self._extract_from_line(processed_line)
                laws.update(line_laws)
        
        # ì¤‘ë³µ ì œê±°
        return self._remove_duplicates_and_substrings(laws)
    
    def _extract_from_line(self, line: str) -> Set[str]:
        """í•œ ì¤„ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        laws = set()
        
        for pattern in self.law_patterns:
            matches = re.findall(pattern, line, re.IGNORECASE)
            for match in matches:
                law_name = self._clean_law_name(match)
                if self._is_valid_law_name(law_name):
                    laws.add(law_name)
        
        return laws
    
    def _extract_attached_regulations(self, text: str) -> Set[str]:
        """ë¶™ì–´ìˆëŠ” í˜•íƒœì˜ í–‰ì •ê·œì¹™ ì¶”ì¶œ"""
        attached_laws = set()
        
        # íŠ¹ë³„ íŒ¨í„´ë“¤ (ë„ì–´ì“°ê¸° ì—†ì´ ë¶™ì–´ìˆëŠ” ê²½ìš°)
        special_patterns = [
            r'ê¸ˆìœµê¸°ê´€ê²€ì‚¬ë°ì œì¬ì—ê´€í•œê·œì •',
            r'ì—¬ì‹ ì „ë¬¸ê¸ˆìœµì—…ê°ë…ê·œì •',
            r'ì—¬ì‹ ì „ë¬¸ê¸ˆìœµì—…ê°ë…ì—…ë¬´ì‹œí–‰ì„¸ì¹™',
            r'[ê°€-í£]+ê²€ì‚¬ë°[ê°€-í£]+ì—ê´€í•œê·œì •',
            r'[ê°€-í£]+ê°ë…ì—…ë¬´ì‹œí–‰ì„¸ì¹™'
        ]
        
        for pattern in special_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                # ë„ì–´ì“°ê¸° ì¶”ê°€í•˜ì—¬ ì •ê·œí™”
                normalized = match
                normalized = re.sub(r'ê²€ì‚¬ë°', 'ê²€ì‚¬ ë° ', normalized)
                normalized = re.sub(r'ì—ê´€í•œ', 'ì— ê´€í•œ ', normalized)
                normalized = re.sub(r'ì—…ë¬´ì‹œí–‰', 'ì—…ë¬´ ì‹œí–‰', normalized)
                
                attached_laws.add(self._clean_law_name(normalized))
        
        return attached_laws
    
    def _clean_law_name(self, law_name: str) -> str:
        """ë²•ë ¹ëª… ì •ì œ"""
        # ë¬¸ìì—´ì¸ì§€ í™•ì¸
        if not isinstance(law_name, str):
            law_name = str(law_name)
        
        # ì‹œí–‰ ì •ë³´ ì œê±°
        law_name = re.sub(r'\s*\[ì‹œí–‰[^\]]+\]', '', law_name)
        
        # ì•ë’¤ ê³µë°± ì œê±°
        law_name = law_name.strip()
        
        # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        law_name = ' '.join(law_name.split())
        
        # ë¶™ì–´ìˆëŠ” í˜•íƒœ ì •ê·œí™”
        law_name = re.sub(r'ê²€ì‚¬ë°', 'ê²€ì‚¬ ë° ', law_name)
        law_name = re.sub(r'ì—ê´€í•œ', 'ì— ê´€í•œ ', law_name)
        
        return law_name
    
    def _is_valid_law_name(self, law_name: str) -> bool:
        """ìœ íš¨í•œ ë²•ë ¹ëª…ì¸ì§€ ê²€ì¦"""
        # ì œì™¸ í‚¤ì›Œë“œ ì²´í¬ (ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê²½ìš°ë§Œ)
        if law_name in self.exclude_keywords:
            return False
        
        # ë„ˆë¬´ ì§§ì€ ê²ƒ ì œì™¸ (ìµœì†Œ 3ì ì´ìƒ)
        if len(law_name) < 3:
            return False
        
        # ìµœì†Œ 2ê¸€ì ì´ìƒì˜ í•œê¸€ì´ ìˆì–´ì•¼ í•¨
        korean_chars = re.findall(r'[ê°€-í£]+', law_name)
        if not korean_chars or max(len(k) for k in korean_chars) < 2:
            return False
        
        # ë²•ë ¹ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆì–´ì•¼ í•¨ - í™•ì¥ëœ í‚¤ì›Œë“œ ëª©ë¡
        law_keywords = ['ë²•', 'ë ¹', 'ê·œì¹™', 'ê·œì •', 'ê³ ì‹œ', 'í›ˆë ¹', 'ì˜ˆê·œ', 'ì§€ì¹¨', 'ì„¸ì¹™', 'ë¶„ë¥˜', 'ì—…ë¬´ê·œì •', 'ê°ë…ê·œì •']
        if not any(keyword in law_name for keyword in law_keywords):
            return False
        
        return True
    
    def _extract_compound_laws(self, text: str) -> Set[str]:
        """í•©ì„± ë²•ë ¹ëª… ì¶”ì¶œ (ì‹œí–‰ë ¹, ì‹œí–‰ê·œì¹™ì´ ë”°ë¡œ í‘œì‹œëœ ê²½ìš°)"""
        compound_laws = set()
        
        # íŒ¨í„´: "ë²•ë¥ ëª…" ë‹¤ìŒ ì¤„ì— "ì‹œí–‰ë ¹" ë˜ëŠ” "ì‹œí–‰ê·œì¹™"ì´ ì˜¤ëŠ” ê²½ìš°
        base_law_pattern = r'([ê°€-í£]+(?:\s+[ê°€-í£]+)*ë²•(?:ë¥ )?)\s*(?:\[ì‹œí–‰[^\]]+\])?\s*\n'
        
        matches = re.finditer(base_law_pattern, text)
        for match in matches:
            base_law = self._clean_law_name(match.group(1))
            
            # ë‹¤ìŒ ëª‡ ì¤„ì—ì„œ ì‹œí–‰ë ¹/ì‹œí–‰ê·œì¹™ ì°¾ê¸°
            next_text = text[match.end():match.end() + 200]  # ë‹¤ìŒ 200ì í™•ì¸
            
            # ì‹œí–‰ë ¹ ì°¾ê¸°
            if f"{base_law} ì‹œí–‰ë ¹" in next_text or f"{base_law}ì‹œí–‰ë ¹" in next_text:
                compound_laws.add(f"{base_law} ì‹œí–‰ë ¹")
            
            # ì‹œí–‰ê·œì¹™ ì°¾ê¸°
            if f"{base_law} ì‹œí–‰ê·œì¹™" in next_text or f"{base_law}ì‹œí–‰ê·œì¹™" in next_text:
                compound_laws.add(f"{base_law} ì‹œí–‰ê·œì¹™")
        
        return compound_laws
    
    def _remove_duplicates_and_substrings(self, laws: Set[str]) -> Set[str]:
        """ì¤‘ë³µ ë° ë¶€ë¶„ ë¬¸ìì—´ ì œê±°"""
        laws_list = sorted(list(laws), key=len, reverse=True)  # ê¸´ ê²ƒë¶€í„° ì •ë ¬
        final_laws = []
        
        for law in laws_list:
            # ì´ë¯¸ ì¶”ê°€ëœ ë²•ë ¹ì˜ ë¶€ë¶„ ë¬¸ìì—´ì¸ì§€ í™•ì¸
            is_substring = False
            for existing_law in final_laws:
                if law in existing_law and law != existing_law:
                    is_substring = True
                    break
            
            # ë„ˆë¬´ ì§§ê±°ë‚˜ ì¼ë°˜ì ì¸ ìš©ì–´ëŠ” ì œì™¸
            if len(law) < 5 and law in ['ê·œì •', 'ì„¸ì¹™', 'ì‹œí–‰ë ¹', 'ì‹œí–‰ê·œì¹™']:
                continue
                
            if not is_substring:
                final_laws.append(law)
        
        return set(final_laws)
    
    def extract_from_excel(self, file) -> List[str]:
        """Excel íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        laws = set()
        
        try:
            excel_file = pd.ExcelFile(file)
            
            for sheet_name in excel_file.sheet_names:
                df = pd.read_excel(file, sheet_name=sheet_name)
                
                # ëª¨ë“  ì…€ì˜ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹¨
                all_text = ""
                for column in df.columns:
                    for value in df[column].dropna():
                        if isinstance(value, str):
                            all_text += value + "\n"
                
                # ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ
                laws.update(self._extract_laws_from_text(all_text))
                
        except Exception as e:
            st.error(f"Excel ì½ê¸° ì˜¤ë¥˜: {str(e)}")
        
        return sorted(list(laws))
    
    def extract_from_markdown(self, file) -> List[str]:
        """Markdown íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        laws = set()
        
        try:
            content = file.read().decode('utf-8')
            laws.update(self._extract_laws_from_text(content))
        except Exception as e:
            st.error(f"Markdown ì½ê¸° ì˜¤ë¥˜: {str(e)}")
        
        return sorted(list(laws))
    
    def extract_from_text(self, file) -> List[str]:
        """í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        laws = set()
        
        try:
            content = file.read().decode('utf-8')
            laws.update(self._extract_laws_from_text(content))
        except Exception as e:
            st.error(f"í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
        
        return sorted(list(laws))


class LawCollectorAPI:
    """ë²•ë ¹ ìˆ˜ì§‘ API í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.law_search_url = "http://www.law.go.kr/DRF/lawSearch.do"
        self.law_detail_url = "http://www.law.go.kr/DRF/lawService.do"
        self.delay = 0.5  # API í˜¸ì¶œ ê°„ê²©
        
    def search_law(self, oc_code: str, law_name: str) -> List[Dict[str, Any]]:
        """ë²•ë ¹ ê²€ìƒ‰"""
        params = {
            'OC': oc_code,
            'target': 'law',
            'type': 'XML',
            'query': law_name,
            'display': '100',
            'page': '1'
        }
        
        try:
            response = requests.get(
                self.law_search_url, 
                params=params, 
                timeout=10,
                verify=False
            )
            response.encoding = 'utf-8'
            
            if response.status_code != 200:
                return []
            
            content = response.text
            
            # BOM ì œê±°
            if content.startswith('\ufeff'):
                content = content[1:]
            
            # XML íŒŒì‹±
            root = ET.fromstring(content.encode('utf-8'))
            laws = []
            
            for law_elem in root.findall('.//law'):
                law_id = law_elem.findtext('ë²•ë ¹ID', '')
                law_name_full = law_elem.findtext('ë²•ë ¹ëª…í•œê¸€', '')
                law_msn = law_elem.findtext('ë²•ë ¹ì¼ë ¨ë²ˆí˜¸', '')
                
                if law_id and law_name_full:
                    law_info = {
                        'law_id': law_id,
                        'law_msn': law_msn,
                        'law_name': law_name_full,
                        'law_type': law_elem.findtext('ë²•ì¢…êµ¬ë¶„', ''),
                        'promulgation_date': law_elem.findtext('ê³µí¬ì¼ì', ''),
                        'enforcement_date': law_elem.findtext('ì‹œí–‰ì¼ì', ''),
                    }
                    laws.append(law_info)
            
            return laws
            
        except Exception as e:
            st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def get_law_detail_with_full_content(self, oc_code: str, law_id: str, law_msn: str, law_name: str) -> Optional[Dict[str, Any]]:
        """ë²•ë ¹ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ - ì¡°ë¬¸, ë¶€ì¹™, ë³„í‘œ ëª¨ë‘ í¬í•¨"""
        params = {
            'OC': oc_code,
            'target': 'law',
            'type': 'XML',
            'MST': law_msn,
            'mobileYn': 'N'
        }
        
        try:
            response = requests.get(
                self.law_detail_url,
                params=params,
                timeout=30,  # íƒ€ì„ì•„ì›ƒ ì¦ê°€
                verify=False
            )
            response.encoding = 'utf-8'
            
            if response.status_code != 200:
                st.warning(f"{law_name} ìƒì„¸ ì •ë³´ ì ‘ê·¼ ì‹¤íŒ¨")
                return None
            
            content = response.text
            
            # BOM ì œê±°
            if content.startswith('\ufeff'):
                content = content[1:]
            
            try:
                root = ET.fromstring(content.encode('utf-8'))
            except ET.ParseError:
                st.warning(f"{law_name} XML íŒŒì‹± ì˜¤ë¥˜")
                return None
            
            # ë²•ë ¹ ì •ë³´ êµ¬ì¡°
            law_detail = {
                'law_id': law_id,
                'law_msn': law_msn,
                'law_name': law_name,
                'law_type': '',
                'promulgation_date': '',
                'enforcement_date': '',
                'articles': [],          # ì¡°ë¬¸
                'supplementary_provisions': [],  # ë¶€ì¹™
                'attachments': [],       # ë³„í‘œ/ë³„ì²¨
                'raw_content': '',       # ì „ì²´ ì›ë¬¸
            }
            
            # ê¸°ë³¸ ì •ë³´
            basic_info = root.find('.//ê¸°ë³¸ì •ë³´')
            if basic_info is not None:
                law_detail['law_type'] = basic_info.findtext('ë²•ì¢…êµ¬ë¶„ëª…', '')
                law_detail['promulgation_date'] = basic_info.findtext('ê³µí¬ì¼ì', '')
                law_detail['enforcement_date'] = basic_info.findtext('ì‹œí–‰ì¼ì', '')
            
            # ì „ì²´ ì¡°ë¬¸ ì¶”ì¶œ - ë‹¤ì–‘í•œ ë°©ë²• ì‹œë„
            self._extract_all_articles(root, law_detail)
            
            # ë¶€ì¹™ ì¶”ì¶œ
            self._extract_supplementary_provisions(root, law_detail)
            
            # ë³„í‘œ/ë³„ì²¨ ì¶”ì¶œ
            self._extract_attachments(root, law_detail)
            
            # ì „ì²´ ì›ë¬¸ ì¶”ì¶œ (í´ë°±)
            if not law_detail['articles']:
                law_detail['raw_content'] = self._extract_full_text(root)
            
            return law_detail
            
        except Exception as e:
            st.warning(f"{law_name} ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _extract_all_articles(self, root: ET.Element, law_detail: Dict[str, Any]) -> None:
        """ëª¨ë“  ì¡°ë¬¸ ì¶”ì¶œ - ê°•í™”ëœ ë²„ì „"""
        # ë°©ë²• 1: ì¡°ë¬¸ íƒœê·¸ ì§ì ‘ ì°¾ê¸°
        articles_section = root.find('.//ì¡°ë¬¸')
        if articles_section is not None:
            # ì¡°ë¬¸ë‹¨ìœ„ ì°¾ê¸°
            for article_unit in articles_section.findall('.//ì¡°ë¬¸ë‹¨ìœ„'):
                article_info = self._parse_article_unit(article_unit)
                if article_info:
                    law_detail['articles'].append(article_info)
        
        # ë°©ë²• 2: ì¡°ë¬¸ë‚´ìš© ì§ì ‘ ì°¾ê¸°
        if not law_detail['articles']:
            for article_content in root.findall('.//ì¡°ë¬¸ë‚´ìš©'):
                if article_content.text:
                    article_info = self._parse_article_text(article_content.text)
                    if article_info:
                        law_detail['articles'].append(article_info)
        
        # ë°©ë²• 3: ì „ì²´ ìš”ì†Œ ìˆœíšŒ
        if not law_detail['articles']:
            article_elements = []
            for elem in root.iter():
                if elem.tag in ['ì¡°', 'ì¡°ë¬¸', 'article', 'ì¡°ë¬¸ë‹¨ìœ„']:
                    article_elements.append(elem)
            
            for elem in article_elements:
                article_info = self._extract_article_from_element(elem)
                if article_info and article_info['content']:
                    law_detail['articles'].append(article_info)
    
    def _parse_article_unit(self, article_elem: ET.Element) -> Optional[Dict[str, Any]]:
        """ì¡°ë¬¸ë‹¨ìœ„ íŒŒì‹±"""
        article_info = {
            'number': '',
            'title': '',
            'content': '',
            'paragraphs': []
        }
        
        # ì¡°ë¬¸ë²ˆí˜¸
        article_num = article_elem.findtext('ì¡°ë¬¸ë²ˆí˜¸', '')
        if article_num:
            article_info['number'] = f"ì œ{article_num}ì¡°"
        
        # ì¡°ë¬¸ì œëª©
        article_info['title'] = article_elem.findtext('ì¡°ë¬¸ì œëª©', '')
        
        # ì¡°ë¬¸ë‚´ìš©
        article_content = article_elem.findtext('ì¡°ë¬¸ë‚´ìš©', '')
        if not article_content:
            # ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            article_content = self._get_all_text(article_elem)
        
        article_info['content'] = article_content
        
        # í•­ ì¶”ì¶œ
        for para in article_elem.findall('.//í•­'):
            para_info = {
                'number': para.findtext('í•­ë²ˆí˜¸', ''),
                'content': para.findtext('í•­ë‚´ìš©', '')
            }
            if para_info['content']:
                article_info['paragraphs'].append(para_info)
        
        return article_info if (article_info['number'] or article_info['content']) else None
    
    def _parse_article_text(self, text: str) -> Optional[Dict[str, Any]]:
        """ì¡°ë¬¸ í…ìŠ¤íŠ¸ íŒŒì‹±"""
        # ì œ1ì¡°, ì œ2ì¡° ë“±ì˜ íŒ¨í„´ ì°¾ê¸°
        pattern = r'(ì œ\d+ì¡°(?:ì˜\d+)?)\s*(?:\((.*?)\))?\s*(.*?)(?=ì œ\d+ì¡°|$)'
        matches = re.findall(pattern, text, re.DOTALL)
        
        if not matches:
            return None
            
        # ì²« ë²ˆì§¸ ë§¤ì¹˜ë§Œ ë°˜í™˜ (ì—¬ëŸ¬ ê°œì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì • í•„ìš”)
        match = matches[0]
        article_info = {
            'number': match[0],
            'title': match[1],
            'content': match[2].strip(),
            'paragraphs': []
        }
        
        # í•­ ë¶„ë¦¬ (â‘ , â‘¡, ... íŒ¨í„´)
        para_pattern = r'([â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]+)\s*(.*?)(?=[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]|$)'
        para_matches = re.findall(para_pattern, article_info['content'], re.DOTALL)
        
        for para_match in para_matches:
            article_info['paragraphs'].append({
                'number': para_match[0],
                'content': para_match[1].strip()
            })
        
        return article_info
    
    def _extract_article_from_element(self, elem: ET.Element) -> Dict[str, Any]:
        """ìš”ì†Œì—ì„œ ì¡°ë¬¸ ì •ë³´ ì¶”ì¶œ"""
        article_info = {
            'number': '',
            'title': '',
            'content': '',
            'paragraphs': []
        }
        
        # ì¡°ë¬¸ë²ˆí˜¸ ì°¾ê¸°
        for tag in ['ì¡°ë¬¸ë²ˆí˜¸', 'ì¡°ë²ˆí˜¸', 'ë²ˆí˜¸']:
            num = elem.findtext(tag, '')
            if num:
                article_info['number'] = f"ì œ{num}ì¡°" if not num.startswith('ì œ') else num
                break
        
        # ì¡°ë¬¸ì œëª© ì°¾ê¸°
        for tag in ['ì¡°ë¬¸ì œëª©', 'ì¡°ì œëª©', 'ì œëª©']:
            title = elem.findtext(tag, '')
            if title:
                article_info['title'] = title
                break
        
        # ì¡°ë¬¸ë‚´ìš© ì°¾ê¸°
        for tag in ['ì¡°ë¬¸ë‚´ìš©', 'ì¡°ë‚´ìš©', 'ë‚´ìš©']:
            content = elem.findtext(tag, '')
            if content:
                article_info['content'] = content
                break
        
        # ë‚´ìš©ì´ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸
        if not article_info['content']:
            article_info['content'] = self._get_all_text(elem)
        
        return article_info
    
    def _extract_supplementary_provisions(self, root: ET.Element, law_detail: Dict[str, Any]) -> None:
        """ë¶€ì¹™ ì¶”ì¶œ"""
        # ë¶€ì¹™ íƒœê·¸ ì°¾ê¸°
        for addendum in root.findall('.//ë¶€ì¹™'):
            addendum_info = {
                'number': addendum.findtext('ë¶€ì¹™ë²ˆí˜¸', ''),
                'promulgation_date': addendum.findtext('ë¶€ì¹™ê³µí¬ì¼ì', ''),
                'content': self._get_all_text(addendum)
            }
            if addendum_info['content']:
                law_detail['supplementary_provisions'].append(addendum_info)
        
        # ë¶€ì¹™ë‚´ìš© ì§ì ‘ ì°¾ê¸°
        if not law_detail['supplementary_provisions']:
            for elem in root.iter():
                if elem.tag == 'ë¶€ì¹™ë‚´ìš©' and elem.text:
                    law_detail['supplementary_provisions'].append({
                        'number': '',
                        'promulgation_date': '',
                        'content': elem.text
                    })
    
    def _extract_attachments(self, root: ET.Element, law_detail: Dict[str, Any]) -> None:
        """ë³„í‘œ/ë³„ì²¨ ì¶”ì¶œ"""
        # ë³„í‘œ ì°¾ê¸°
        for table in root.findall('.//ë³„í‘œ'):
            table_info = {
                'type': 'ë³„í‘œ',
                'number': table.findtext('ë³„í‘œë²ˆí˜¸', ''),
                'title': table.findtext('ë³„í‘œì œëª©', ''),
                'content': self._get_all_text(table)
            }
            if table_info['content'] or table_info['title']:
                law_detail['attachments'].append(table_info)
        
        # ë³„ì§€ ì°¾ê¸°
        for form in root.findall('.//ë³„ì§€'):
            form_info = {
                'type': 'ë³„ì§€',
                'number': form.findtext('ë³„ì§€ë²ˆí˜¸', ''),
                'title': form.findtext('ë³„ì§€ì œëª©', ''),
                'content': self._get_all_text(form)
            }
            if form_info['content'] or form_info['title']:
                law_detail['attachments'].append(form_info)
        
        # ì„œì‹ ì°¾ê¸°
        for format_elem in root.findall('.//ì„œì‹'):
            format_info = {
                'type': 'ì„œì‹',
                'number': format_elem.findtext('ì„œì‹ë²ˆí˜¸', ''),
                'title': format_elem.findtext('ì„œì‹ì œëª©', ''),
                'content': self._get_all_text(format_elem)
            }
            if format_info['content'] or format_info['title']:
                law_detail['attachments'].append(format_info)
    
    def _extract_full_text(self, root: ET.Element) -> str:
        """ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ (í´ë°±)"""
        return self._get_all_text(root)
    
    def _get_all_text(self, elem: ET.Element) -> str:
        """ìš”ì†Œì˜ ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        texts = []
        
        # í˜„ì¬ ìš”ì†Œì˜ í…ìŠ¤íŠ¸
        if elem.text and elem.text.strip():
            texts.append(elem.text.strip())
        
        # ëª¨ë“  ìì‹ ìš”ì†Œì˜ í…ìŠ¤íŠ¸
        for child in elem:
            child_text = self._get_all_text(child)
            if child_text:
                texts.append(child_text)
            
            # tail í…ìŠ¤íŠ¸ (ìš”ì†Œ ë’¤ì˜ í…ìŠ¤íŠ¸)
            if child.tail and child.tail.strip():
                texts.append(child.tail.strip())
        
        return ' '.join(texts)
    
    def export_to_zip(self, laws_dict: Dict[str, Dict[str, Any]]) -> bytes:
        """ìˆ˜ì§‘ëœ ë²•ë ¹ì„ ZIPìœ¼ë¡œ ë‚´ë³´ë‚´ê¸° - MD ì§€ì› ì¶”ê°€"""
        zip_buffer = BytesIO()
        
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            # ì „ì²´ JSON ë°ì´í„°
            all_data = {
                'collection_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'total_laws': len(laws_dict),
                'laws': laws_dict
            }
            
            zip_file.writestr(
                'all_laws.json',
                json.dumps(all_data, ensure_ascii=False, indent=2)
            )
            
            # ì „ì²´ í†µí•© MD íŒŒì¼ ìƒì„±
            all_laws_md = self._create_all_laws_markdown(laws_dict)
            zip_file.writestr('all_laws.md', all_laws_md)
            
            # ê°œë³„ ë²•ë ¹ íŒŒì¼
            for law_id, law in laws_dict.items():
                safe_name = re.sub(r'[\\/*?:"<>|]', '_', law['law_name'])
                
                # JSON íŒŒì¼
                zip_file.writestr(
                    f'laws/{safe_name}.json',
                    json.dumps(law, ensure_ascii=False, indent=2)
                )
                
                # í…ìŠ¤íŠ¸ íŒŒì¼ (ì „ì²´ ë‚´ìš© í¬í•¨)
                text_content = self._format_law_full_text(law)
                zip_file.writestr(
                    f'laws/{safe_name}.txt',
                    text_content
                )
                
                # Markdown íŒŒì¼ ì¶”ê°€
                md_content = self._format_law_markdown(law)
                zip_file.writestr(
                    f'laws/{safe_name}.md',
                    md_content
                )
            
            # README íŒŒì¼
            readme = self._create_readme(laws_dict)
            zip_file.writestr('README.md', readme)
        
        zip_buffer.seek(0)
        return zip_buffer.getvalue()
    
    def _format_law_markdown(self, law: Dict[str, Any]) -> str:
        """ê°œë³„ ë²•ë ¹ì„ Markdownìœ¼ë¡œ í¬ë§·"""
        lines = []
        
        # ì œëª©
        lines.append(f"# {law['law_name']}\n")
        
        # ë©”íƒ€ë°ì´í„°
        lines.append("## ğŸ“‹ ê¸°ë³¸ ì •ë³´\n")
        lines.append(f"- **ë²•ì¢…êµ¬ë¶„**: {law.get('law_type', '')}")
        lines.append(f"- **ê³µí¬ì¼ì**: {law.get('promulgation_date', '')}")
        lines.append(f"- **ì‹œí–‰ì¼ì**: {law.get('enforcement_date', '')}")
        lines.append(f"- **ë²•ë ¹ID**: {law.get('law_id', '')}")
        lines.append("")
        
        # ì¡°ë¬¸
        if law.get('articles'):
            lines.append("## ğŸ“– ì¡°ë¬¸\n")
            for article in law['articles']:
                lines.append(f"### {article['number']}")
                if article.get('title'):
                    lines.append(f"**{article['title']}**\n")
                
                lines.append(article['content'])
                
                # í•­
                if article.get('paragraphs'):
                    for para in article['paragraphs']:
                        lines.append(f"\n> {para['number']} {para['content']}")
                
                lines.append("")
        
        # ë¶€ì¹™
        if law.get('supplementary_provisions'):
            lines.append("\n## ğŸ“Œ ë¶€ì¹™\n")
            for idx, supp in enumerate(law['supplementary_provisions'], 1):
                if supp.get('promulgation_date'):
                    lines.append(f"### ë¶€ì¹™ <{supp['promulgation_date']}>")
                else:
                    lines.append(f"### ë¶€ì¹™ {idx}")
                lines.append(f"\n{supp['content']}\n")
        
        # ë³„í‘œ/ë³„ì²¨
        if law.get('attachments'):
            lines.append("\n## ğŸ“ ë³„í‘œ/ë³„ì²¨\n")
            for attach in law['attachments']:
                lines.append(f"### [{attach['type']}] {attach.get('title', '')}")
                lines.append(f"\n{attach['content']}\n")
        
        # ì›ë¬¸ (ì¡°ë¬¸ì´ ì—†ëŠ” ê²½ìš°)
        if not law.get('articles') and law.get('raw_content'):
            lines.append("\n## ğŸ“„ ì›ë¬¸\n")
            lines.append(law['raw_content'])
        
        return '\n'.join(lines)
    
    def _create_all_laws_markdown(self, laws_dict: Dict[str, Dict[str, Any]]) -> str:
        """ì „ì²´ ë²•ë ¹ì„ í•˜ë‚˜ì˜ Markdownìœ¼ë¡œ ìƒì„±"""
        lines = []
        
        # í—¤ë”
        lines.append("# ğŸ“š ë²•ë ¹ ìˆ˜ì§‘ ê²°ê³¼ (ì „ì²´)\n")
        lines.append(f"**ìˆ˜ì§‘ ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"**ì´ ë²•ë ¹ ìˆ˜**: {len(laws_dict)}ê°œ\n")
        
        # ëª©ì°¨
        lines.append("## ğŸ“‘ ëª©ì°¨\n")
        for idx, (law_id, law) in enumerate(laws_dict.items(), 1):
            # ì•µì»¤ ë§í¬ ìƒì„± (íŠ¹ìˆ˜ë¬¸ì ì œê±°)
            anchor = re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', law['law_name'])
            lines.append(f"{idx}. [{law['law_name']}](#{anchor})")
        lines.append("")
        
        # êµ¬ë¶„ì„ 
        lines.append("---\n")
        
        # ê° ë²•ë ¹ ë‚´ìš©
        for law_id, law in laws_dict.items():
            # ì•µì»¤ë¥¼ ìœ„í•œ ID
            anchor = re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', law['law_name'])
            lines.append(f'<div id="{anchor}"></div>\n')
            
            # ë²•ë ¹ ë‚´ìš© ì¶”ê°€
            lines.append(self._format_law_markdown(law))
            lines.append("\n---\n")
        
        return '\n'.join(lines)
    
    def export_single_file(self, laws_dict: Dict[str, Dict[str, Any]], format: str = 'json') -> str:
        """ì„ íƒí•œ ë²•ë ¹ë“¤ì„ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        if format == 'json':
            data = {
                'collection_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'total_laws': len(laws_dict),
                'laws': laws_dict
            }
            return json.dumps(data, ensure_ascii=False, indent=2)
        
        elif format == 'markdown':
            return self._create_all_laws_markdown(laws_dict)
        
        elif format == 'text':
            lines = []
            lines.append(f"ë²•ë ¹ ìˆ˜ì§‘ ê²°ê³¼")
            lines.append(f"ìˆ˜ì§‘ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            lines.append(f"ì´ ë²•ë ¹ ìˆ˜: {len(laws_dict)}ê°œ")
            lines.append("="*80 + "\n")
            
            for law_id, law in laws_dict.items():
                lines.append(self._format_law_full_text(law))
                lines.append("\n" + "="*80 + "\n")
            
            return '\n'.join(lines)
    
    def _format_law_full_text(self, law: Dict[str, Any]) -> str:
        """ë²•ë ¹ ì „ì²´ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ í¬ë§·"""
        lines = []
        
        # í—¤ë”
        lines.append(f"{'=' * 80}")
        lines.append(f"ë²•ë ¹ëª…: {law['law_name']}")
        lines.append(f"ë²•ì¢…êµ¬ë¶„: {law.get('law_type', '')}")
        lines.append(f"ê³µí¬ì¼ì: {law.get('promulgation_date', '')}")
        lines.append(f"ì‹œí–‰ì¼ì: {law.get('enforcement_date', '')}")
        lines.append(f"{'=' * 80}\n")
        
        # ì¡°ë¬¸
        if law.get('articles'):
            lines.append("ã€ ì¡° ë¬¸ ã€‘\n")
            for article in law['articles']:
                lines.append(f"\n{article['number']} {article.get('title', '')}")
                lines.append(article['content'])
                
                # í•­
                if article.get('paragraphs'):
                    for para in article['paragraphs']:
                        lines.append(f"\n  {para['number']} {para['content']}")
                
                lines.append("")  # ì¡°ë¬¸ ê°„ ê³µë°±
        
        # ë¶€ì¹™
        if law.get('supplementary_provisions'):
            lines.append("\n\nã€ ë¶€ ì¹™ ã€‘\n")
            for idx, supp in enumerate(law['supplementary_provisions'], 1):
                if supp.get('promulgation_date'):
                    lines.append(f"\në¶€ì¹™ <{supp['promulgation_date']}>")
                else:
                    lines.append(f"\në¶€ì¹™ {idx}")
                lines.append(supp['content'])
        
        # ë³„í‘œ/ë³„ì²¨
        if law.get('attachments'):
            lines.append("\n\nã€ ë³„í‘œ/ë³„ì²¨ ã€‘\n")
            for attach in law['attachments']:
                lines.append(f"\n[{attach['type']}] {attach.get('title', '')}")
                lines.append(attach['content'])
                lines.append("")
        
        # ì›ë¬¸ (ì¡°ë¬¸ì´ ì—†ëŠ” ê²½ìš°)
        if not law.get('articles') and law.get('raw_content'):
            lines.append("\n\nã€ ì› ë¬¸ ã€‘\n")
            lines.append(law['raw_content'])
        
        return '\n'.join(lines)
    
    def _create_readme(self, laws_dict: Dict[str, Dict[str, Any]]) -> str:
        """README ìƒì„± - ê°œì„ ëœ ë²„ì „"""
        content = f"""# ë²•ë ¹ ìˆ˜ì§‘ ê²°ê³¼

ìˆ˜ì§‘ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ì´ ë²•ë ¹ ìˆ˜: {len(laws_dict)}ê°œ

## ğŸ“ íŒŒì¼ êµ¬ì¡°

- `all_laws.json`: ì „ì²´ ë²•ë ¹ ë°ì´í„° (JSON)
- `all_laws.md`: ì „ì²´ ë²•ë ¹ í†µí•© ë¬¸ì„œ (Markdown)
- `laws/`: ê°œë³„ ë²•ë ¹ íŒŒì¼ ë””ë ‰í† ë¦¬
  - `*.json`: ë²•ë ¹ë³„ ìƒì„¸ ë°ì´í„°
  - `*.txt`: ë²•ë ¹ë³„ ì „ì²´ í…ìŠ¤íŠ¸ (ì¡°ë¬¸, ë¶€ì¹™, ë³„í‘œ í¬í•¨)
  - `*.md`: ë²•ë ¹ë³„ Markdown ë¬¸ì„œ
- `README.md`: ì´ íŒŒì¼

## ğŸ“Š ìˆ˜ì§‘ í†µê³„

"""
        # í†µê³„
        total_articles = 0
        total_provisions = 0
        total_attachments = 0
        
        for law in laws_dict.values():
            total_articles += len(law.get('articles', []))
            total_provisions += len(law.get('supplementary_provisions', []))
            total_attachments += len(law.get('attachments', []))
        
        content += f"- ì´ ì¡°ë¬¸ ìˆ˜: {total_articles:,}ê°œ\n"
        content += f"- ì´ ë¶€ì¹™ ìˆ˜: {total_provisions}ê°œ\n"
        content += f"- ì´ ë³„í‘œ/ë³„ì²¨ ìˆ˜: {total_attachments}ê°œ\n"
        
        content += "\n## ğŸ“– ìˆ˜ì§‘ëœ ë²•ë ¹ ëª©ë¡\n\n"
        
        for law_id, law in laws_dict.items():
            article_count = len(law.get('articles', []))
            content += f"### {law['law_name']}\n"
            content += f"- ë²•ì¢…êµ¬ë¶„: {law.get('law_type', '')}\n"
            content += f"- ì‹œí–‰ì¼ì: {law.get('enforcement_date', '')}\n"
            content += f"- ì¡°ë¬¸: {article_count}ê°œ\n"
            content += f"- ë¶€ì¹™: {len(law.get('supplementary_provisions', []))}ê°œ\n"
            content += f"- ë³„í‘œ/ë³„ì²¨: {len(law.get('attachments', []))}ê°œ\n\n"
        
        return content


# ë©”ì¸ UI
def main():
    st.title("ğŸ“š ë²•ì œì²˜ ë²•ë ¹ ìˆ˜ì§‘ê¸°")
    st.markdown("ë²•ì œì²˜ Open APIë¥¼ í™œìš©í•œ ë²•ë ¹ ìˆ˜ì§‘ ë„êµ¬")
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # ê¸°ê´€ì½”ë“œ ì…ë ¥
        oc_code = st.text_input(
            "ê¸°ê´€ì½”ë“œ (OC)",
            placeholder="ì´ë©”ì¼ @ ì•ë¶€ë¶„",
            help="ì˜ˆ: test@korea.kr â†’ test"
        )
        
        st.divider()
        
        # AI ì„¤ì • ì„¹ì…˜ ì¶”ê°€
        with st.expander("ğŸ¤– AI ì„¤ì • (ì„ íƒì‚¬í•­)", expanded=False):
            st.markdown("**ChatGPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë²•ë ¹ëª… ì¶”ì¶œ ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤**")
            
            api_key = st.text_input(
                "OpenAI API Key",
                type="password",
                value=st.session_state.get('openai_api_key', ''),
                help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”. https://platform.openai.com/api-keys ì—ì„œ ë°œê¸‰ ê°€ëŠ¥í•©ë‹ˆë‹¤."
            )
            
            if api_key:
                st.session_state.openai_api_key = api_key
                st.session_state.use_ai = True
                st.success("âœ… API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
                
                # API í‚¤ í…ŒìŠ¤íŠ¸ ë²„íŠ¼
                if st.button("ğŸ” API í‚¤ í…ŒìŠ¤íŠ¸", type="secondary"):
                    try:
                        import openai
                        openai.api_key = api_key
                        
                        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìš”ì²­
                        response = openai.ChatCompletion.create(
                            model="gpt-3.5-turbo",
                            messages=[{"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”"}],
                            max_tokens=10
                        )
                        st.success("âœ… API í‚¤ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤!")
                    except Exception as e:
                        st.error(f"âŒ API í‚¤ ì˜¤ë¥˜: {str(e)}")
            else:
                st.session_state.use_ai = False
                st.info("ğŸ’¡ API í‚¤ë¥¼ ì…ë ¥í•˜ë©´ ë” ì •í™•í•œ ë²•ë ¹ëª… ì¶”ì¶œì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        st.divider()
        
        # ëª¨ë“œ ì„ íƒ
        st.subheader("ğŸ¯ ìˆ˜ì§‘ ë°©ì‹")
        mode = st.radio(
            "ë°©ì‹ ì„ íƒ",
            ["ì§ì ‘ ê²€ìƒ‰", "íŒŒì¼ ì—…ë¡œë“œ"],
            help="ì§ì ‘ ê²€ìƒ‰: ë²•ë ¹ëª…ì„ ì…ë ¥í•˜ì—¬ ê²€ìƒ‰\níŒŒì¼ ì—…ë¡œë“œ: PDF/Excel/MD íŒŒì¼ì—ì„œ ë²•ë ¹ ì¶”ì¶œ"
        )
        st.session_state.mode = 'direct' if mode == "ì§ì ‘ ê²€ìƒ‰" else 'file'
        
        # ì§ì ‘ ê²€ìƒ‰ ëª¨ë“œ
        if st.session_state.mode == 'direct':
            law_name = st.text_input(
                "ë²•ë ¹ëª…",
                placeholder="ì˜ˆ: ë¯¼ë²•, ìƒë²•, í˜•ë²•",
                help="ê²€ìƒ‰í•  ë²•ë ¹ëª…ì„ ì…ë ¥í•˜ì„¸ìš”"
            )
            
            search_btn = st.button("ğŸ” ê²€ìƒ‰", type="primary", use_container_width=True)
        
        # íŒŒì¼ ì—…ë¡œë“œ ëª¨ë“œ
        else:
            st.subheader("ğŸ“„ ë²•ë ¹ì²´ê³„ë„ íŒŒì¼ ì—…ë¡œë“œ")
            uploaded_file = st.file_uploader(
                "íŒŒì¼ ì„ íƒ",
                type=['pdf', 'xlsx', 'xls', 'md', 'txt'],
                help="PDF, Excel, Markdown, í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì§€ì›í•©ë‹ˆë‹¤"
            )
            
            if uploaded_file:
                st.success(f"âœ… {uploaded_file.name} ì—…ë¡œë“œë¨")
                file_type = uploaded_file.name.split('.')[-1].lower()
                st.info(f"íŒŒì¼ í˜•ì‹: {file_type.upper()}")
        
        # ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ”„ ì´ˆê¸°í™”", type="secondary", use_container_width=True):
            # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
            keys_to_keep = ['mode']
            for key in list(st.session_state.keys()):
                if key not in keys_to_keep:
                    del st.session_state[key]
            st.rerun()
    
    # ë©”ì¸ ì»¨í…ì¸ 
    collector = LawCollectorAPI()
    
    # ì§ì ‘ ê²€ìƒ‰ ëª¨ë“œ
    if st.session_state.mode == 'direct':
        st.header("ğŸ” ì§ì ‘ ê²€ìƒ‰ ëª¨ë“œ")
        
        if 'search_btn' in locals() and search_btn:
            if not oc_code:
                st.error("ê¸°ê´€ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            elif not law_name:
                st.error("ë²•ë ¹ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            else:
                with st.spinner(f"'{law_name}' ê²€ìƒ‰ ì¤‘..."):
                    results = collector.search_law(oc_code, law_name)
                    
                    if results:
                        st.success(f"{len(results)}ê°œì˜ ë²•ë ¹ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                        st.session_state.search_results = results
                    else:
                        st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        st.session_state.search_results = []
        
        # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
        if st.session_state.search_results:
            display_search_results_and_collect(collector, oc_code)
    
    # íŒŒì¼ ì—…ë¡œë“œ ëª¨ë“œ
    else:
        st.header("ğŸ“„ íŒŒì¼ ì—…ë¡œë“œ ëª¨ë“œ")
        extractor = EnhancedLawFileExtractor()  # ê°œì„ ëœ ì¶”ì¶œê¸° ì‚¬ìš©
        
        # íŒŒì¼ì—ì„œ ë²•ë ¹ ì¶”ì¶œ
        if uploaded_file and not st.session_state.file_processed:
            st.subheader("ğŸ“‹ STEP 1: ë²•ë ¹ëª… ì¶”ì¶œ")
            
            with st.spinner("íŒŒì¼ì—ì„œ ë²•ë ¹ëª…ì„ ì¶”ì¶œí•˜ëŠ” ì¤‘..."):
                file_type = uploaded_file.name.split('.')[-1].lower()
                
                # íŒŒì¼ íƒ€ì…ë³„ ì²˜ë¦¬
                if file_type == 'pdf':
                    extracted_laws = extractor.extract_from_pdf(uploaded_file)
                elif file_type in ['xlsx', 'xls']:
                    extracted_laws = extractor.extract_from_excel(uploaded_file)
                elif file_type == 'md':
                    extracted_laws = extractor.extract_from_markdown(uploaded_file)
                elif file_type == 'txt':
                    extracted_laws = extractor.extract_from_text(uploaded_file)
                else:
                    st.error("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤")
                    extracted_laws = []
                
                if extracted_laws:
                    st.success(f"âœ… {len(extracted_laws)}ê°œì˜ ë²•ë ¹ëª…ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                    st.session_state.extracted_laws = extracted_laws
                    st.session_state.file_processed = True
                else:
                    st.warning("íŒŒì¼ì—ì„œ ë²•ë ¹ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ì¶”ì¶œëœ ë²•ë ¹ í‘œì‹œ ë° í¸ì§‘
        if st.session_state.extracted_laws:
            st.subheader("âœï¸ STEP 2: ë²•ë ¹ëª… í™•ì¸ ë° í¸ì§‘")
            st.info("ì¶”ì¶œëœ ë²•ë ¹ëª…ì„ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ìˆ˜ì •í•˜ê±°ë‚˜ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            
            # ì¶”ì¶œëœ ë²•ë ¹ ëª©ë¡ í‘œì‹œ (ì½ê¸° ì „ìš©)
            st.write("**ì¶”ì¶œëœ ë²•ë ¹ëª…:**")
            for idx, law in enumerate(st.session_state.extracted_laws, 1):
                st.write(f"{idx}. {law}")
            
            # ë²•ë ¹ëª… í¸ì§‘ ì˜ì—­
            edited_laws = []
            
            st.write("\n**ë²•ë ¹ëª… í¸ì§‘:**")
            for idx, law_name in enumerate(st.session_state.extracted_laws):
                col1, col2 = st.columns([4, 1])
                with col1:
                    edited_name = st.text_input(
                        f"ë²•ë ¹ {idx+1}",
                        value=law_name,
                        key=f"edit_{idx}"
                    )
                    if edited_name:
                        edited_laws.append(edited_name)
                with col2:
                    if st.button("ì‚­ì œ", key=f"del_{idx}"):
                        st.session_state.extracted_laws.pop(idx)
                        st.rerun()
            
            # ë²•ë ¹ëª… ì¶”ê°€
            st.subheader("ë²•ë ¹ëª… ì¶”ê°€")
            new_law = st.text_input("ìƒˆ ë²•ë ¹ëª… ì…ë ¥", key="new_law_input")
            if st.button("â• ì¶”ê°€") and new_law:
                st.session_state.extracted_laws.append(new_law)
                st.rerun()
            
            # ë²•ë ¹ ê²€ìƒ‰ ë²„íŠ¼
            if st.button("ğŸ” ë²•ë ¹ ê²€ìƒ‰", type="primary", use_container_width=True):
                if not oc_code:
                    st.error("ê¸°ê´€ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
                else:
                    # ê²€ìƒ‰ ì‹œì‘
                    search_results = []
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    # ìˆ˜ì •ëœ ë²•ë ¹ëª…ìœ¼ë¡œ ì—…ë°ì´íŠ¸
                    if edited_laws:
                        st.session_state.extracted_laws = edited_laws
                    
                    total = len(st.session_state.extracted_laws)
                    
                    for idx, law_name in enumerate(st.session_state.extracted_laws):
                        progress = (idx + 1) / total
                        progress_bar.progress(progress)
                        status_text.text(f"ê²€ìƒ‰ ì¤‘: {law_name}")
                        
                        # API ê²€ìƒ‰
                        results = collector.search_law(oc_code, law_name)
                        
                        for result in results:
                            # ê²€ìƒ‰ì–´ì™€ ìœ ì‚¬í•œ ê²°ê³¼ë§Œ í¬í•¨
                            if law_name in result['law_name'] or result['law_name'] in law_name:
                                result['search_query'] = law_name
                                search_results.append(result)
                        
                        time.sleep(collector.delay)
                    
                    progress_bar.progress(1.0)
                    status_text.text("ê²€ìƒ‰ ì™„ë£Œ!")
                    
                    if search_results:
                        st.success(f"âœ… ì´ {len(search_results)}ê°œì˜ ë²•ë ¹ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                        st.session_state.search_results = search_results
                    else:
                        st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
        if st.session_state.search_results:
            display_search_results_and_collect(collector, oc_code, is_file_mode=True)


def display_search_results_and_collect(collector: LawCollectorAPI, oc_code: str, is_file_mode: bool = False) -> None:
    """ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ ë° ìˆ˜ì§‘ - ê³µí†µ í•¨ìˆ˜"""
    st.subheader("ğŸ“‘ ê²€ìƒ‰ ê²°ê³¼")
    
    # ì „ì²´ ì„ íƒ
    select_all = st.checkbox("ì „ì²´ ì„ íƒ", key="select_all_results")
    
    # í…Œì´ë¸” í—¤ë”
    if is_file_mode:
        col1, col2, col3, col4, col5 = st.columns([1, 3, 2, 2, 2])
        with col5:
            st.markdown("**ê²€ìƒ‰ì–´**")
    else:
        col1, col2, col3, col4 = st.columns([1, 3, 2, 2])
    
    with col1:
        st.markdown("**ì„ íƒ**")
    with col2:
        st.markdown("**ë²•ë ¹ëª…**")
    with col3:
        st.markdown("**ë²•ì¢…êµ¬ë¶„**")
    with col4:
        st.markdown("**ì‹œí–‰ì¼ì**")
    
    st.divider()
    
    # ì„ íƒëœ ë²•ë ¹
    selected_indices = []
    
    for idx, law in enumerate(st.session_state.search_results):
        if is_file_mode:
            col1, col2, col3, col4, col5 = st.columns([1, 3, 2, 2, 2])
        else:
            col1, col2, col3, col4 = st.columns([1, 3, 2, 2])
        
        with col1:
            is_selected = st.checkbox("", key=f"sel_{idx}", value=select_all)
            if is_selected:
                selected_indices.append(idx)
        
        with col2:
            st.write(law['law_name'])
        
        with col3:
            st.write(law.get('law_type', ''))
        
        with col4:
            st.write(law.get('enforcement_date', ''))
        
        if is_file_mode:
            with col5:
                st.write(law.get('search_query', ''))
    
    # ì„ íƒëœ ë²•ë ¹ ì €ì¥
    st.session_state.selected_laws = [
        st.session_state.search_results[i] for i in selected_indices
    ]
    
    if st.session_state.selected_laws:
        st.success(f"{len(st.session_state.selected_laws)}ê°œ ë²•ë ¹ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤")
        
        # ìˆ˜ì§‘ ë²„íŠ¼
        if st.button("ğŸ“¥ ì„ íƒí•œ ë²•ë ¹ ìˆ˜ì§‘", type="primary", use_container_width=True):
            collected_laws = {}
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            total = len(st.session_state.selected_laws)
            success_count = 0
            
            for idx, law in enumerate(st.session_state.selected_laws):
                progress = (idx + 1) / total
                progress_bar.progress(progress)
                status_text.text(f"ìˆ˜ì§‘ ì¤‘ ({idx + 1}/{total}): {law['law_name']}")
                
                # ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
                law_detail = collector.get_law_detail_with_full_content(
                    oc_code,
                    law['law_id'],
                    law.get('law_msn', ''),
                    law['law_name']
                )
                
                if law_detail:
                    collected_laws[law['law_id']] = law_detail
                    success_count += 1
                
                time.sleep(collector.delay)
            
            progress_bar.progress(1.0)
            status_text.text(f"ìˆ˜ì§‘ ì™„ë£Œ! (ì„±ê³µ: {success_count}/{total})")
            
            st.session_state.collected_laws = collected_laws
            
            # í†µê³„ í‘œì‹œ
            total_articles = sum(len(law.get('articles', [])) for law in collected_laws.values())
            total_provisions = sum(len(law.get('supplementary_provisions', [])) for law in collected_laws.values())
            total_attachments = sum(len(law.get('attachments', [])) for law in collected_laws.values())
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì´ ì¡°ë¬¸", f"{total_articles:,}ê°œ")
            with col2:
                st.metric("ì´ ë¶€ì¹™", f"{total_provisions}ê°œ")
            with col3:
                st.metric("ì´ ë³„í‘œ/ë³„ì²¨", f"{total_attachments}ê°œ")
    
    # ë‹¤ìš´ë¡œë“œ ì„¹ì…˜
    if st.session_state.collected_laws:
        st.header("ğŸ’¾ ë‹¤ìš´ë¡œë“œ")
        
        # ë‹¤ìš´ë¡œë“œ ì˜µì…˜ ì„ íƒ
        st.subheader("ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì˜µì…˜")
        download_option = st.radio(
            "ë‹¤ìš´ë¡œë“œ ë°©ì‹ ì„ íƒ",
            ["ê°œë³„ íŒŒì¼ (ZIP)", "í†µí•© íŒŒì¼ (ë‹¨ì¼)"],
            help="ê°œë³„ íŒŒì¼: ê° ë²•ë ¹ë³„ë¡œ íŒŒì¼ ìƒì„±\ní†µí•© íŒŒì¼: ëª¨ë“  ë²•ë ¹ì„ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ"
        )
        
        if download_option == "ê°œë³„ íŒŒì¼ (ZIP)":
            col1, col2 = st.columns(2)
            
            with col1:
                # JSON ë‹¤ìš´ë¡œë“œ
                json_data = {
                    'collection_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'mode': st.session_state.mode,
                    'laws': st.session_state.collected_laws
                }
                json_str = json.dumps(json_data, ensure_ascii=False, indent=2)
                
                st.download_button(
                    label="ğŸ“„ JSON ë‹¤ìš´ë¡œë“œ",
                    data=json_str,
                    file_name=f"laws_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json",
                    use_container_width=True
                )
            
            with col2:
                # ZIP ë‹¤ìš´ë¡œë“œ (MD í¬í•¨)
                zip_data = collector.export_to_zip(st.session_state.collected_laws)
                
                st.download_button(
                    label="ğŸ“¦ ZIP ë‹¤ìš´ë¡œë“œ (JSON+TXT+MD)",
                    data=zip_data,
                    file_name=f"laws_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                    mime="application/zip",
                    use_container_width=True
                )
        
        else:  # í†µí•© íŒŒì¼
            file_format = st.selectbox(
                "íŒŒì¼ í˜•ì‹ ì„ íƒ",
                ["JSON", "Markdown", "Text"],
                help="ëª¨ë“  ë²•ë ¹ì„ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ í†µí•©í•©ë‹ˆë‹¤"
            )
            
            if file_format == "JSON":
                content = collector.export_single_file(st.session_state.collected_laws, 'json')
                mime = "application/json"
                extension = "json"
            elif file_format == "Markdown":
                content = collector.export_single_file(st.session_state.collected_laws, 'markdown')
                mime = "text/markdown"
                extension = "md"
            else:  # Text
                content = collector.export_single_file(st.session_state.collected_laws, 'text')
                mime = "text/plain"
                extension = "txt"
            
            st.download_button(
                label=f"ğŸ’¾ {file_format} í†µí•© íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=content,
                file_name=f"all_laws_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{extension}",
                mime=mime,
                use_container_width=True
            )
        
        # ìˆ˜ì§‘ ê²°ê³¼ ìƒì„¸
        with st.expander("ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìƒì„¸"):
            for law_id, law in st.session_state.collected_laws.items():
                st.subheader(law['law_name'])
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.write(f"ì¡°ë¬¸: {len(law.get('articles', []))}ê°œ")
                with col2:
                    st.write(f"ë¶€ì¹™: {len(law.get('supplementary_provisions', []))}ê°œ")
                with col3:
                    st.write(f"ë³„í‘œ: {len(law.get('attachments', []))}ê°œ")
                
                # ìƒ˜í”Œ ì¡°ë¬¸ í‘œì‹œ
                if law.get('articles'):
                    st.write("**ìƒ˜í”Œ ì¡°ë¬¸:**")
                    sample = law['articles'][0]
                    st.text(f"{sample['number']} {sample.get('title', '')}")
                    content_preview = sample['content'][:200] + "..." if len(sample['content']) > 200 else sample['content']
                    st.text(content_preview)


if __name__ == "__main__":
    main()
