"""
ë²•ì œì²˜ ë²•ë ¹ ìˆ˜ì§‘ê¸° - ê°œì„ ëœ ë²„ì „ (v4.0)
- ë³´ì•ˆ ê°•í™”: SSL ì¸ì¦ì„œ ê²€ì¦
- ì„±ëŠ¥ ê°œì„ : ë¹„ë™ê¸° ì²˜ë¦¬ ì§€ì›
- ì½”ë“œ êµ¬ì¡° ê°œì„ : ì„¤ì • ë¶„ë¦¬, ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
- Open API ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜
"""

import streamlit as st
import requests
import xml.etree.ElementTree as ET
import json
import asyncio
import aiohttp
from datetime import datetime
from io import BytesIO
import zipfile
import pandas as pd
import PyPDF2
import pdfplumber
from typing import List, Set, Dict, Optional, Tuple, Any
from dataclasses import dataclass
from functools import lru_cache
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import os
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë²•ì œì²˜ ë²•ë ¹ ìˆ˜ì§‘ê¸°",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì„¤ì • í´ë˜ìŠ¤
@dataclass
class APIConfig:
    """API ì„¤ì •ì„ ê´€ë¦¬í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    # ë²•ì œì²˜ API ì—”ë“œí¬ì¸íŠ¸
    LAW_SEARCH_URL = "https://www.law.go.kr/DRF/lawSearch.do"
    LAW_DETAIL_URL = "https://www.law.go.kr/DRF/lawService.do"
    ADMIN_RULE_SEARCH_URL = "https://www.law.go.kr/DRF/admRulSearch.do"
    ADMIN_RULE_DETAIL_URL = "https://www.law.go.kr/DRF/admRulService.do"
    
    # API ì„¤ì •
    DEFAULT_DELAY = 0.3  # API í˜¸ì¶œ ê°„ê²© (ì´ˆ)
    MAX_RETRIES = 3      # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
    TIMEOUT = 30         # íƒ€ì„ì•„ì›ƒ (ì´ˆ)
    MAX_CONCURRENT = 5   # ìµœëŒ€ ë™ì‹œ ìš”ì²­ ìˆ˜
    
    # í˜ì´ì§€ë‹¹ ê²°ê³¼ ìˆ˜
    RESULTS_PER_PAGE = 100

# ë²•ë ¹ëª… íŒ¨í„´ ì„¤ì •
class LawPatterns:
    """ë²•ë ¹ëª… ì¶”ì¶œ íŒ¨í„´ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    # ì œì™¸ í‚¤ì›Œë“œ
    EXCLUDE_KEYWORDS = {
        'ìƒí•˜ìœ„ë²•', 'í–‰ì •ê·œì¹™', 'ë²•ë ¹', 'ì‹œí–‰ë ¹', 'ì‹œí–‰ê·œì¹™', 'ëŒ€í†µë ¹ë ¹', 
        'ì´ë¦¬ë ¹', 'ë¶€ë ¹', 'ê´€í•œ ê·œì •', 'ìƒìœ„ë²•', 'í•˜ìœ„ë²•', 'ê´€ë ¨ë²•ë ¹'
    }
    
    # ë²•ë ¹ íƒ€ì…
    LAW_TYPES = {
        'ë²•', 'ë²•ë¥ ', 'ì‹œí–‰ë ¹', 'ì‹œí–‰ê·œì¹™', 'ê·œì •', 'ê·œì¹™', 'ì„¸ì¹™', 
        'ê³ ì‹œ', 'í›ˆë ¹', 'ì˜ˆê·œ', 'ì§€ì¹¨', 'ë¶„ë¥˜', 'ì—…ë¬´ê·œì •', 'ê°ë…ê·œì •'
    }
    
    # í–‰ì •ê·œì¹™ í‚¤ì›Œë“œ
    ADMIN_KEYWORDS = {
        'ê·œì •', 'ê³ ì‹œ', 'í›ˆë ¹', 'ì˜ˆê·œ', 'ì§€ì¹¨', 'ì„¸ì¹™', 'ê¸°ì¤€', 'ìš”ë ¹', 'ì§€ì‹œ'
    }


class EnhancedLawFileExtractor:
    """ê°œì„ ëœ ë²•ë ¹ëª… ì¶”ì¶œ í´ë˜ìŠ¤"""
    
    def __init__(self, use_ai: bool = False, api_key: Optional[str] = None):
        self.patterns = LawPatterns()
        self.use_ai = use_ai
        self.api_key = api_key
        self.logger = logging.getLogger(self.__class__.__name__)
        
    def extract_from_file(self, file, file_type: str) -> List[str]:
        """íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ì¶”ì¶œ ë©”ì„œë“œ ë””ìŠ¤íŒ¨ì¹˜"""
        extractors = {
            'pdf': self._extract_from_pdf,
            'xlsx': self._extract_from_excel,
            'xls': self._extract_from_excel,
            'md': self._extract_from_markdown,
            'txt': self._extract_from_text
        }
        
        extractor = extractors.get(file_type.lower())
        if not extractor:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_type}")
            
        return extractor(file)
    
    def _extract_from_pdf(self, file) -> List[str]:
        """PDF íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        try:
            text = self._read_pdf_content(file)
            laws = self._extract_laws_from_text(text)
            
            if self.use_ai and self.api_key:
                laws = self._enhance_with_ai(text, laws)
                
            return sorted(list(laws))
            
        except Exception as e:
            self.logger.error(f"PDF ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []
    
    def _read_pdf_content(self, file) -> str:
        """PDF ë‚´ìš© ì½ê¸° - pdfplumber ìš°ì„ , ì‹¤íŒ¨ì‹œ PyPDF2"""
        text = ""
        
        # pdfplumber ì‹œë„
        try:
            with pdfplumber.open(file) as pdf:
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
            return text
        except Exception as e:
            self.logger.warning(f"pdfplumber ì‹¤íŒ¨: {e}")
        
        # PyPDF2 í´ë°±
        try:
            file.seek(0)
            pdf_reader = PyPDF2.PdfReader(file)
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
            return text
        except Exception as e:
            self.logger.error(f"PyPDF2ë„ ì‹¤íŒ¨: {e}")
            raise
    
    def _extract_laws_from_text(self, text: str) -> Set[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ - ê°œì„ ëœ ë¡œì§"""
        laws = set()
        
        # ì •ê·œí™”
        text = self._normalize_text(text)
        
        # ë¼ì¸ë³„ ì²˜ë¦¬
        for line in text.split('\n'):
            line = line.strip()
            
            # ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
            if line in self.patterns.EXCLUDE_KEYWORDS:
                continue
                
            # ë²•ë ¹ëª… ì¶”ì¶œ
            extracted = self._extract_law_names(line)
            laws.update(extracted)
        
        # í›„ì²˜ë¦¬
        laws = self._post_process_laws(laws)
        
        return laws
    
    def _normalize_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ê·œí™”"""
        # ì—°ì† ê³µë°± ì œê±°
        text = ' '.join(text.split())
        
        # í‘œì¤€í™”
        replacements = {
            'ì—ê´€í•œ': 'ì— ê´€í•œ',
            'ë°': ' ë° ',
            'Â·': 'Â·',  # ì¤‘ì  í†µì¼
            'ï¼Œ': ',',  # ì‰¼í‘œ í†µì¼
        }
        
        for old, new in replacements.items():
            text = text.replace(old, new)
            
        return text
    
    def _extract_law_names(self, line: str) -> Set[str]:
        """ë¼ì¸ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        laws = set()
        
        # ì‹œí–‰ ë‚ ì§œ íŒ¨í„´ ì œê±°
        line = self._remove_enforcement_date(line)
        
        # ë²•ë ¹ íƒ€ì…ë³„ ë§¤ì¹­
        for law_type in self.patterns.LAW_TYPES:
            if law_type in line:
                # ë²•ë ¹ëª… ê²½ê³„ ì°¾ê¸°
                law_name = self._find_law_boundaries(line, law_type)
                if law_name and self._validate_law_name(law_name):
                    laws.add(law_name)
        
        return laws
    
    def _remove_enforcement_date(self, text: str) -> str:
        """ì‹œí–‰ ë‚ ì§œ ì •ë³´ ì œê±°"""
        import re
        return re.sub(r'\[ì‹œí–‰\s*\d{4}\.\s*\d{1,2}\.\s*\d{1,2}\.\]', '', text)
    
    def _find_law_boundaries(self, text: str, law_type: str) -> Optional[str]:
        """ë²•ë ¹ëª…ì˜ ì‹œì‘ê³¼ ë ì°¾ê¸°"""
        import re
        
        # ë²•ë ¹ íƒ€ì… ìœ„ì¹˜ ì°¾ê¸°
        type_pos = text.find(law_type)
        if type_pos == -1:
            return None
            
        # ì‹œì‘ ìœ„ì¹˜ ì°¾ê¸° (í•œê¸€ë¡œ ì‹œì‘)
        start = 0
        for i in range(type_pos - 1, -1, -1):
            if not (text[i].isalnum() or text[i] in ' Â·ë°ê´€í•œì˜ì—'):
                start = i + 1
                break
        
        # ë ìœ„ì¹˜ëŠ” ë²•ë ¹ íƒ€ì… ë’¤
        end = type_pos + len(law_type)
        
        # ì‹œí–‰ë ¹/ì‹œí–‰ê·œì¹™ ì²˜ë¦¬
        if end < len(text) - 3:
            next_chars = text[end:end+4]
            if 'ì‹œí–‰ë ¹' in next_chars or 'ì‹œí–‰ê·œì¹™' in next_chars:
                end = text.find(' ', end)
                if end == -1:
                    end = len(text)
        
        return text[start:end].strip()
    
    def _validate_law_name(self, law_name: str) -> bool:
        """ë²•ë ¹ëª… ìœ íš¨ì„± ê²€ì¦"""
        # ê¸¸ì´ ì²´í¬
        if len(law_name) < 3 or len(law_name) > 100:
            return False
            
        # ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
        if law_name in self.patterns.EXCLUDE_KEYWORDS:
            return False
            
        # í•œê¸€ í¬í•¨ ì²´í¬
        import re
        if not re.search(r'[ê°€-í£]', law_name):
            return False
            
        # ë²•ë ¹ íƒ€ì… í¬í•¨ ì²´í¬
        if not any(law_type in law_name for law_type in self.patterns.LAW_TYPES):
            return False
            
        return True
    
    def _post_process_laws(self, laws: Set[str]) -> Set[str]:
        """ë²•ë ¹ëª… í›„ì²˜ë¦¬ - ì¤‘ë³µ ì œê±°, ì •ê·œí™”"""
        processed = set()
        
        # ì •ë ¬í•˜ì—¬ ê¸´ ê²ƒë¶€í„° ì²˜ë¦¬
        sorted_laws = sorted(laws, key=len, reverse=True)
        
        for law in sorted_laws:
            # ë¶€ë¶„ ë¬¸ìì—´ ì²´í¬
            is_substring = False
            for existing in processed:
                if law in existing and law != existing:
                    is_substring = True
                    break
                    
            if not is_substring:
                # ìµœì¢… ì •ê·œí™”
                law = law.strip()
                law = ' '.join(law.split())  # ì—°ì† ê³µë°± ì œê±°
                processed.add(law)
                
        return processed
    
    def _enhance_with_ai(self, text: str, laws: Set[str]) -> Set[str]:
        """AIë¥¼ í™œìš©í•œ ë²•ë ¹ëª… ì¶”ì¶œ ê°œì„ """
        try:
            from openai import OpenAI
            
            client = OpenAI(api_key=self.api_key)
            
            # í…ìŠ¤íŠ¸ ìƒ˜í”Œë§ (í† í° ì œí•œ)
            sample = text[:3000]
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._create_ai_prompt(sample, laws)
            
            # API í˜¸ì¶œ
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "í•œêµ­ ë²•ë ¹ ë°ì´í„°ë² ì´ìŠ¤ ì „ë¬¸ê°€"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=1000
            )
            
            # ì‘ë‹µ íŒŒì‹±
            ai_laws = self._parse_ai_response(response.choices[0].message.content)
            
            # ê²°ê³¼ ë³‘í•©
            return laws.union(ai_laws)
            
        except Exception as e:
            self.logger.error(f"AI ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return laws
    
    def _create_ai_prompt(self, text: str, existing_laws: Set[str]) -> str:
        """AI í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ í•œêµ­ ë²•ë ¹ëª…ì„ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”.

ê·œì¹™:
1. ë²•ì œì²˜ ê³µì‹ ëª…ì¹­ ì‚¬ìš©
2. "ìƒí•˜ìœ„ë²•", "ê´€ë ¨ë²•ë ¹" ê°™ì€ ì¹´í…Œê³ ë¦¬ ì œì™¸
3. ì‹œí–‰ë ¹/ì‹œí–‰ê·œì¹™ì€ ê¸°ë³¸ë²•ê³¼ í•¨ê»˜ í‘œê¸°
4. í•œ ì¤„ì— í•˜ë‚˜ì”© ì¶œë ¥

í…ìŠ¤íŠ¸:
{text}

í˜„ì¬ ì¶”ì¶œëœ ë²•ë ¹ (ì°¸ê³ ):
{', '.join(list(existing_laws)[:10])}

ë²•ë ¹ëª…ë§Œ ì¶œë ¥:"""
    
    def _parse_ai_response(self, response: str) -> Set[str]:
        """AI ì‘ë‹µ íŒŒì‹±"""
        laws = set()
        
        for line in response.strip().split('\n'):
            line = line.strip()
            
            # ë²ˆí˜¸, ê¸°í˜¸ ì œê±°
            import re
            line = re.sub(r'^[\d\-\.\*\â€¢\Â·]+\s*', '', line)
            line = line.strip('"\'')
            
            if line and self._validate_law_name(line):
                laws.add(line)
                
        return laws
    
    def _extract_from_excel(self, file) -> List[str]:
        """Excel íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        laws = set()
        
        try:
            excel_file = pd.ExcelFile(file)
            
            for sheet_name in excel_file.sheet_names:
                df = pd.read_excel(file, sheet_name=sheet_name)
                
                # ëª¨ë“  ì…€ì˜ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
                text = self._collect_excel_text(df)
                
                # ë²•ë ¹ëª… ì¶”ì¶œ
                sheet_laws = self._extract_laws_from_text(text)
                laws.update(sheet_laws)
                
        except Exception as e:
            self.logger.error(f"Excel ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            
        return sorted(list(laws))
    
    def _collect_excel_text(self, df: pd.DataFrame) -> str:
        """DataFrameì—ì„œ í…ìŠ¤íŠ¸ ìˆ˜ì§‘"""
        texts = []
        
        for column in df.columns:
            for value in df[column].dropna():
                if isinstance(value, str):
                    texts.append(value)
                    
        return '\n'.join(texts)
    
    def _extract_from_markdown(self, file) -> List[str]:
        """Markdown íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        try:
            content = file.read().decode('utf-8')
            laws = self._extract_laws_from_text(content)
            return sorted(list(laws))
        except Exception as e:
            self.logger.error(f"Markdown ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []
    
    def _extract_from_text(self, file) -> List[str]:
        """í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        try:
            content = file.read().decode('utf-8')
            laws = self._extract_laws_from_text(content)
            return sorted(list(laws))
        except Exception as e:
            self.logger.error(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []


class LawCollectorAPI:
    """ê°œì„ ëœ ë²•ë ¹ ìˆ˜ì§‘ API í´ë˜ìŠ¤"""
    
    def __init__(self, oc_code: str):
        self.oc_code = oc_code
        self.config = APIConfig()
        self.logger = logging.getLogger(self.__class__.__name__)
        self.session = self._create_session()
        
    def _create_session(self) -> requests.Session:
        """ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ì…˜ ìƒì„±"""
        session = requests.Session()
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # SSL ì¸ì¦ì„œ ê²€ì¦ í™œì„±í™” (ë³´ì•ˆ ê°•í™”)
        session.verify = True
        
        # ì¬ì‹œë„ ì„¤ì •
        from requests.adapters import HTTPAdapter
        from requests.packages.urllib3.util.retry import Retry
        
        retry_strategy = Retry(
            total=self.config.MAX_RETRIES,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504]
        )
        
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        return session
    
    def search_laws(self, law_names: List[str], 
                   progress_callback=None) -> List[Dict[str, Any]]:
        """ì—¬ëŸ¬ ë²•ë ¹ì„ ë³‘ë ¬ë¡œ ê²€ìƒ‰"""
        results = []
        
        with ThreadPoolExecutor(max_workers=self.config.MAX_CONCURRENT) as executor:
            # ê²€ìƒ‰ ì‘ì—… ì œì¶œ
            future_to_law = {
                executor.submit(self.search_single_law, law_name): law_name
                for law_name in law_names
            }
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for idx, future in enumerate(as_completed(future_to_law)):
                law_name = future_to_law[future]
                
                try:
                    result = future.result()
                    results.extend(result)
                    
                    if progress_callback:
                        progress_callback((idx + 1) / len(law_names))
                        
                except Exception as e:
                    self.logger.error(f"{law_name} ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                    
        return results
    
    def search_single_law(self, law_name: str) -> List[Dict[str, Any]]:
        """ë‹¨ì¼ ë²•ë ¹ ê²€ìƒ‰ - ì¼ë°˜ ë²•ë ¹ê³¼ í–‰ì •ê·œì¹™ ëª¨ë‘"""
        results = []
        
        # ì¼ë°˜ ë²•ë ¹ ê²€ìƒ‰
        results.extend(self._search_general_law(law_name))
        
        # í–‰ì •ê·œì¹™ ê²€ìƒ‰ (í•´ë‹¹í•˜ëŠ” ê²½ìš°)
        if any(keyword in law_name for keyword in LawPatterns.ADMIN_KEYWORDS):
            results.extend(self._search_admin_rule(law_name))
            
        # ì¤‘ë³µ ì œê±°
        return self._remove_duplicates(results)
    
    def _search_general_law(self, law_name: str) -> List[Dict[str, Any]]:
        """ì¼ë°˜ ë²•ë ¹ ê²€ìƒ‰"""
        params = {
            'OC': self.oc_code,
            'target': 'law',
            'type': 'XML',
            'query': law_name,
            'display': str(self.config.RESULTS_PER_PAGE),
            'page': '1'
        }
        
        try:
            response = self.session.get(
                self.config.LAW_SEARCH_URL,
                params=params,
                timeout=self.config.TIMEOUT
            )
            
            if response.status_code != 200:
                self.logger.warning(f"ê²€ìƒ‰ ì‹¤íŒ¨: {law_name} - {response.status_code}")
                return []
                
            # XML íŒŒì‹±
            laws = self._parse_law_search_response(response.content, law_name)
            return laws
            
        except Exception as e:
            self.logger.error(f"ì¼ë°˜ ë²•ë ¹ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def _search_admin_rule(self, law_name: str) -> List[Dict[str, Any]]:
        """í–‰ì •ê·œì¹™ ê²€ìƒ‰"""
        params = {
            'OC': self.oc_code,
            'target': 'admrul',
            'type': 'XML',
            'query': law_name,
            'display': str(self.config.RESULTS_PER_PAGE),
            'page': '1'
        }
        
        try:
            response = self.session.get(
                self.config.ADMIN_RULE_SEARCH_URL,
                params=params,
                timeout=self.config.TIMEOUT
            )
            
            if response.status_code != 200:
                return []
                
            # XML íŒŒì‹±
            rules = self._parse_admin_rule_response(response.content, law_name)
            return rules
            
        except Exception as e:
            self.logger.error(f"í–‰ì •ê·œì¹™ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def _parse_law_search_response(self, content: bytes, 
                                  search_query: str) -> List[Dict[str, Any]]:
        """ë²•ë ¹ ê²€ìƒ‰ ì‘ë‹µ íŒŒì‹±"""
        laws = []
        
        try:
            # XML íŒŒì‹±
            root = ET.fromstring(content)
            
            for law_elem in root.findall('.//law'):
                law_info = {
                    'law_id': law_elem.findtext('ë²•ë ¹ID', ''),
                    'law_msn': law_elem.findtext('ë²•ë ¹ì¼ë ¨ë²ˆí˜¸', ''),
                    'law_name': law_elem.findtext('ë²•ë ¹ëª…í•œê¸€', ''),
                    'law_type': law_elem.findtext('ë²•ì¢…êµ¬ë¶„', ''),
                    'promulgation_date': law_elem.findtext('ê³µí¬ì¼ì', ''),
                    'enforcement_date': law_elem.findtext('ì‹œí–‰ì¼ì', ''),
                    'is_admin_rule': False,
                    'search_query': search_query
                }
                
                if law_info['law_id'] and law_info['law_name']:
                    laws.append(law_info)
                    
        except ET.ParseError as e:
            self.logger.error(f"XML íŒŒì‹± ì˜¤ë¥˜: {e}")
            
        return laws
    
    def _parse_admin_rule_response(self, content: bytes, 
                                  search_query: str) -> List[Dict[str, Any]]:
        """í–‰ì •ê·œì¹™ ê²€ìƒ‰ ì‘ë‹µ íŒŒì‹±"""
        rules = []
        
        try:
            root = ET.fromstring(content)
            
            for rule_elem in root.findall('.//admrul'):
                rule_info = {
                    'law_id': rule_elem.findtext('í–‰ì •ê·œì¹™ID', ''),
                    'law_msn': rule_elem.findtext('í–‰ì •ê·œì¹™ì¼ë ¨ë²ˆí˜¸', ''),
                    'law_name': rule_elem.findtext('í–‰ì •ê·œì¹™ëª…', ''),
                    'law_type': rule_elem.findtext('í–‰ì •ê·œì¹™ì¢…ë¥˜', ''),
                    'promulgation_date': rule_elem.findtext('ë°œë ¹ì¼ì', ''),
                    'enforcement_date': rule_elem.findtext('ì‹œí–‰ì¼ì', ''),
                    'is_admin_rule': True,
                    'search_query': search_query
                }
                
                if rule_info['law_id'] and rule_info['law_name']:
                    rules.append(rule_info)
                    
        except ET.ParseError as e:
            self.logger.error(f"í–‰ì •ê·œì¹™ XML íŒŒì‹± ì˜¤ë¥˜: {e}")
            
        return rules
    
    def _remove_duplicates(self, laws: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì¤‘ë³µ ì œê±°"""
        seen = set()
        unique_laws = []
        
        for law in laws:
            law_id = law['law_id']
            if law_id not in seen:
                seen.add(law_id)
                unique_laws.append(law)
                
        return unique_laws
    
    def collect_law_details(self, laws: List[Dict[str, Any]], 
                           progress_callback=None) -> Dict[str, Dict[str, Any]]:
        """ë²•ë ¹ ìƒì„¸ ì •ë³´ ë³‘ë ¬ ìˆ˜ì§‘"""
        collected = {}
        
        with ThreadPoolExecutor(max_workers=self.config.MAX_CONCURRENT) as executor:
            # ìˆ˜ì§‘ ì‘ì—… ì œì¶œ
            future_to_law = {
                executor.submit(
                    self._get_law_detail,
                    law['law_id'],
                    law['law_msn'],
                    law['law_name'],
                    law['is_admin_rule']
                ): law
                for law in laws
            }
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for idx, future in enumerate(as_completed(future_to_law)):
                law = future_to_law[future]
                
                try:
                    detail = future.result()
                    if detail:
                        collected[law['law_id']] = detail
                        
                    if progress_callback:
                        progress_callback((idx + 1) / len(laws))
                        
                except Exception as e:
                    self.logger.error(f"{law['law_name']} ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
                    
        return collected
    
    def _get_law_detail(self, law_id: str, law_msn: str, 
                       law_name: str, is_admin_rule: bool) -> Optional[Dict[str, Any]]:
        """ë²•ë ¹ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        if is_admin_rule:
            return self._get_admin_rule_detail(law_id, law_msn, law_name)
        else:
            return self._get_general_law_detail(law_id, law_msn, law_name)
    
    def _get_general_law_detail(self, law_id: str, law_msn: str, 
                               law_name: str) -> Optional[Dict[str, Any]]:
        """ì¼ë°˜ ë²•ë ¹ ìƒì„¸ ì •ë³´"""
        params = {
            'OC': self.oc_code,
            'target': 'law',
            'type': 'XML',
            'MST': law_msn
        }
        
        try:
            response = self.session.get(
                self.config.LAW_DETAIL_URL,
                params=params,
                timeout=self.config.TIMEOUT
            )
            
            if response.status_code != 200:
                return None
                
            # ìƒì„¸ ì •ë³´ íŒŒì‹±
            return self._parse_law_detail(response.content, law_id, law_msn, law_name)
            
        except Exception as e:
            self.logger.error(f"ë²•ë ¹ ìƒì„¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None
    
    def _get_admin_rule_detail(self, law_id: str, law_msn: str, 
                              law_name: str) -> Optional[Dict[str, Any]]:
        """í–‰ì •ê·œì¹™ ìƒì„¸ ì •ë³´"""
        params = {
            'OC': self.oc_code,
            'target': 'admrul',
            'type': 'XML',
            'MST': law_msn
        }
        
        try:
            response = self.session.get(
                self.config.ADMIN_RULE_DETAIL_URL,
                params=params,
                timeout=self.config.TIMEOUT
            )
            
            if response.status_code != 200:
                return None
                
            return self._parse_law_detail(response.content, law_id, law_msn, law_name)
            
        except Exception as e:
            self.logger.error(f"í–‰ì •ê·œì¹™ ìƒì„¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None
    
    def _parse_law_detail(self, content: bytes, law_id: str, 
                         law_msn: str, law_name: str) -> Dict[str, Any]:
        """ë²•ë ¹ ìƒì„¸ ì •ë³´ íŒŒì‹±"""
        detail = {
            'law_id': law_id,
            'law_msn': law_msn,
            'law_name': law_name,
            'law_type': '',
            'promulgation_date': '',
            'enforcement_date': '',
            'articles': [],
            'supplementary_provisions': [],
            'attachments': [],
            'raw_content': ''
        }
        
        try:
            root = ET.fromstring(content)
            
            # ê¸°ë³¸ ì •ë³´
            basic_info = root.find('.//ê¸°ë³¸ì •ë³´')
            if basic_info is not None:
                detail['law_type'] = basic_info.findtext('ë²•ì¢…êµ¬ë¶„ëª…', '')
                detail['promulgation_date'] = basic_info.findtext('ê³µí¬ì¼ì', '')
                detail['enforcement_date'] = basic_info.findtext('ì‹œí–‰ì¼ì', '')
            
            # ì¡°ë¬¸ ì¶”ì¶œ
            self._extract_articles(root, detail)
            
            # ë¶€ì¹™ ì¶”ì¶œ
            self._extract_supplementary_provisions(root, detail)
            
            # ë³„í‘œ ì¶”ì¶œ
            self._extract_attachments(root, detail)
            
            # ì›ë¬¸ ì €ì¥ (ì¡°ë¬¸ì´ ì—†ëŠ” ê²½ìš°)
            if not detail['articles']:
                detail['raw_content'] = self._extract_full_text(root)
                
        except Exception as e:
            self.logger.error(f"ìƒì„¸ ì •ë³´ íŒŒì‹± ì˜¤ë¥˜: {e}")
            
        return detail
    
    def _extract_articles(self, root: ET.Element, detail: Dict[str, Any]) -> None:
        """ì¡°ë¬¸ ì¶”ì¶œ"""
        articles_section = root.find('.//ì¡°ë¬¸')
        if articles_section is None:
            return
            
        for article_unit in articles_section.findall('.//ì¡°ë¬¸ë‹¨ìœ„'):
            article = {
                'number': article_unit.findtext('ì¡°ë¬¸ë²ˆí˜¸', ''),
                'title': article_unit.findtext('ì¡°ë¬¸ì œëª©', ''),
                'content': article_unit.findtext('ì¡°ë¬¸ë‚´ìš©', ''),
                'paragraphs': []
            }
            
            # í•­ ì¶”ì¶œ
            for para in article_unit.findall('.//í•­'):
                paragraph = {
                    'number': para.findtext('í•­ë²ˆí˜¸', ''),
                    'content': para.findtext('í•­ë‚´ìš©', '')
                }
                if paragraph['content']:
                    article['paragraphs'].append(paragraph)
            
            if article['number'] or article['content']:
                detail['articles'].append(article)
    
    def _extract_supplementary_provisions(self, root: ET.Element, 
                                        detail: Dict[str, Any]) -> None:
        """ë¶€ì¹™ ì¶”ì¶œ"""
        for addendum in root.findall('.//ë¶€ì¹™'):
            provision = {
                'number': addendum.findtext('ë¶€ì¹™ë²ˆí˜¸', ''),
                'promulgation_date': addendum.findtext('ë¶€ì¹™ê³µí¬ì¼ì', ''),
                'content': self._get_all_text(addendum)
            }
            if provision['content']:
                detail['supplementary_provisions'].append(provision)
    
    def _extract_attachments(self, root: ET.Element, detail: Dict[str, Any]) -> None:
        """ë³„í‘œ/ë³„ì²¨ ì¶”ì¶œ"""
        # ë³„í‘œ
        for table in root.findall('.//ë³„í‘œ'):
            attachment = {
                'type': 'ë³„í‘œ',
                'number': table.findtext('ë³„í‘œë²ˆí˜¸', ''),
                'title': table.findtext('ë³„í‘œì œëª©', ''),
                'content': self._get_all_text(table)
            }
            if attachment['content'] or attachment['title']:
                detail['attachments'].append(attachment)
        
        # ë³„ì§€
        for form in root.findall('.//ë³„ì§€'):
            attachment = {
                'type': 'ë³„ì§€',
                'number': form.findtext('ë³„ì§€ë²ˆí˜¸', ''),
                'title': form.findtext('ë³„ì§€ì œëª©', ''),
                'content': self._get_all_text(form)
            }
            if attachment['content'] or attachment['title']:
                detail['attachments'].append(attachment)
    
    def _extract_full_text(self, root: ET.Element) -> str:
        """ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        return self._get_all_text(root)
    
    def _get_all_text(self, elem: ET.Element) -> str:
        """ìš”ì†Œì˜ ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        texts = []
        
        if elem.text:
            texts.append(elem.text.strip())
            
        for child in elem:
            child_text = self._get_all_text(child)
            if child_text:
                texts.append(child_text)
                
            if child.tail:
                texts.append(child.tail.strip())
                
        return ' '.join(texts)


class LawExporter:
    """ë²•ë ¹ ë‚´ë³´ë‚´ê¸° í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
    
    def export_to_zip(self, laws_dict: Dict[str, Dict[str, Any]]) -> bytes:
        """ZIP íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        zip_buffer = BytesIO()
        
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            # ë©”íƒ€ë°ì´í„°
            metadata = {
                'collection_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'total_laws': len(laws_dict),
                'laws': laws_dict
            }
            
            # ì „ì²´ JSON
            zip_file.writestr(
                'all_laws.json',
                json.dumps(metadata, ensure_ascii=False, indent=2)
            )
            
            # ì „ì²´ Markdown
            all_laws_md = self._create_all_laws_markdown(laws_dict)
            zip_file.writestr('all_laws.md', all_laws_md)
            
            # ê°œë³„ íŒŒì¼
            for law_id, law in laws_dict.items():
                safe_name = self._sanitize_filename(law['law_name'])
                
                # JSON
                zip_file.writestr(
                    f'laws/{safe_name}.json',
                    json.dumps(law, ensure_ascii=False, indent=2)
                )
                
                # í…ìŠ¤íŠ¸
                text_content = self._format_law_text(law)
                zip_file.writestr(f'laws/{safe_name}.txt', text_content)
                
                # Markdown
                md_content = self._format_law_markdown(law)
                zip_file.writestr(f'laws/{safe_name}.md', md_content)
            
            # README
            readme = self._create_readme(laws_dict)
            zip_file.writestr('README.md', readme)
        
        zip_buffer.seek(0)
        return zip_buffer.getvalue()
    
    def export_single_file(self, laws_dict: Dict[str, Dict[str, Any]], 
                          format: str = 'json') -> str:
        """ë‹¨ì¼ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        exporters = {
            'json': self._export_as_json,
            'markdown': self._export_as_markdown,
            'text': self._export_as_text
        }
        
        exporter = exporters.get(format, self._export_as_json)
        return exporter(laws_dict)
    
    def _sanitize_filename(self, filename: str) -> str:
        """íŒŒì¼ëª… ì•ˆì „í•˜ê²Œ ë³€í™˜"""
        import re
        return re.sub(r'[\\/*?:"<>|]', '_', filename)
    
    def _export_as_json(self, laws_dict: Dict[str, Dict[str, Any]]) -> str:
        """JSON í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        data = {
            'collection_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'total_laws': len(laws_dict),
            'laws': laws_dict
        }
        return json.dumps(data, ensure_ascii=False, indent=2)
    
    def _export_as_markdown(self, laws_dict: Dict[str, Dict[str, Any]]) -> str:
        """Markdown í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        return self._create_all_laws_markdown(laws_dict)
    
    def _export_as_text(self, laws_dict: Dict[str, Dict[str, Any]]) -> str:
        """í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        lines = []
        lines.append("ë²•ë ¹ ìˆ˜ì§‘ ê²°ê³¼")
        lines.append(f"ìˆ˜ì§‘ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"ì´ ë²•ë ¹ ìˆ˜: {len(laws_dict)}ê°œ")
        lines.append("=" * 80 + "\n")
        
        for law_id, law in laws_dict.items():
            lines.append(self._format_law_text(law))
            lines.append("\n" + "=" * 80 + "\n")
            
        return '\n'.join(lines)
    
    def _format_law_text(self, law: Dict[str, Any]) -> str:
        """ë²•ë ¹ì„ í…ìŠ¤íŠ¸ë¡œ í¬ë§·"""
        lines = []
        
        # í—¤ë”
        lines.append(f"ë²•ë ¹ëª…: {law['law_name']}")
        lines.append(f"ë²•ì¢…êµ¬ë¶„: {law.get('law_type', '')}")
        lines.append(f"ê³µí¬ì¼ì: {law.get('promulgation_date', '')}")
        lines.append(f"ì‹œí–‰ì¼ì: {law.get('enforcement_date', '')}")
        lines.append("-" * 60)
        
        # ì¡°ë¬¸
        if law.get('articles'):
            lines.append("\nã€ì¡° ë¬¸ã€‘\n")
            for article in law['articles']:
                lines.append(f"{article['number']} {article.get('title', '')}")
                lines.append(article['content'])
                
                if article.get('paragraphs'):
                    for para in article['paragraphs']:
                        lines.append(f"  {para['number']} {para['content']}")
                lines.append("")
        
        # ë¶€ì¹™
        if law.get('supplementary_provisions'):
            lines.append("\nã€ë¶€ ì¹™ã€‘\n")
            for provision in law['supplementary_provisions']:
                if provision.get('promulgation_date'):
                    lines.append(f"ë¶€ì¹™ <{provision['promulgation_date']}>")
                lines.append(provision['content'])
                lines.append("")
        
        # ë³„í‘œ
        if law.get('attachments'):
            lines.append("\nã€ë³„í‘œ/ë³„ì²¨ã€‘\n")
            for attachment in law['attachments']:
                lines.append(f"[{attachment['type']}] {attachment.get('title', '')}")
                lines.append(attachment['content'])
                lines.append("")
        
        return '\n'.join(lines)
    
    def _format_law_markdown(self, law: Dict[str, Any]) -> str:
        """ë²•ë ¹ì„ Markdownìœ¼ë¡œ í¬ë§·"""
        lines = []
        
        # ì œëª©
        lines.append(f"# {law['law_name']}\n")
        
        # ê¸°ë³¸ ì •ë³´
        lines.append("## ğŸ“‹ ê¸°ë³¸ ì •ë³´\n")
        lines.append(f"- **ë²•ì¢…êµ¬ë¶„**: {law.get('law_type', '')}")
        lines.append(f"- **ê³µí¬ì¼ì**: {law.get('promulgation_date', '')}")
        lines.append(f"- **ì‹œí–‰ì¼ì**: {law.get('enforcement_date', '')}")
        lines.append("")
        
        # ì¡°ë¬¸
        if law.get('articles'):
            lines.append("## ğŸ“– ì¡°ë¬¸\n")
            for article in law['articles']:
                lines.append(f"### {article['number']}")
                if article.get('title'):
                    lines.append(f"**{article['title']}**\n")
                lines.append(article['content'])
                
                if article.get('paragraphs'):
                    for para in article['paragraphs']:
                        lines.append(f"\n> {para['number']} {para['content']}")
                lines.append("")
        
        # ë¶€ì¹™
        if law.get('supplementary_provisions'):
            lines.append("## ğŸ“Œ ë¶€ì¹™\n")
            for provision in law['supplementary_provisions']:
                if provision.get('promulgation_date'):
                    lines.append(f"### ë¶€ì¹™ <{provision['promulgation_date']}>")
                lines.append(provision['content'])
                lines.append("")
        
        # ë³„í‘œ
        if law.get('attachments'):
            lines.append("## ğŸ“ ë³„í‘œ/ë³„ì²¨\n")
            for attachment in law['attachments']:
                lines.append(f"### [{attachment['type']}] {attachment.get('title', '')}")
                lines.append(attachment['content'])
                lines.append("")
        
        return '\n'.join(lines)
    
    def _create_all_laws_markdown(self, laws_dict: Dict[str, Dict[str, Any]]) -> str:
        """ì „ì²´ ë²•ë ¹ Markdown ìƒì„±"""
        lines = []
        
        # í—¤ë”
        lines.append("# ğŸ“š ë²•ë ¹ ìˆ˜ì§‘ ê²°ê³¼\n")
        lines.append(f"**ìˆ˜ì§‘ ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"**ì´ ë²•ë ¹ ìˆ˜**: {len(laws_dict)}ê°œ\n")
        
        # ëª©ì°¨
        lines.append("## ğŸ“‘ ëª©ì°¨\n")
        for idx, (law_id, law) in enumerate(laws_dict.items(), 1):
            anchor = self._sanitize_filename(law['law_name'])
            lines.append(f"{idx}. [{law['law_name']}](#{anchor})")
        lines.append("\n---\n")
        
        # ê° ë²•ë ¹
        for law_id, law in laws_dict.items():
            lines.append(self._format_law_markdown(law))
            lines.append("\n---\n")
            
        return '\n'.join(lines)
    
    def _create_readme(self, laws_dict: Dict[str, Dict[str, Any]]) -> str:
        """README ìƒì„±"""
        # í†µê³„ ê³„ì‚°
        total_articles = sum(len(law.get('articles', [])) for law in laws_dict.values())
        total_provisions = sum(len(law.get('supplementary_provisions', [])) for law in laws_dict.values())
        total_attachments = sum(len(law.get('attachments', [])) for law in laws_dict.values())
        
        content = f"""# ë²•ë ¹ ìˆ˜ì§‘ ê²°ê³¼

ìˆ˜ì§‘ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ì´ ë²•ë ¹ ìˆ˜: {len(laws_dict)}ê°œ

## ğŸ“ íŒŒì¼ êµ¬ì¡°

- `all_laws.json`: ì „ì²´ ë²•ë ¹ ë°ì´í„° (JSON)
- `all_laws.md`: ì „ì²´ ë²•ë ¹ í†µí•© ë¬¸ì„œ (Markdown)
- `laws/`: ê°œë³„ ë²•ë ¹ íŒŒì¼
  - `*.json`: ë²•ë ¹ë³„ ìƒì„¸ ë°ì´í„°
  - `*.txt`: ë²•ë ¹ë³„ í…ìŠ¤íŠ¸
  - `*.md`: ë²•ë ¹ë³„ Markdown
- `README.md`: ì´ íŒŒì¼

## ğŸ“Š í†µê³„

- ì´ ì¡°ë¬¸ ìˆ˜: {total_articles:,}ê°œ
- ì´ ë¶€ì¹™ ìˆ˜: {total_provisions}ê°œ
- ì´ ë³„í‘œ/ë³„ì²¨ ìˆ˜: {total_attachments}ê°œ

## ğŸ“– ìˆ˜ì§‘ëœ ë²•ë ¹ ëª©ë¡

"""
        
        for law_id, law in laws_dict.items():
            content += f"\n### {law['law_name']}\n"
            content += f"- ë²•ì¢…êµ¬ë¶„: {law.get('law_type', '')}\n"
            content += f"- ì‹œí–‰ì¼ì: {law.get('enforcement_date', '')}\n"
            content += f"- ì¡°ë¬¸: {len(law.get('articles', []))}ê°œ\n"
            
        return content


# Streamlit UI í—¬í¼ í•¨ìˆ˜ë“¤
def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    defaults = {
        'mode': 'direct',
        'extracted_laws': [],
        'search_results': [],
        'selected_laws': [],
        'collected_laws': {},
        'file_processed': False,
        'openai_api_key': None,
        'use_ai': False,
        'oc_code': ''
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value


def show_sidebar():
    """ì‚¬ì´ë“œë°” UI"""
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # ê¸°ê´€ì½”ë“œ
        oc_code = st.text_input(
            "ê¸°ê´€ì½”ë“œ (OC)",
            value=st.session_state.get('oc_code', ''),
            placeholder="ì´ë©”ì¼ @ ì•ë¶€ë¶„",
            help="ì˜ˆ: test@korea.kr â†’ test"
        )
        st.session_state.oc_code = oc_code
        
        st.divider()
        
        # AI ì„¤ì •
        with st.expander("ğŸ¤– AI ì„¤ì • (ì„ íƒì‚¬í•­)", expanded=False):
            st.markdown("**ChatGPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë²•ë ¹ëª… ì¶”ì¶œ ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤**")
            
            api_key = st.text_input(
                "OpenAI API Key",
                type="password",
                value=st.session_state.get('openai_api_key', ''),
                help="https://platform.openai.com/api-keys ì—ì„œ ë°œê¸‰"
            )
            
            if api_key:
                st.session_state.openai_api_key = api_key
                st.session_state.use_ai = True
                st.success("âœ… API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
            else:
                st.session_state.use_ai = False
                st.info("ğŸ’¡ API í‚¤ë¥¼ ì…ë ¥í•˜ë©´ ë” ì •í™•í•œ ë²•ë ¹ëª… ì¶”ì¶œì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        st.divider()
        
        # ëª¨ë“œ ì„ íƒ
        st.subheader("ğŸ¯ ìˆ˜ì§‘ ë°©ì‹")
        mode = st.radio(
            "ë°©ì‹ ì„ íƒ",
            ["ì§ì ‘ ê²€ìƒ‰", "íŒŒì¼ ì—…ë¡œë“œ"],
            help="ì§ì ‘ ê²€ìƒ‰: ë²•ë ¹ëª…ì„ ì…ë ¥í•˜ì—¬ ê²€ìƒ‰\níŒŒì¼ ì—…ë¡œë“œ: íŒŒì¼ì—ì„œ ë²•ë ¹ ì¶”ì¶œ"
        )
        st.session_state.mode = 'direct' if mode == "ì§ì ‘ ê²€ìƒ‰" else 'file'
        
        # ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ”„ ì´ˆê¸°í™”", type="secondary", use_container_width=True):
            keys_to_keep = ['mode', 'openai_api_key', 'use_ai', 'oc_code']
            for key in list(st.session_state.keys()):
                if key not in keys_to_keep:
                    del st.session_state[key]
            st.session_state.file_processed = False
            st.rerun()
        
        return oc_code


def handle_direct_search_mode(oc_code: str):
    """ì§ì ‘ ê²€ìƒ‰ ëª¨ë“œ ì²˜ë¦¬"""
    st.header("ğŸ” ì§ì ‘ ê²€ìƒ‰ ëª¨ë“œ")
    
    law_name = st.text_input(
        "ë²•ë ¹ëª…",
        placeholder="ì˜ˆ: ë¯¼ë²•, ìƒë²•, í˜•ë²•",
        help="ê²€ìƒ‰í•  ë²•ë ¹ëª…ì„ ì…ë ¥í•˜ì„¸ìš”"
    )
    
    if st.button("ğŸ” ê²€ìƒ‰", type="primary", use_container_width=True):
        if not oc_code:
            st.error("ê¸°ê´€ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        elif not law_name:
            st.error("ë²•ë ¹ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        else:
            with st.spinner(f"'{law_name}' ê²€ìƒ‰ ì¤‘..."):
                collector = LawCollectorAPI(oc_code)
                results = collector.search_single_law(law_name)
                
                if results:
                    st.success(f"{len(results)}ê°œì˜ ë²•ë ¹ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                    st.session_state.search_results = results
                else:
                    st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    st.session_state.search_results = []


def handle_file_upload_mode(oc_code: str):
    """íŒŒì¼ ì—…ë¡œë“œ ëª¨ë“œ ì²˜ë¦¬"""
    st.header("ğŸ“„ íŒŒì¼ ì—…ë¡œë“œ ëª¨ë“œ")
    
    # AI ìƒíƒœ í‘œì‹œ
    if st.session_state.use_ai:
        st.info("ğŸ¤– AI ê°•í™” ëª¨ë“œê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤")
    else:
        st.info("ğŸ’¡ AI ì„¤ì •ì„ í†µí•´ ë²•ë ¹ëª… ì¶”ì¶œ ì •í™•ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    
    uploaded_file = st.file_uploader(
        "íŒŒì¼ ì„ íƒ",
        type=['pdf', 'xlsx', 'xls', 'md', 'txt'],
        help="PDF, Excel, Markdown, í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì§€ì›í•©ë‹ˆë‹¤"
    )
    
    if uploaded_file and not st.session_state.file_processed:
        st.subheader("ğŸ“‹ STEP 1: ë²•ë ¹ëª… ì¶”ì¶œ")
        
        with st.spinner("íŒŒì¼ì—ì„œ ë²•ë ¹ëª…ì„ ì¶”ì¶œí•˜ëŠ” ì¤‘..."):
            extractor = EnhancedLawFileExtractor(
                use_ai=st.session_state.use_ai,
                api_key=st.session_state.openai_api_key
            )
            
            file_type = uploaded_file.name.split('.')[-1].lower()
            
            try:
                extracted_laws = extractor.extract_from_file(uploaded_file, file_type)
                
                if extracted_laws:
                    st.success(f"âœ… {len(extracted_laws)}ê°œì˜ ë²•ë ¹ëª…ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                    st.session_state.extracted_laws = extracted_laws
                    st.session_state.file_processed = True
                else:
                    st.warning("íŒŒì¼ì—ì„œ ë²•ë ¹ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    
            except Exception as e:
                st.error(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
    
    # ì¶”ì¶œëœ ë²•ë ¹ í‘œì‹œ
    if st.session_state.extracted_laws:
        display_extracted_laws(oc_code)


def display_extracted_laws(oc_code: str):
    """ì¶”ì¶œëœ ë²•ë ¹ í‘œì‹œ ë° í¸ì§‘"""
    st.subheader("âœï¸ STEP 2: ë²•ë ¹ëª… í™•ì¸ ë° í¸ì§‘")
    
    # ì¶”ì¶œëœ ë²•ë ¹ ëª©ë¡
    st.write("**ì¶”ì¶œëœ ë²•ë ¹ëª…:**")
    for idx, law in enumerate(st.session_state.extracted_laws, 1):
        st.write(f"{idx}. {law}")
    
    # í¸ì§‘ ì˜ì—­
    edited_laws = []
    st.write("\n**ë²•ë ¹ëª… í¸ì§‘:**")
    
    for idx, law_name in enumerate(st.session_state.extracted_laws):
        col1, col2 = st.columns([4, 1])
        with col1:
            edited_name = st.text_input(
                f"ë²•ë ¹ {idx+1}",
                value=law_name,
                key=f"edit_{idx}"
            )
            if edited_name:
                edited_laws.append(edited_name)
        with col2:
            if st.button("ì‚­ì œ", key=f"del_{idx}"):
                st.session_state.extracted_laws.pop(idx)
                st.rerun()
    
    # ë²•ë ¹ëª… ì¶”ê°€
    st.subheader("ë²•ë ¹ëª… ì¶”ê°€")
    new_law = st.text_input("ìƒˆ ë²•ë ¹ëª… ì…ë ¥", key="new_law_input")
    if st.button("â• ì¶”ê°€") and new_law:
        st.session_state.extracted_laws.append(new_law)
        st.rerun()
    
    # ê²€ìƒ‰ ë²„íŠ¼
    if st.button("ğŸ” ë²•ë ¹ ê²€ìƒ‰", type="primary", use_container_width=True):
        if not oc_code:
            st.error("ê¸°ê´€ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        else:
            search_laws_from_list(oc_code, edited_laws or st.session_state.extracted_laws)


def search_laws_from_list(oc_code: str, law_names: List[str]):
    """ë²•ë ¹ ëª©ë¡ ê²€ìƒ‰"""
    collector = LawCollectorAPI(oc_code)
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    def update_progress(progress):
        progress_bar.progress(progress)
    
    with st.spinner("ë²•ë ¹ì„ ê²€ìƒ‰í•˜ëŠ” ì¤‘..."):
        results = collector.search_laws(law_names, progress_callback=update_progress)
    
    progress_bar.progress(1.0)
    status_text.text("ê²€ìƒ‰ ì™„ë£Œ!")
    
    if results:
        st.success(f"âœ… ì´ {len(results)}ê°œì˜ ë²•ë ¹ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
        st.session_state.search_results = results
    else:
        st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")


def display_search_results_and_collect(oc_code: str):
    """ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ ë° ìˆ˜ì§‘"""
    if not st.session_state.search_results:
        return
        
    st.subheader("ğŸ“‘ ê²€ìƒ‰ ê²°ê³¼")
    
    # ì „ì²´ ì„ íƒ
    select_all = st.checkbox("ì „ì²´ ì„ íƒ")
    
    # í…Œì´ë¸” í—¤ë”
    cols = st.columns([1, 3, 2, 2, 2])
    headers = ["ì„ íƒ", "ë²•ë ¹ëª…", "ë²•ì¢…êµ¬ë¶„", "ì‹œí–‰ì¼ì", "ê²€ìƒ‰ì–´"]
    for col, header in zip(cols, headers):
        col.markdown(f"**{header}**")
    
    st.divider()
    
    # ê²°ê³¼ í‘œì‹œ
    selected_indices = []
    for idx, law in enumerate(st.session_state.search_results):
        cols = st.columns([1, 3, 2, 2, 2])
        
        with cols[0]:
            if st.checkbox("", key=f"sel_{idx}", value=select_all):
                selected_indices.append(idx)
        
        with cols[1]:
            st.write(law['law_name'])
        
        with cols[2]:
            st.write(law.get('law_type', ''))
        
        with cols[3]:
            st.write(law.get('enforcement_date', ''))
        
        with cols[4]:
            st.write(law.get('search_query', ''))
    
    # ì„ íƒëœ ë²•ë ¹ ì €ì¥
    st.session_state.selected_laws = [
        st.session_state.search_results[i] for i in selected_indices
    ]
    
    if st.session_state.selected_laws:
        st.success(f"{len(st.session_state.selected_laws)}ê°œ ë²•ë ¹ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤")
        
        # ìˆ˜ì§‘ ë²„íŠ¼
        if st.button("ğŸ“¥ ì„ íƒí•œ ë²•ë ¹ ìˆ˜ì§‘", type="primary", use_container_width=True):
            collect_selected_laws(oc_code)


def collect_selected_laws(oc_code: str):
    """ì„ íƒëœ ë²•ë ¹ ìˆ˜ì§‘"""
    collector = LawCollectorAPI(oc_code)
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    def update_progress(progress):
        progress_bar.progress(progress)
        
    with st.spinner("ë²•ë ¹ ìƒì„¸ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì¤‘..."):
        collected = collector.collect_law_details(
            st.session_state.selected_laws,
            progress_callback=update_progress
        )
    
    progress_bar.progress(1.0)
    status_text.text("ìˆ˜ì§‘ ì™„ë£Œ!")
    
    st.session_state.collected_laws = collected
    
    # í†µê³„ í‘œì‹œ
    display_collection_stats(collected)


def display_collection_stats(collected_laws: Dict[str, Dict[str, Any]]):
    """ìˆ˜ì§‘ í†µê³„ í‘œì‹œ"""
    total_articles = sum(len(law.get('articles', [])) for law in collected_laws.values())
    total_provisions = sum(len(law.get('supplementary_provisions', [])) for law in collected_laws.values())
    total_attachments = sum(len(law.get('attachments', [])) for law in collected_laws.values())
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ì´ ì¡°ë¬¸", f"{total_articles:,}ê°œ")
    with col2:
        st.metric("ì´ ë¶€ì¹™", f"{total_provisions}ê°œ")
    with col3:
        st.metric("ì´ ë³„í‘œ/ë³„ì²¨", f"{total_attachments}ê°œ")


def display_download_section():
    """ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ í‘œì‹œ"""
    if not st.session_state.collected_laws:
        return
        
    st.header("ğŸ’¾ ë‹¤ìš´ë¡œë“œ")
    
    exporter = LawExporter()
    
    # ë‹¤ìš´ë¡œë“œ ì˜µì…˜
    st.subheader("ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì˜µì…˜")
    download_option = st.radio(
        "ë‹¤ìš´ë¡œë“œ ë°©ì‹ ì„ íƒ",
        ["ê°œë³„ íŒŒì¼ (ZIP)", "í†µí•© íŒŒì¼ (ë‹¨ì¼)"],
        help="ê°œë³„ íŒŒì¼: ê° ë²•ë ¹ë³„ë¡œ íŒŒì¼ ìƒì„±\ní†µí•© íŒŒì¼: ëª¨ë“  ë²•ë ¹ì„ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ"
    )
    
    if download_option == "ê°œë³„ íŒŒì¼ (ZIP)":
        # ZIP ë‹¤ìš´ë¡œë“œ
        zip_data = exporter.export_to_zip(st.session_state.collected_laws)
        
        st.download_button(
            label="ğŸ“¦ ZIP ë‹¤ìš´ë¡œë“œ (JSON+TXT+MD)",
            data=zip_data,
            file_name=f"laws_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
            mime="application/zip",
            use_container_width=True
        )
    else:
        # í†µí•© íŒŒì¼
        file_format = st.selectbox(
            "íŒŒì¼ í˜•ì‹ ì„ íƒ",
            ["JSON", "Markdown", "Text"]
        )
        
        format_map = {
            "JSON": ("json", "application/json", "json"),
            "Markdown": ("markdown", "text/markdown", "md"),
            "Text": ("text", "text/plain", "txt")
        }
        
        fmt, mime, ext = format_map[file_format]
        content = exporter.export_single_file(st.session_state.collected_laws, fmt)
        
        st.download_button(
            label=f"ğŸ’¾ {file_format} í†µí•© íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            data=content,
            file_name=f"all_laws_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{ext}",
            mime=mime,
            use_container_width=True
        )
    
    # ìˆ˜ì§‘ ê²°ê³¼ ìƒì„¸
    with st.expander("ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìƒì„¸"):
        for law_id, law in st.session_state.collected_laws.items():
            st.subheader(law['law_name'])
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.write(f"ì¡°ë¬¸: {len(law.get('articles', []))}ê°œ")
            with col2:
                st.write(f"ë¶€ì¹™: {len(law.get('supplementary_provisions', []))}ê°œ")
            with col3:
                st.write(f"ë³„í‘œ: {len(law.get('attachments', []))}ê°œ")
            
            # ìƒ˜í”Œ ì¡°ë¬¸
            if law.get('articles'):
                st.write("**ìƒ˜í”Œ ì¡°ë¬¸:**")
                sample = law['articles'][0]
                st.text(f"{sample['number']} {sample.get('title', '')}")
                st.text(sample['content'][:200] + "...")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    initialize_session_state()
    
    # ì œëª©
    st.title("ğŸ“š ë²•ì œì²˜ ë²•ë ¹ ìˆ˜ì§‘ê¸°")
    st.markdown("ë²•ì œì²˜ Open APIë¥¼ í™œìš©í•œ ë²•ë ¹ ìˆ˜ì§‘ ë„êµ¬ (v4.0)")
    
    # ì‚¬ì´ë“œë°”
    oc_code = show_sidebar()
    
    # ëª¨ë“œë³„ ì²˜ë¦¬
    if st.session_state.mode == 'direct':
        handle_direct_search_mode(oc_code)
    else:
        handle_file_upload_mode(oc_code)
    
    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
    if st.session_state.search_results:
        display_search_results_and_collect(oc_code)
    
    # ë‹¤ìš´ë¡œë“œ ì„¹ì…˜
    display_download_section()


if __name__ == "__main__":
    main()
