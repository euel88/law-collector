"""
ë²•ì œì²˜ ë²•ë ¹ ìˆ˜ì§‘ê¸° - ë²„ê·¸ ìˆ˜ì • ì™„ë£Œ (v6.1)
- OpenAI API í‚¤ ì‚¬ì´ë“œë°” ì§ì ‘ ì…ë ¥ ë°©ì‹ ìœ ì§€
- í–‰ì •ê·œì¹™ API URL ìˆ˜ì •
- ì ‘ê·¼ì„± ê²½ê³  í•´ê²°
- ë³´ì•ˆ ê°•í™”
"""

import streamlit as st
import requests
import xml.etree.ElementTree as ET
import json
import time
import re
import os
from datetime import datetime
from io import BytesIO
import zipfile
import pandas as pd
import PyPDF2
import pdfplumber
from typing import List, Set, Dict, Optional, Tuple, Any
from dataclasses import dataclass
from functools import lru_cache
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ“š ë²•ì œì²˜ ë²•ë ¹ ìˆ˜ì§‘ê¸°",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===== ì„¤ì • í´ë˜ìŠ¤ =====
@dataclass
class APIConfig:
    """API ì„¤ì •ì„ ê´€ë¦¬í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    # ë²•ì œì²˜ API ì—”ë“œí¬ì¸íŠ¸ (ìˆ˜ì •ë¨)
    LAW_SEARCH_URL = "https://www.law.go.kr/DRF/lawSearch.do"
    LAW_DETAIL_URL = "https://www.law.go.kr/DRF/lawService.do"
    # í–‰ì •ê·œì¹™ API URL ìˆ˜ì • (admRulScë¡œ ë³€ê²½)
    ADMIN_RULE_SEARCH_URL = "https://www.law.go.kr/DRF/admRulSc.do"
    ADMIN_RULE_DETAIL_URL = "https://www.law.go.kr/DRF/admRulInfoR.do"
    
    # API ì„¤ì •
    DEFAULT_DELAY = 0.3  # API í˜¸ì¶œ ê°„ê²© (ì´ˆ)
    MAX_RETRIES = 3      # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
    TIMEOUT = 30         # íƒ€ì„ì•„ì›ƒ (ì´ˆ)
    MAX_CONCURRENT = 5   # ìµœëŒ€ ë™ì‹œ ìš”ì²­ ìˆ˜
    
    # í˜ì´ì§€ë‹¹ ê²°ê³¼ ìˆ˜
    RESULTS_PER_PAGE = 100


class LawPatterns:
    """ë²•ë ¹ëª… ì¶”ì¶œ íŒ¨í„´ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    # ì œì™¸ í‚¤ì›Œë“œ
    EXCLUDE_KEYWORDS = {
        'ìƒí•˜ìœ„ë²•', 'í–‰ì •ê·œì¹™', 'ë²•ë ¹', 'ì‹œí–‰ë ¹', 'ì‹œí–‰ê·œì¹™', 'ëŒ€í†µë ¹ë ¹', 
        'ì´ë¦¬ë ¹', 'ë¶€ë ¹', 'ê´€í•œ ê·œì •', 'ìƒìœ„ë²•', 'í•˜ìœ„ë²•', 'ê´€ë ¨ë²•ë ¹'
    }
    
    # ë²•ë ¹ íƒ€ì…
    LAW_TYPES = {
        'ë²•', 'ë²•ë¥ ', 'ì‹œí–‰ë ¹', 'ì‹œí–‰ê·œì¹™', 'ê·œì •', 'ê·œì¹™', 'ì„¸ì¹™', 
        'ê³ ì‹œ', 'í›ˆë ¹', 'ì˜ˆê·œ', 'ì§€ì¹¨', 'ë¶„ë¥˜', 'ì—…ë¬´ê·œì •', 'ê°ë…ê·œì •'
    }
    
    # í–‰ì •ê·œì¹™ í‚¤ì›Œë“œ
    ADMIN_KEYWORDS = {
        'ê·œì •', 'ê³ ì‹œ', 'í›ˆë ¹', 'ì˜ˆê·œ', 'ì§€ì¹¨', 'ì„¸ì¹™', 'ê¸°ì¤€', 'ìš”ë ¹', 'ì§€ì‹œ'
    }
    
    # ë²•ë ¹ëª… íŒ¨í„´ (ì •ê·œí‘œí˜„ì‹)
    LAW_PATTERNS = [
        # ì‹œí–‰ ë‚ ì§œ í¬í•¨ íŒ¨í„´
        r'([ê°€-í£]+(?:\s+[ê°€-í£]+)*(?:ë²•|ë²•ë¥ |ê·œì •|ê·œì¹™|ì„¸ì¹™|ë¶„ë¥˜))\s*\[ì‹œí–‰\s*\d{4}\.\s*\d{1,2}\.\s*\d{1,2}\.\]',
        # ë…ë¦½ì ì¸ ê·œì •/ì„¸ì¹™
        r'^([ê°€-í£]+(?:(?:\s+ë°\s+)|(?:\s+))?[ê°€-í£]*(?:ì—\s*ê´€í•œ\s*)?(?:ê·œì •|ì—…ë¬´ê·œì •|ê°ë…ê·œì •|ìš´ì˜ê·œì •|ê´€ë¦¬ê·œì •))(?:\s|$)',
        # ì‹œí–‰ì„¸ì¹™
        r'^([ê°€-í£]+(?:(?:\s+ë°\s+)|(?:\s+))?[ê°€-í£]*(?:ì—…ë¬´)?ì‹œí–‰ì„¸ì¹™)(?:\s|$)',
        # ë¶™ì–´ìˆëŠ” í˜•íƒœ
        r'([ê°€-í£]+(?:ê²€ì‚¬ë°ì œì¬ì—ê´€í•œ|ì—ê´€í•œ)?ê·œì •)(?:\s|$)',
        # ì¼ë°˜ ë²•ë¥ 
        r'^([ê°€-í£]+(?:\s+[ê°€-í£]+)*(?:ì—\s*ê´€í•œ\s*)?(?:íŠ¹ë³„|ê¸°ë³¸|ê´€ë¦¬|ì´‰ì§„|ì§€ì›|ìœ¡ì„±|ì§„í¥|ë³´í˜¸|ê·œì œ|ë°©ì§€)?ë²•(?:ë¥ )?)(?:\s|$)',
        # ì‹œí–‰ë ¹/ì‹œí–‰ê·œì¹™
        r'^([ê°€-í£]+(?:\s+[ê°€-í£]+)*ë²•(?:ë¥ )?)\s+ì‹œí–‰ë ¹(?:\s|$)',
        r'^([ê°€-í£]+(?:\s+[ê°€-í£]+)*ë²•(?:ë¥ )?)\s+ì‹œí–‰ê·œì¹™(?:\s|$)',
    ]


# ===== íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ í´ë˜ìŠ¤ =====
class EnhancedLawFileExtractor:
    """ê°œì„ ëœ ë²•ë ¹ëª… ì¶”ì¶œ í´ë˜ìŠ¤"""
    
    def __init__(self, use_ai: bool = False, api_key: Optional[str] = None):
        self.patterns = LawPatterns()
        self.use_ai = use_ai
        self.api_key = api_key
        self.logger = logging.getLogger(self.__class__.__name__)
        
    def extract_from_file(self, file, file_type: str) -> List[str]:
        """íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ì¶”ì¶œ ë©”ì„œë“œ ë””ìŠ¤íŒ¨ì¹˜"""
        extractors = {
            'pdf': self._extract_from_pdf,
            'xlsx': self._extract_from_excel,
            'xls': self._extract_from_excel,
            'md': self._extract_from_markdown,
            'txt': self._extract_from_text
        }
        
        extractor = extractors.get(file_type.lower())
        if not extractor:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_type}")
            
        return extractor(file)
    
    def _extract_from_pdf(self, file) -> List[str]:
        """PDF íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        try:
            text = self._read_pdf_content(file)
            laws = self._extract_laws_from_text(text)
            
            if self.use_ai and self.api_key:
                laws = self._enhance_with_ai(text, laws)
                
            return sorted(list(laws))
            
        except Exception as e:
            self.logger.error(f"PDF ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            st.error(f"PDF íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return []
    
    def _read_pdf_content(self, file) -> str:
        """PDF ë‚´ìš© ì½ê¸° - pdfplumber ìš°ì„ , ì‹¤íŒ¨ì‹œ PyPDF2"""
        text = ""
        
        # pdfplumber ì‹œë„
        try:
            with pdfplumber.open(file) as pdf:
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
            return text
        except Exception as e:
            self.logger.warning(f"pdfplumber ì‹¤íŒ¨: {e}")
        
        # PyPDF2 í´ë°±
        try:
            file.seek(0)
            pdf_reader = PyPDF2.PdfReader(file)
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
            return text
        except Exception as e:
            self.logger.error(f"PyPDF2ë„ ì‹¤íŒ¨: {e}")
            raise
    
    def _extract_laws_from_text(self, text: str) -> Set[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        laws = set()
        
        # í…ìŠ¤íŠ¸ ì •ê·œí™”
        text = self._normalize_text(text)
        
        # íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ë²•ë ¹ëª… ì¶”ì¶œ
        for pattern in self.patterns.LAW_PATTERNS:
            matches = re.findall(pattern, text, re.MULTILINE | re.IGNORECASE)
            for match in matches:
                law_name = self._clean_law_name(match)
                if self._validate_law_name(law_name):
                    laws.add(law_name)
        
        # ë¼ì¸ë³„ ì¶”ê°€ ì²˜ë¦¬
        for line in text.split('\n'):
            line = line.strip()
            if line in self.patterns.EXCLUDE_KEYWORDS:
                continue
            
            # ë²•ë ¹ íƒ€ì…ë³„ ë§¤ì¹­
            for law_type in self.patterns.LAW_TYPES:
                if law_type in line:
                    law_name = self._extract_law_name_from_line(line, law_type)
                    if law_name and self._validate_law_name(law_name):
                        laws.add(law_name)
        
        # í›„ì²˜ë¦¬
        laws = self._post_process_laws(laws)
        
        return laws
    
    def _normalize_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ê·œí™”"""
        # ì—°ì† ê³µë°± ì œê±°
        text = ' '.join(text.split())
        
        # í‘œì¤€í™”
        replacements = {
            'ì—ê´€í•œ': 'ì— ê´€í•œ',
            'ë°': ' ë° ',
            'Â·': 'Â·',  # ì¤‘ì  í†µì¼
            'ï¼Œ': ',',  # ì‰¼í‘œ í†µì¼
        }
        
        for old, new in replacements.items():
            text = text.replace(old, new)
            
        return text
    
    def _clean_law_name(self, law_name: str) -> str:
        """ë²•ë ¹ëª… ì •ì œ"""
        if not isinstance(law_name, str):
            law_name = str(law_name)
        
        # ì‹œí–‰ ì •ë³´ ì œê±°
        law_name = re.sub(r'\s*\[ì‹œí–‰[^\]]+\]', '', law_name)
        
        # ì•ë’¤ ê³µë°± ì œê±°
        law_name = law_name.strip()
        
        # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        law_name = ' '.join(law_name.split())
        
        # ë¶™ì–´ìˆëŠ” í˜•íƒœ ì •ê·œí™”
        law_name = re.sub(r'ê²€ì‚¬ë°', 'ê²€ì‚¬ ë° ', law_name)
        law_name = re.sub(r'ì—ê´€í•œ', 'ì— ê´€í•œ ', law_name)
        
        return law_name
    
    def _extract_law_name_from_line(self, line: str, law_type: str) -> Optional[str]:
        """ë¼ì¸ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        # ë²•ë ¹ íƒ€ì… ìœ„ì¹˜ ì°¾ê¸°
        type_pos = line.find(law_type)
        if type_pos == -1:
            return None
            
        # ì‹œì‘ ìœ„ì¹˜ ì°¾ê¸° (í•œê¸€ë¡œ ì‹œì‘)
        start = 0
        for i in range(type_pos - 1, -1, -1):
            if not (line[i].isalnum() or line[i] in ' Â·ë°ê´€í•œì˜ì—'):
                start = i + 1
                break
        
        # ë ìœ„ì¹˜ëŠ” ë²•ë ¹ íƒ€ì… ë’¤
        end = type_pos + len(law_type)
        
        # ì‹œí–‰ë ¹/ì‹œí–‰ê·œì¹™ ì²˜ë¦¬
        if end < len(line) - 3:
            next_chars = line[end:end+4]
            if 'ì‹œí–‰ë ¹' in next_chars or 'ì‹œí–‰ê·œì¹™' in next_chars:
                space_pos = line.find(' ', end)
                if space_pos != -1:
                    end = space_pos
                else:
                    end = len(line)
        
        return line[start:end].strip()
    
    def _validate_law_name(self, law_name: str) -> bool:
        """ë²•ë ¹ëª… ìœ íš¨ì„± ê²€ì¦"""
        # ê¸¸ì´ ì²´í¬
        if len(law_name) < 3 or len(law_name) > 100:
            return False
            
        # ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
        if law_name in self.patterns.EXCLUDE_KEYWORDS:
            return False
            
        # í•œê¸€ í¬í•¨ ì²´í¬
        if not re.search(r'[ê°€-í£]', law_name):
            return False
            
        # ë²•ë ¹ íƒ€ì… í¬í•¨ ì²´í¬
        if not any(law_type in law_name for law_type in self.patterns.LAW_TYPES):
            return False
            
        return True
    
    def _post_process_laws(self, laws: Set[str]) -> Set[str]:
        """ë²•ë ¹ëª… í›„ì²˜ë¦¬ - ì¤‘ë³µ ì œê±°, ì •ê·œí™”"""
        processed = set()
        
        # ì •ë ¬í•˜ì—¬ ê¸´ ê²ƒë¶€í„° ì²˜ë¦¬
        sorted_laws = sorted(laws, key=len, reverse=True)
        
        for law in sorted_laws:
            # ë¶€ë¶„ ë¬¸ìì—´ ì²´í¬
            is_substring = False
            for existing in processed:
                if law in existing and law != existing:
                    is_substring = True
                    break
                    
            if not is_substring:
                # ìµœì¢… ì •ê·œí™”
                law = law.strip()
                law = ' '.join(law.split())  # ì—°ì† ê³µë°± ì œê±°
                processed.add(law)
                
        return processed
    
    def _enhance_with_ai(self, text: str, laws: Set[str]) -> Set[str]:
        """AIë¥¼ í™œìš©í•œ ë²•ë ¹ëª… ì¶”ì¶œ ê°œì„ """
        try:
            # OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì²´í¬
            try:
                from openai import OpenAI
            except ImportError:
                self.logger.warning("OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return laws
            
            # API í‚¤ ìœ íš¨ì„± ê²€ì¦
            if not self.api_key or not self.api_key.startswith('sk-'):
                self.logger.warning("ìœ íš¨í•˜ì§€ ì•Šì€ OpenAI API í‚¤")
                return laws
            
            client = OpenAI(api_key=self.api_key)
            
            # í…ìŠ¤íŠ¸ ìƒ˜í”Œë§ (í† í° ì œí•œ)
            sample = text[:3000]
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._create_ai_prompt(sample, laws)
            
            # API í˜¸ì¶œ (ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”)
            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "í•œêµ­ ë²•ë ¹ ë°ì´í„°ë² ì´ìŠ¤ ì „ë¬¸ê°€"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.1,
                    max_tokens=1000
                )
                
                # ì‘ë‹µ íŒŒì‹±
                ai_laws = self._parse_ai_response(response.choices[0].message.content)
                
                # ê²°ê³¼ ë³‘í•©
                return laws.union(ai_laws)
                
            except Exception as api_error:
                self.logger.error(f"OpenAI API í˜¸ì¶œ ì˜¤ë¥˜: {api_error}")
                st.warning("AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì¶”ì¶œ ê²°ê³¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                return laws
            
        except Exception as e:
            self.logger.error(f"AI ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return laws
    
    def _create_ai_prompt(self, text: str, existing_laws: Set[str]) -> str:
        """AI í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ í•œêµ­ ë²•ë ¹ëª…ì„ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”.

ê·œì¹™:
1. ë²•ì œì²˜ ê³µì‹ ëª…ì¹­ ì‚¬ìš©
2. "ìƒí•˜ìœ„ë²•", "ê´€ë ¨ë²•ë ¹" ê°™ì€ ì¹´í…Œê³ ë¦¬ ì œì™¸
3. ì‹œí–‰ë ¹/ì‹œí–‰ê·œì¹™ì€ ê¸°ë³¸ë²•ê³¼ í•¨ê»˜ í‘œê¸°
4. í•œ ì¤„ì— í•˜ë‚˜ì”© ì¶œë ¥

í…ìŠ¤íŠ¸:
{text}

í˜„ì¬ ì¶”ì¶œëœ ë²•ë ¹ (ì°¸ê³ ):
{', '.join(list(existing_laws)[:10])}

ë²•ë ¹ëª…ë§Œ ì¶œë ¥:"""
    
    def _parse_ai_response(self, response: str) -> Set[str]:
        """AI ì‘ë‹µ íŒŒì‹±"""
        laws = set()
        
        for line in response.strip().split('\n'):
            line = line.strip()
            
            # ë²ˆí˜¸, ê¸°í˜¸ ì œê±°
            line = re.sub(r'^[\d\-\.\*\â€¢\Â·]+\s*', '', line)
            line = line.strip('"\'')
            
            if line and self._validate_law_name(line):
                laws.add(line)
                
        return laws
    
    def _extract_from_excel(self, file) -> List[str]:
        """Excel íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        laws = set()
        
        try:
            excel_file = pd.ExcelFile(file)
            
            for sheet_name in excel_file.sheet_names:
                df = pd.read_excel(file, sheet_name=sheet_name)
                
                # ëª¨ë“  ì…€ì˜ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
                text = self._collect_excel_text(df)
                
                # ë²•ë ¹ëª… ì¶”ì¶œ
                sheet_laws = self._extract_laws_from_text(text)
                laws.update(sheet_laws)
                
        except Exception as e:
            self.logger.error(f"Excel ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            st.error(f"Excel íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            
        return sorted(list(laws))
    
    def _collect_excel_text(self, df: pd.DataFrame) -> str:
        """DataFrameì—ì„œ í…ìŠ¤íŠ¸ ìˆ˜ì§‘"""
        texts = []
        
        for column in df.columns:
            for value in df[column].dropna():
                if isinstance(value, str):
                    texts.append(value)
                    
        return '\n'.join(texts)
    
    def _extract_from_markdown(self, file) -> List[str]:
        """Markdown íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        try:
            content = file.read().decode('utf-8')
            laws = self._extract_laws_from_text(content)
            return sorted(list(laws))
        except Exception as e:
            self.logger.error(f"Markdown ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []
    
    def _extract_from_text(self, file) -> List[str]:
        """í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        try:
            content = file.read().decode('utf-8')
            laws = self._extract_laws_from_text(content)
            return sorted(list(laws))
        except Exception as e:
            self.logger.error(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []


# ===== ë²•ë ¹ ìˆ˜ì§‘ API í´ë˜ìŠ¤ =====
class LawCollectorAPI:
    """ê°œì„ ëœ ë²•ë ¹ ìˆ˜ì§‘ API í´ë˜ìŠ¤ - í–‰ì •ê·œì¹™ ì™„ë²½ ì§€ì›"""
    
    def __init__(self, oc_code: str):
        self.oc_code = oc_code
        self.config = APIConfig()
        self.logger = logging.getLogger(self.__class__.__name__)
        self.session = self._create_session()
        
    def _create_session(self) -> requests.Session:
        """ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ì…˜ ìƒì„±"""
        session = requests.Session()
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # SSL ì¸ì¦ì„œ ê²€ì¦ í™œì„±í™” (ë³´ì•ˆ ê°•í™”)
        session.verify = True
        
        # ì¬ì‹œë„ ì„¤ì •
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        
        retry_strategy = Retry(
            total=self.config.MAX_RETRIES,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504]
        )
        
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        return session
    
    def search_laws(self, law_names: List[str], 
                   progress_callback=None) -> List[Dict[str, Any]]:
        """ì—¬ëŸ¬ ë²•ë ¹ì„ ë³‘ë ¬ë¡œ ê²€ìƒ‰"""
        results = []
        no_result_laws = []
        
        with ThreadPoolExecutor(max_workers=self.config.MAX_CONCURRENT) as executor:
            # ê²€ìƒ‰ ì‘ì—… ì œì¶œ
            future_to_law = {
                executor.submit(self._search_with_variations, law_name): law_name
                for law_name in law_names
            }
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for idx, future in enumerate(as_completed(future_to_law)):
                law_name = future_to_law[future]
                
                try:
                    result = future.result()
                    if result:
                        results.extend(result)
                    else:
                        no_result_laws.append(law_name)
                    
                    if progress_callback:
                        progress_callback((idx + 1) / len(law_names))
                        
                except Exception as e:
                    self.logger.error(f"{law_name} ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                    no_result_laws.append(law_name)
        
        # ê²€ìƒ‰ ì‹¤íŒ¨í•œ ë²•ë ¹ í‘œì‹œ
        if no_result_laws:
            with st.expander(f"âŒ ê²€ìƒ‰ë˜ì§€ ì•Šì€ ë²•ë ¹ ({len(no_result_laws)}ê°œ)"):
                for law in no_result_laws:
                    st.write(f"- {law}")
                st.info("ğŸ’¡ Tip: ê¸°ê´€ì½”ë“œë¥¼ í™•ì¸í•˜ê±°ë‚˜, ë²•ë ¹ëª…ì„ ìˆ˜ì •í•´ë³´ì„¸ìš”.")
                    
        return results
    
    def _search_with_variations(self, law_name: str) -> List[Dict[str, Any]]:
        """ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ë²•ë ¹ ê²€ìƒ‰"""
        variations = self._generate_search_variations(law_name)
        
        for variation in variations:
            results = self.search_single_law(variation)
            if results:
                # ì›ë˜ ê²€ìƒ‰ì–´ ì €ì¥
                for result in results:
                    result['search_query'] = law_name
                return results
        
        return []
    
    def _generate_search_variations(self, law_name: str) -> List[str]:
        """ë²•ë ¹ëª…ì˜ ë‹¤ì–‘í•œ ë³€í˜• ìƒì„±"""
        variations = [law_name]
        
        # ë„ì–´ì“°ê¸° ì¶”ê°€/ì œê±°
        spaced = law_name.replace('ë°', ' ë° ').replace('ì—ê´€í•œ', 'ì— ê´€í•œ')
        if spaced != law_name:
            variations.append(spaced)
        
        no_space = law_name.replace(' ', '')
        if no_space != law_name:
            variations.append(no_space)
        
        # ì‹œí–‰ë ¹/ì‹œí–‰ê·œì¹™ ë¶„ë¦¬
        if ' ì‹œí–‰ë ¹' in law_name:
            base = law_name.replace(' ì‹œí–‰ë ¹', '')
            variations.extend([base, f"{base}ì‹œí–‰ë ¹"])
        
        if ' ì‹œí–‰ê·œì¹™' in law_name:
            base = law_name.replace(' ì‹œí–‰ê·œì¹™', '')
            variations.extend([base, f"{base}ì‹œí–‰ê·œì¹™"])
        
        return variations[:3]  # ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ
    
    def search_single_law(self, law_name: str) -> List[Dict[str, Any]]:
        """ë‹¨ì¼ ë²•ë ¹ ê²€ìƒ‰ - ì¼ë°˜ ë²•ë ¹ê³¼ í–‰ì •ê·œì¹™ ëª¨ë‘"""
        results = []
        
        # ì¼ë°˜ ë²•ë ¹ ê²€ìƒ‰
        general_laws = self._search_general_law(law_name)
        results.extend(general_laws)
        
        # í–‰ì •ê·œì¹™ í‚¤ì›Œë“œ í™•ì¸
        admin_keywords = LawPatterns.ADMIN_KEYWORDS
        if any(keyword in law_name for keyword in admin_keywords):
            # í–‰ì •ê·œì¹™ ê²€ìƒ‰ (ìƒˆë¡œìš´ URLê³¼ íŒŒë¼ë¯¸í„° ì‚¬ìš©)
            admin_rules = self._search_admin_rule_new(law_name)
            results.extend(admin_rules)
            
            # í–‰ì •ê·œì¹™ë§Œ ê²€ìƒ‰ëœ ê²½ìš° ë¡œê·¸
            if admin_rules and not general_laws:
                self.logger.info(f"'{law_name}'ëŠ” í–‰ì •ê·œì¹™ìœ¼ë¡œë§Œ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì¤‘ë³µ ì œê±°
        return self._remove_duplicates(results)
    
    def _search_general_law(self, law_name: str) -> List[Dict[str, Any]]:
        """ì¼ë°˜ ë²•ë ¹ ê²€ìƒ‰"""
        params = {
            'OC': self.oc_code,
            'target': 'law',
            'type': 'XML',
            'query': law_name,
            'display': str(self.config.RESULTS_PER_PAGE),
            'page': '1'
        }
        
        try:
            response = self.session.get(
                self.config.LAW_SEARCH_URL,
                params=params,
                timeout=self.config.TIMEOUT
            )
            
            if response.status_code != 200:
                self.logger.warning(f"ê²€ìƒ‰ ì‹¤íŒ¨: {law_name} - {response.status_code}")
                return []
                
            # XML íŒŒì‹±
            laws = self._parse_law_search_response(response.text, law_name)
            return laws
            
        except Exception as e:
            self.logger.error(f"ì¼ë°˜ ë²•ë ¹ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def _search_admin_rule_new(self, law_name: str) -> List[Dict[str, Any]]:
        """í–‰ì •ê·œì¹™ ê²€ìƒ‰ - ìƒˆë¡œìš´ API ì‚¬ìš©"""
        # ë²•ì œì²˜ ì›¹ì‚¬ì´íŠ¸ì˜ ì‹¤ì œ íŒŒë¼ë¯¸í„° ì‚¬ìš©
        params = {
            'OC': self.oc_code,
            'type': 'XML',
            'query': law_name,
            'target': 'admrul',
            'display': '100',
            'page': '1',
            'sort': 'date'
        }
        
        try:
            self.logger.info(f"í–‰ì •ê·œì¹™ ê²€ìƒ‰ ì‹œì‘: {law_name}")
            
            # ë¨¼ì € ì¼ë°˜ ë²•ë ¹ ê²€ìƒ‰ APIë¡œ ì‹œë„ (í–‰ì •ê·œì¹™ë„ í¬í•¨ë  ìˆ˜ ìˆìŒ)
            response = self.session.get(
                self.config.LAW_SEARCH_URL,
                params=params,
                timeout=self.config.TIMEOUT
            )
            
            if response.status_code == 200:
                rules = self._parse_admin_rule_from_law_api(response.text, law_name)
                if rules:
                    self.logger.info(f"í–‰ì •ê·œì¹™ {len(rules)}ê°œ ë°œê²¬: {law_name}")
                    return rules
            
            # ëŒ€ì²´ ë°©ë²•: í–‰ì •ê·œì¹™ ì „ìš© ê²€ìƒ‰
            return self._search_admin_rule_alternative(law_name)
            
        except Exception as e:
            self.logger.error(f"í–‰ì •ê·œì¹™ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def _search_admin_rule_alternative(self, law_name: str) -> List[Dict[str, Any]]:
        """í–‰ì •ê·œì¹™ ëŒ€ì²´ ê²€ìƒ‰ ë°©ë²•"""
        # ë²•ì œì²˜ ì›¹ì‚¬ì´íŠ¸ì²˜ëŸ¼ ì¼ë°˜ ë²•ë ¹ APIë¡œ í–‰ì •ê·œì¹™ ê²€ìƒ‰
        params = {
            'OC': self.oc_code,
            'target': 'law',  # lawë¡œ ì„¤ì •
            'type': 'XML',
            'query': law_name,
            'display': '100',
            'page': '1',
            'LSC': 'admrul'  # ë²•ë ¹êµ¬ë¶„: í–‰ì •ê·œì¹™
        }
        
        try:
            response = self.session.get(
                self.config.LAW_SEARCH_URL,
                params=params,
                timeout=self.config.TIMEOUT
            )
            
            if response.status_code != 200:
                return []
            
            # ì¼ë°˜ ë²•ë ¹ íŒŒì‹± ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬í•˜ë˜ í–‰ì •ê·œì¹™ í”Œë˜ê·¸ ì¶”ê°€
            laws = self._parse_law_search_response(response.text, law_name)
            for law in laws:
                law['is_admin_rule'] = True
            
            return laws
            
        except Exception as e:
            self.logger.error(f"í–‰ì •ê·œì¹™ ëŒ€ì²´ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def _parse_admin_rule_from_law_api(self, content: str, 
                                      search_query: str) -> List[Dict[str, Any]]:
        """ì¼ë°˜ ë²•ë ¹ API ì‘ë‹µì—ì„œ í–‰ì •ê·œì¹™ íŒŒì‹±"""
        rules = []
        
        try:
            # ì „ì²˜ë¦¬
            content = self._preprocess_xml_content(content)
            
            # XML íŒŒì‹±
            root = ET.fromstring(content.encode('utf-8'))
            
            # ì¼ë°˜ ë²•ë ¹ í˜•ì‹ìœ¼ë¡œ íŒŒì‹±í•˜ë˜ í–‰ì •ê·œì¹™ ì—¬ë¶€ í™•ì¸
            for law_elem in root.findall('.//law'):
                law_type = law_elem.findtext('ë²•ì¢…êµ¬ë¶„', '')
                
                # í–‰ì •ê·œì¹™ íƒ€ì… í™•ì¸
                admin_types = ['í›ˆë ¹', 'ì˜ˆê·œ', 'ê³ ì‹œ', 'ê·œì •', 'ì§€ì¹¨', 'ì„¸ì¹™']
                is_admin = any(admin_type in law_type for admin_type in admin_types)
                
                if is_admin:
                    law_info = {
                        'law_id': law_elem.findtext('ë²•ë ¹ID', ''),
                        'law_msn': law_elem.findtext('ë²•ë ¹ì¼ë ¨ë²ˆí˜¸', ''),
                        'law_name': law_elem.findtext('ë²•ë ¹ëª…í•œê¸€', ''),
                        'law_type': law_type,
                        'promulgation_date': law_elem.findtext('ê³µí¬ì¼ì', ''),
                        'enforcement_date': law_elem.findtext('ì‹œí–‰ì¼ì', ''),
                        'is_admin_rule': True,
                        'search_query': search_query
                    }
                    
                    if law_info['law_id'] and law_info['law_name']:
                        rules.append(law_info)
                        
        except ET.ParseError as e:
            self.logger.error(f"XML íŒŒì‹± ì˜¤ë¥˜: {e}")
            
        return rules
    
    def _parse_law_search_response(self, content: str, 
                                  search_query: str) -> List[Dict[str, Any]]:
        """ë²•ë ¹ ê²€ìƒ‰ ì‘ë‹µ íŒŒì‹±"""
        laws = []
        
        try:
            # ì „ì²˜ë¦¬
            content = self._preprocess_xml_content(content)
            
            # XML íŒŒì‹±
            root = ET.fromstring(content.encode('utf-8'))
            
            for law_elem in root.findall('.//law'):
                law_info = {
                    'law_id': law_elem.findtext('ë²•ë ¹ID', ''),
                    'law_msn': law_elem.findtext('ë²•ë ¹ì¼ë ¨ë²ˆí˜¸', ''),
                    'law_name': law_elem.findtext('ë²•ë ¹ëª…í•œê¸€', ''),
                    'law_type': law_elem.findtext('ë²•ì¢…êµ¬ë¶„', ''),
                    'promulgation_date': law_elem.findtext('ê³µí¬ì¼ì', ''),
                    'enforcement_date': law_elem.findtext('ì‹œí–‰ì¼ì', ''),
                    'is_admin_rule': False,
                    'search_query': search_query
                }
                
                if law_info['law_id'] and law_info['law_name']:
                    laws.append(law_info)
                    
        except ET.ParseError as e:
            self.logger.error(f"XML íŒŒì‹± ì˜¤ë¥˜: {e}")
            
        return laws
    
    def _preprocess_xml_content(self, content: str) -> str:
        """XML ë‚´ìš© ì „ì²˜ë¦¬"""
        # BOM ì œê±°
        if content.startswith('\ufeff'):
            content = content[1:]
        
        # XML í—¤ë” í™•ì¸
        if not content.strip().startswith('<?xml'):
            content = '<?xml version="1.0" encoding="UTF-8"?>\n' + content
        
        # íŠ¹ìˆ˜ë¬¸ì ì œê±°
        content = re.sub(r'[\x00-\x08\x0B-\x0C\x0E-\x1F\x7F]', '', content)
        
        return content
    
    def collect_law_details(self, laws: List[Dict[str, Any]], 
                           progress_callback=None) -> Dict[str, Dict[str, Any]]:
        """ë²•ë ¹ ìƒì„¸ ì •ë³´ ë³‘ë ¬ ìˆ˜ì§‘"""
        collected = {}
        
        with ThreadPoolExecutor(max_workers=self.config.MAX_CONCURRENT) as executor:
            # ìˆ˜ì§‘ ì‘ì—… ì œì¶œ
            future_to_law = {
                executor.submit(
                    self._get_law_detail,
                    law['law_id'],
                    law['law_msn'],
                    law['law_name'],
                    law.get('is_admin_rule', False)
                ): law
                for law in laws
            }
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for idx, future in enumerate(as_completed(future_to_law)):
                law = future_to_law[future]
                
                try:
                    detail = future.result()
                    if detail:
                        collected[law['law_id']] = detail
                        
                    if progress_callback:
                        progress_callback((idx + 1) / len(laws))
                        
                except Exception as e:
                    self.logger.error(f"{law['law_name']} ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
                    
        return collected
    
    def _get_law_detail(self, law_id: str, law_msn: str, 
                       law_name: str, is_admin_rule: bool) -> Optional[Dict[str, Any]]:
        """ë²•ë ¹ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        # í–‰ì •ê·œì¹™ë„ ì¼ë°˜ ë²•ë ¹ê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
        return self._get_general_law_detail(law_id, law_msn, law_name)
    
    def _get_general_law_detail(self, law_id: str, law_msn: str, 
                               law_name: str) -> Optional[Dict[str, Any]]:
        """ì¼ë°˜ ë²•ë ¹ ìƒì„¸ ì •ë³´ (í–‰ì •ê·œì¹™ í¬í•¨)"""
        params = {
            'OC': self.oc_code,
            'target': 'law',
            'type': 'XML',
            'MST': law_msn
        }
        
        try:
            response = self.session.get(
                self.config.LAW_DETAIL_URL,
                params=params,
                timeout=self.config.TIMEOUT
            )
            
            if response.status_code != 200:
                return None
                
            # ìƒì„¸ ì •ë³´ íŒŒì‹±
            return self._parse_law_detail(response.text, law_id, law_msn, law_name)
            
        except Exception as e:
            self.logger.error(f"ë²•ë ¹ ìƒì„¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None
    
    def _parse_law_detail(self, content: str, law_id: str, 
                         law_msn: str, law_name: str) -> Dict[str, Any]:
        """ë²•ë ¹ ìƒì„¸ ì •ë³´ íŒŒì‹±"""
        detail = {
            'law_id': law_id,
            'law_msn': law_msn,
            'law_name': law_name,
            'law_type': '',
            'promulgation_date': '',
            'enforcement_date': '',
            'department': '',
            'articles': [],
            'supplementary_provisions': [],
            'attachments': [],
            'raw_content': ''
        }
        
        try:
            # ì „ì²˜ë¦¬
            content = self._preprocess_xml_content(content)
            
            # XML íŒŒì‹±
            root = ET.fromstring(content.encode('utf-8'))
            
            # ê¸°ë³¸ ì •ë³´
            basic_info = root.find('.//ê¸°ë³¸ì •ë³´')
            if basic_info is not None:
                detail['law_type'] = basic_info.findtext('ë²•ì¢…êµ¬ë¶„ëª…', '')
                detail['department'] = basic_info.findtext('ì†Œê´€ë¶€ì²˜ëª…', '')
                detail['promulgation_date'] = basic_info.findtext('ê³µí¬ì¼ì', '')
                detail['enforcement_date'] = basic_info.findtext('ì‹œí–‰ì¼ì', '')
            
            # ì¡°ë¬¸ ì¶”ì¶œ
            self._extract_articles(root, detail)
            
            # ë¶€ì¹™ ì¶”ì¶œ
            self._extract_supplementary_provisions(root, detail)
            
            # ë³„í‘œ ì¶”ì¶œ
            self._extract_attachments(root, detail)
            
            # ì›ë¬¸ ì €ì¥ (ì¡°ë¬¸ì´ ì—†ëŠ” ê²½ìš°)
            if not detail['articles']:
                detail['raw_content'] = self._extract_full_text(root)
                
            self.logger.info(f"ìƒì„¸ ì •ë³´ íŒŒì‹± ì™„ë£Œ: {law_name} - ì¡°ë¬¸ {len(detail['articles'])}ê°œ")
                
        except Exception as e:
            self.logger.error(f"ìƒì„¸ ì •ë³´ íŒŒì‹± ì˜¤ë¥˜: {e}")
            
        return detail
    
    def _extract_articles(self, root: ET.Element, detail: Dict[str, Any]) -> None:
        """ì¡°ë¬¸ ì¶”ì¶œ"""
        # í‘œì¤€ ì¡°ë¬¸ êµ¬ì¡°
        articles_section = root.find('.//ì¡°ë¬¸')
        if articles_section is not None:
            for article_unit in articles_section.findall('.//ì¡°ë¬¸ë‹¨ìœ„'):
                article = self._parse_article_unit(article_unit)
                if article:
                    detail['articles'].append(article)
            return
        
        # ì¡°ë¬¸ë‚´ìš© ì§ì ‘ ì°¾ê¸°
        for article_content in root.findall('.//ì¡°ë¬¸ë‚´ìš©'):
            if article_content.text:
                articles = self._parse_article_text(article_content.text)
                detail['articles'].extend(articles)
    
    def _parse_article_unit(self, article_elem: ET.Element) -> Optional[Dict[str, Any]]:
        """ì¡°ë¬¸ë‹¨ìœ„ íŒŒì‹±"""
        article = {
            'number': '',
            'title': '',
            'content': '',
            'paragraphs': []
        }
        
        # ì¡°ë¬¸ë²ˆí˜¸
        article_num = article_elem.findtext('ì¡°ë¬¸ë²ˆí˜¸', '')
        if article_num:
            article['number'] = f"ì œ{article_num}ì¡°"
        
        # ì¡°ë¬¸ì œëª©
        article['title'] = article_elem.findtext('ì¡°ë¬¸ì œëª©', '')
        
        # ì¡°ë¬¸ë‚´ìš©
        article['content'] = article_elem.findtext('ì¡°ë¬¸ë‚´ìš©', '')
        
        # í•­ ì¶”ì¶œ
        for para in article_elem.findall('.//í•­'):
            paragraph = {
                'number': para.findtext('í•­ë²ˆí˜¸', ''),
                'content': para.findtext('í•­ë‚´ìš©', '')
            }
            if paragraph['content']:
                article['paragraphs'].append(paragraph)
        
        return article if (article['number'] or article['content']) else None
    
    def _parse_article_text(self, text: str) -> List[Dict[str, Any]]:
        """ì¡°ë¬¸ í…ìŠ¤íŠ¸ íŒŒì‹±"""
        articles = []
        
        # ì¡°ë¬¸ íŒ¨í„´
        pattern = r'(ì œ\d+ì¡°(?:ì˜\d+)?)\s*(?:\((.*?)\))?\s*(.*?)(?=ì œ\d+ì¡°|$)'
        matches = re.findall(pattern, text, re.DOTALL)
        
        for match in matches:
            article = {
                'number': match[0],
                'title': match[1],
                'content': match[2].strip(),
                'paragraphs': []
            }
            articles.append(article)
            
        return articles
    
    def _extract_supplementary_provisions(self, root: ET.Element, 
                                        detail: Dict[str, Any]) -> None:
        """ë¶€ì¹™ ì¶”ì¶œ"""
        for addendum in root.findall('.//ë¶€ì¹™'):
            provision = {
                'number': addendum.findtext('ë¶€ì¹™ë²ˆí˜¸', ''),
                'promulgation_date': addendum.findtext('ë¶€ì¹™ê³µí¬ì¼ì', ''),
                'content': self._get_all_text(addendum)
            }
            if provision['content']:
                detail['supplementary_provisions'].append(provision)
        
        # ë¶€ì¹™ë‚´ìš© ì§ì ‘ ì°¾ê¸°
        if not detail['supplementary_provisions']:
            for elem in root.findall('.//ë¶€ì¹™ë‚´ìš©'):
                if elem.text:
                    detail['supplementary_provisions'].append({
                        'number': '',
                        'promulgation_date': '',
                        'content': elem.text
                    })
    
    def _extract_attachments(self, root: ET.Element, detail: Dict[str, Any]) -> None:
        """ë³„í‘œ/ë³„ì²¨ ì¶”ì¶œ"""
        # ë³„í‘œ
        for table in root.findall('.//ë³„í‘œ'):
            attachment = {
                'type': 'ë³„í‘œ',
                'number': table.findtext('ë³„í‘œë²ˆí˜¸', ''),
                'title': table.findtext('ë³„í‘œì œëª©', ''),
                'content': self._get_all_text(table)
            }
            if attachment['content'] or attachment['title']:
                detail['attachments'].append(attachment)
        
        # ë³„ì§€
        for form in root.findall('.//ë³„ì§€'):
            attachment = {
                'type': 'ë³„ì§€',
                'number': form.findtext('ë³„ì§€ë²ˆí˜¸', ''),
                'title': form.findtext('ë³„ì§€ì œëª©', ''),
                'content': self._get_all_text(form)
            }
            if attachment['content'] or attachment['title']:
                detail['attachments'].append(attachment)
    
    def _extract_full_text(self, root: ET.Element) -> str:
        """ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        return self._get_all_text(root)
    
    def _get_all_text(self, elem: ET.Element) -> str:
        """ìš”ì†Œì˜ ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        texts = []
        
        if elem.text:
            texts.append(elem.text.strip())
            
        for child in elem:
            child_text = self._get_all_text(child)
            if child_text:
                texts.append(child_text)
                
            if child.tail:
                texts.append(child.tail.strip())
                
        return ' '.join(texts)
    
    def _remove_duplicates(self, laws: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì¤‘ë³µ ì œê±°"""
        seen = set()
        unique_laws = []
        
        for law in laws:
            law_id = law['law_id']
            if law_id not in seen:
                seen.add(law_id)
                unique_laws.append(law)
                
        return unique_laws


# ===== ë²•ë ¹ ë‚´ë³´ë‚´ê¸° í´ë˜ìŠ¤ =====
class LawExporter:
    """ë²•ë ¹ ë‚´ë³´ë‚´ê¸° í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
    
    def export_to_zip(self, laws_dict: Dict[str, Dict[str, Any]]) -> bytes:
        """ZIP íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        zip_buffer = BytesIO()
        
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            # ë©”íƒ€ë°ì´í„°
            metadata = {
                'collection_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'total_laws': len(laws_dict),
                'admin_rule_count': sum(1 for law in laws_dict.values() if 'í–‰ì •ê·œì¹™' in law.get('law_type', '') or law.get('law_type') in ['í›ˆë ¹', 'ì˜ˆê·œ', 'ê³ ì‹œ', 'ê·œì •']),
                'laws': laws_dict
            }
            
            # ì „ì²´ JSON
            zip_file.writestr(
                'all_laws.json',
                json.dumps(metadata, ensure_ascii=False, indent=2)
            )
            
            # ì „ì²´ Markdown
            all_laws_md = self._create_all_laws_markdown(laws_dict)
            zip_file.writestr('all_laws.md', all_laws_md)
            
            # ê°œë³„ íŒŒì¼
            for law_id, law in laws_dict.items():
                safe_name = self._sanitize_filename(law['law_name'])
                
                # JSON
                zip_file.writestr(
                    f'laws/{safe_name}.json',
                    json.dumps(law, ensure_ascii=False, indent=2)
                )
                
                # í…ìŠ¤íŠ¸
                text_content = self._format_law_text(law)
                zip_file.writestr(f'laws/{safe_name}.txt', text_content)
                
                # Markdown
                md_content = self._format_law_markdown(law)
                zip_file.writestr(f'laws/{safe_name}.md', md_content)
            
            # README
            readme = self._create_readme(laws_dict)
            zip_file.writestr('README.md', readme)
        
        zip_buffer.seek(0)
        return zip_buffer.getvalue()
    
    def export_single_file(self, laws_dict: Dict[str, Dict[str, Any]], 
                          format: str = 'json') -> str:
        """ë‹¨ì¼ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        exporters = {
            'json': self._export_as_json,
            'markdown': self._export_as_markdown,
            'text': self._export_as_text
        }
        
        exporter = exporters.get(format, self._export_as_json)
        return exporter(laws_dict)
    
    def _sanitize_filename(self, filename: str) -> str:
        """íŒŒì¼ëª… ì•ˆì „í•˜ê²Œ ë³€í™˜"""
        return re.sub(r'[\\/*?:"<>|]', '_', filename)
    
    def _export_as_json(self, laws_dict: Dict[str, Dict[str, Any]]) -> str:
        """JSON í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        data = {
            'collection_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'total_laws': len(laws_dict),
            'laws': laws_dict
        }
        return json.dumps(data, ensure_ascii=False, indent=2)
    
    def _export_as_markdown(self, laws_dict: Dict[str, Dict[str, Any]]) -> str:
        """Markdown í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        return self._create_all_laws_markdown(laws_dict)
    
    def _export_as_text(self, laws_dict: Dict[str, Dict[str, Any]]) -> str:
        """í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        lines = []
        lines.append("ë²•ë ¹ ìˆ˜ì§‘ ê²°ê³¼")
        lines.append(f"ìˆ˜ì§‘ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"ì´ ë²•ë ¹ ìˆ˜: {len(laws_dict)}ê°œ")
        lines.append("=" * 80 + "\n")
        
        for law_id, law in laws_dict.items():
            lines.append(self._format_law_text(law))
            lines.append("\n" + "=" * 80 + "\n")
            
        return '\n'.join(lines)
    
    def _format_law_text(self, law: Dict[str, Any]) -> str:
        """ë²•ë ¹ì„ í…ìŠ¤íŠ¸ë¡œ í¬ë§·"""
        lines = []
        
        # í—¤ë”
        lines.append(f"ë²•ë ¹ëª…: {law['law_name']}")
        lines.append(f"ë²•ì¢…êµ¬ë¶„: {law.get('law_type', '')}")
        if law.get('department'):
            lines.append(f"ì†Œê´€ë¶€ì²˜: {law.get('department', '')}")
        lines.append(f"ê³µí¬ì¼ì: {law.get('promulgation_date', '')}")
        lines.append(f"ì‹œí–‰ì¼ì: {law.get('enforcement_date', '')}")
        lines.append("-" * 60)
        
        # ì¡°ë¬¸
        if law.get('articles'):
            lines.append("\nã€ì¡° ë¬¸ã€‘\n")
            for article in law['articles']:
                lines.append(f"{article['number']} {article.get('title', '')}")
                lines.append(article['content'])
                
                if article.get('paragraphs'):
                    for para in article['paragraphs']:
                        lines.append(f"  {para['number']} {para['content']}")
                lines.append("")
        
        # ë¶€ì¹™
        if law.get('supplementary_provisions'):
            lines.append("\nã€ë¶€ ì¹™ã€‘\n")
            for provision in law['supplementary_provisions']:
                if provision.get('promulgation_date'):
                    lines.append(f"ë¶€ì¹™ <{provision['promulgation_date']}>")
                lines.append(provision['content'])
                lines.append("")
        
        # ë³„í‘œ
        if law.get('attachments'):
            lines.append("\nã€ë³„í‘œ/ë³„ì²¨ã€‘\n")
            for attachment in law['attachments']:
                lines.append(f"[{attachment['type']}] {attachment.get('title', '')}")
                lines.append(attachment['content'])
                lines.append("")
        
        # ì›ë¬¸ (ì¡°ë¬¸ì´ ì—†ëŠ” ê²½ìš°)
        if not law.get('articles') and law.get('raw_content'):
            lines.append("\nã€ì› ë¬¸ã€‘\n")
            lines.append(law['raw_content'])
        
        return '\n'.join(lines)
    
    def _format_law_markdown(self, law: Dict[str, Any]) -> str:
        """ë²•ë ¹ì„ Markdownìœ¼ë¡œ í¬ë§·"""
        lines = []
        
        # ì œëª©
        lines.append(f"# {law['law_name']}\n")
        
        # ê¸°ë³¸ ì •ë³´
        lines.append("## ğŸ“‹ ê¸°ë³¸ ì •ë³´\n")
        lines.append(f"- **ë²•ì¢…êµ¬ë¶„**: {law.get('law_type', '')}")
        if law.get('department'):
            lines.append(f"- **ì†Œê´€ë¶€ì²˜**: {law.get('department', '')}")
        lines.append(f"- **ê³µí¬ì¼ì**: {law.get('promulgation_date', '')}")
        lines.append(f"- **ì‹œí–‰ì¼ì**: {law.get('enforcement_date', '')}")
        lines.append("")
        
        # ì¡°ë¬¸
        if law.get('articles'):
            lines.append("## ğŸ“– ì¡°ë¬¸\n")
            for article in law['articles']:
                lines.append(f"### {article['number']}")
                if article.get('title'):
                    lines.append(f"**{article['title']}**\n")
                lines.append(article['content'])
                
                if article.get('paragraphs'):
                    for para in article['paragraphs']:
                        lines.append(f"\n> {para['number']} {para['content']}")
                lines.append("")
        
        # ë¶€ì¹™
        if law.get('supplementary_provisions'):
            lines.append("## ğŸ“Œ ë¶€ì¹™\n")
            for provision in law['supplementary_provisions']:
                if provision.get('promulgation_date'):
                    lines.append(f"### ë¶€ì¹™ <{provision['promulgation_date']}>")
                lines.append(provision['content'])
                lines.append("")
        
        # ë³„í‘œ
        if law.get('attachments'):
            lines.append("## ğŸ“ ë³„í‘œ/ë³„ì²¨\n")
            for attachment in law['attachments']:
                lines.append(f"### [{attachment['type']}] {attachment.get('title', '')}")
                lines.append(attachment['content'])
                lines.append("")
        
        return '\n'.join(lines)
    
    def _create_all_laws_markdown(self, laws_dict: Dict[str, Dict[str, Any]]) -> str:
        """ì „ì²´ ë²•ë ¹ Markdown ìƒì„±"""
        lines = []
        
        # í—¤ë”
        lines.append("# ğŸ“š ë²•ë ¹ ìˆ˜ì§‘ ê²°ê³¼\n")
        lines.append(f"**ìˆ˜ì§‘ ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"**ì´ ë²•ë ¹ ìˆ˜**: {len(laws_dict)}ê°œ")
        
        # í†µê³„
        admin_rule_count = sum(1 for law in laws_dict.values() 
                             if 'í–‰ì •ê·œì¹™' in law.get('law_type', '') or 
                             law.get('law_type') in ['í›ˆë ¹', 'ì˜ˆê·œ', 'ê³ ì‹œ', 'ê·œì •'])
        if admin_rule_count > 0:
            lines.append(f"**í–‰ì •ê·œì¹™ ìˆ˜**: {admin_rule_count}ê°œ")
        
        lines.append("")
        
        # ëª©ì°¨
        lines.append("## ğŸ“‘ ëª©ì°¨\n")
        for idx, (law_id, law) in enumerate(laws_dict.items(), 1):
            anchor = self._sanitize_filename(law['law_name'])
            type_emoji = "ğŸ“‹" if (law.get('is_admin_rule') or 
                                 law.get('law_type') in ['í›ˆë ¹', 'ì˜ˆê·œ', 'ê³ ì‹œ', 'ê·œì •']) else "ğŸ“–"
            lines.append(f"{idx}. {type_emoji} [{law['law_name']}](#{anchor})")
        lines.append("\n---\n")
        
        # ê° ë²•ë ¹
        for law_id, law in laws_dict.items():
            lines.append(self._format_law_markdown(law))
            lines.append("\n---\n")
            
        return '\n'.join(lines)
    
    def _create_readme(self, laws_dict: Dict[str, Dict[str, Any]]) -> str:
        """README ìƒì„±"""
        # í†µê³„ ê³„ì‚°
        total_articles = sum(len(law.get('articles', [])) for law in laws_dict.values())
        total_provisions = sum(len(law.get('supplementary_provisions', [])) for law in laws_dict.values())
        total_attachments = sum(len(law.get('attachments', [])) for law in laws_dict.values())
        admin_rule_count = sum(1 for law in laws_dict.values() 
                              if 'í–‰ì •ê·œì¹™' in law.get('law_type', '') or 
                              law.get('law_type') in ['í›ˆë ¹', 'ì˜ˆê·œ', 'ê³ ì‹œ', 'ê·œì •'])
        
        content = f"""# ë²•ë ¹ ìˆ˜ì§‘ ê²°ê³¼

ìˆ˜ì§‘ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ì´ ë²•ë ¹ ìˆ˜: {len(laws_dict)}ê°œ

## ğŸ“ íŒŒì¼ êµ¬ì¡°

- `all_laws.json`: ì „ì²´ ë²•ë ¹ ë°ì´í„° (JSON)
- `all_laws.md`: ì „ì²´ ë²•ë ¹ í†µí•© ë¬¸ì„œ (Markdown)
- `laws/`: ê°œë³„ ë²•ë ¹ íŒŒì¼
  - `*.json`: ë²•ë ¹ë³„ ìƒì„¸ ë°ì´í„°
  - `*.txt`: ë²•ë ¹ë³„ í…ìŠ¤íŠ¸
  - `*.md`: ë²•ë ¹ë³„ Markdown
- `README.md`: ì´ íŒŒì¼

## ğŸ“Š í†µê³„

- ì´ ì¡°ë¬¸ ìˆ˜: {total_articles:,}ê°œ
- ì´ ë¶€ì¹™ ìˆ˜: {total_provisions}ê°œ
- ì´ ë³„í‘œ/ë³„ì²¨ ìˆ˜: {total_attachments}ê°œ
- í–‰ì •ê·œì¹™ ìˆ˜: {admin_rule_count}ê°œ

## ğŸ“– ìˆ˜ì§‘ëœ ë²•ë ¹ ëª©ë¡

"""
        
        # ì¼ë°˜ ë²•ë ¹ê³¼ í–‰ì •ê·œì¹™ ë¶„ë¦¬
        general_laws = []
        admin_rules = []
        
        for law_id, law in laws_dict.items():
            if ('í–‰ì •ê·œì¹™' in law.get('law_type', '') or 
                law.get('law_type') in ['í›ˆë ¹', 'ì˜ˆê·œ', 'ê³ ì‹œ', 'ê·œì •']):
                admin_rules.append((law_id, law))
            else:
                general_laws.append((law_id, law))
        
        # ì¼ë°˜ ë²•ë ¹ ëª©ë¡
        if general_laws:
            content += "\n### ğŸ“– ì¼ë°˜ ë²•ë ¹\n\n"
            for law_id, law in general_laws:
                content += f"#### {law['law_name']}\n"
                content += f"- ë²•ì¢…êµ¬ë¶„: {law.get('law_type', '')}\n"
                content += f"- ì‹œí–‰ì¼ì: {law.get('enforcement_date', '')}\n"
                content += f"- ì¡°ë¬¸: {len(law.get('articles', []))}ê°œ\n\n"
        
        # í–‰ì •ê·œì¹™ ëª©ë¡
        if admin_rules:
            content += "\n### ğŸ“‹ í–‰ì •ê·œì¹™\n\n"
            for law_id, law in admin_rules:
                content += f"#### {law['law_name']}\n"
                content += f"- ìœ í˜•: {law.get('law_type', '')}\n"
                if law.get('department'):
                    content += f"- ì†Œê´€ë¶€ì²˜: {law.get('department', '')}\n"
                content += f"- ì‹œí–‰ì¼ì: {law.get('enforcement_date', '')}\n"
                content += f"- ì¡°ë¬¸: {len(law.get('articles', []))}ê°œ\n\n"
            
        return content


# ===== Streamlit UI í•¨ìˆ˜ë“¤ =====
def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    defaults = {
        'mode': 'direct',
        'extracted_laws': [],
        'search_results': [],
        'selected_laws': [],
        'collected_laws': {},
        'file_processed': False,
        'openai_api_key': None,
        'use_ai': False,
        'oc_code': ''
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value


def show_sidebar():
    """ì‚¬ì´ë“œë°” UI"""
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # ê¸°ê´€ì½”ë“œ ì…ë ¥
        oc_code = st.text_input(
            "ê¸°ê´€ì½”ë“œ (OC)",
            value=st.session_state.get('oc_code', ''),
            placeholder="ì´ë©”ì¼ @ ì•ë¶€ë¶„",
            help="ì˜ˆ: test@korea.kr â†’ test"
        )
        st.session_state.oc_code = oc_code
        
        st.divider()
        
        # AI ì„¤ì • (ì‚¬ì´ë“œë°” ì§ì ‘ ì…ë ¥ ë°©ì‹ ìœ ì§€)
        with st.expander("ğŸ¤– AI ì„¤ì • (ì„ íƒì‚¬í•­)", expanded=False):
            st.markdown("**ChatGPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë²•ë ¹ëª… ì¶”ì¶œ ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤**")
            
            # OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ í™•ì¸
            try:
                import openai
                openai_available = True
            except ImportError:
                openai_available = False
                st.warning("âš ï¸ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                st.info("ì„¤ì¹˜í•˜ë ¤ë©´: `pip install openai`")
            
            if openai_available:
                # ì§ì ‘ ì…ë ¥ ë°©ì‹
                api_key = st.text_input(
                    "OpenAI API Key",
                    type="password",
                    value=st.session_state.get('openai_api_key', ''),
                    help="https://platform.openai.com/api-keys ì—ì„œ ë°œê¸‰"
                )
                
                if api_key:
                    # ê°„ë‹¨í•œ ìœ íš¨ì„± ê²€ì¦
                    if api_key.startswith('sk-') and len(api_key) > 20:
                        st.session_state.openai_api_key = api_key
                        st.session_state.use_ai = True
                        st.success("âœ… API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    else:
                        st.error("âŒ ì˜¬ë°”ë¥¸ í˜•ì‹ì˜ API í‚¤ê°€ ì•„ë‹™ë‹ˆë‹¤.")
                        st.session_state.use_ai = False
                else:
                    st.session_state.use_ai = False
                    st.info("ğŸ’¡ API í‚¤ë¥¼ ì…ë ¥í•˜ë©´ ë” ì •í™•í•œ ë²•ë ¹ëª… ì¶”ì¶œì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        st.divider()
        
        # ëª¨ë“œ ì„ íƒ
        st.subheader("ğŸ¯ ìˆ˜ì§‘ ë°©ì‹")
        mode = st.radio(
            "ë°©ì‹ ì„ íƒ",
            ["ì§ì ‘ ê²€ìƒ‰", "íŒŒì¼ ì—…ë¡œë“œ"],
            help="ì§ì ‘ ê²€ìƒ‰: ë²•ë ¹ëª…ì„ ì…ë ¥í•˜ì—¬ ê²€ìƒ‰\níŒŒì¼ ì—…ë¡œë“œ: íŒŒì¼ì—ì„œ ë²•ë ¹ ì¶”ì¶œ"
        )
        st.session_state.mode = 'direct' if mode == "ì§ì ‘ ê²€ìƒ‰" else 'file'
        
        # í…ŒìŠ¤íŠ¸ ë²„íŠ¼ ì¶”ê°€
        st.divider()
        st.subheader("ğŸ§ª í…ŒìŠ¤íŠ¸")
        
        if st.button("í–‰ì •ê·œì¹™ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸", type="secondary", use_container_width=True):
            if not oc_code:
                st.error("ê¸°ê´€ì½”ë“œë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”!")
            else:
                test_admin_rule_search(oc_code)
        
        # ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ”„ ì´ˆê¸°í™”", type="secondary", use_container_width=True):
            keys_to_keep = ['mode', 'openai_api_key', 'use_ai', 'oc_code']
            for key in list(st.session_state.keys()):
                if key not in keys_to_keep:
                    del st.session_state[key]
            st.session_state.file_processed = False
            st.rerun()
        
        return oc_code


def test_admin_rule_search(oc_code: str):
    """í–‰ì •ê·œì¹™ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    with st.spinner("í–‰ì •ê·œì¹™ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì¤‘..."):
        collector = LawCollectorAPI(oc_code)
        
        # í…ŒìŠ¤íŠ¸í•  í–‰ì •ê·œì¹™ë“¤
        test_rules = [
            "ê¸ˆìœµê¸°ê´€ê²€ì‚¬ë°ì œì¬ì—ê´€í•œê·œì •",
            "ì—¬ì‹ ì „ë¬¸ê¸ˆìœµì—…ê°ë…ê·œì •",
            "ì—¬ì‹ ì „ë¬¸ê¸ˆìœµì—…ê°ë…ì—…ë¬´ì‹œí–‰ì„¸ì¹™"
        ]
        
        results = []
        for rule_name in test_rules:
            st.write(f"\nğŸ” ê²€ìƒ‰ ì¤‘: {rule_name}")
            
            found = collector.search_single_law(rule_name)
            if found:
                st.success(f"âœ… {len(found)}ê°œ ë°œê²¬!")
                for item in found:
                    type_emoji = "ğŸ“‹" if item.get('is_admin_rule') else "ğŸ“–"
                    st.write(f"  {type_emoji} {item['law_name']} ({item['law_type']})")
            else:
                st.warning(f"âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            
            results.extend(found)
            time.sleep(0.5)
        
        if results:
            st.sidebar.success(f"ì´ {len(results)}ê°œ ë²•ë ¹ ë°œê²¬!")
        else:
            st.sidebar.error("ë²•ë ¹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


def handle_direct_search_mode(oc_code: str):
    """ì§ì ‘ ê²€ìƒ‰ ëª¨ë“œ ì²˜ë¦¬"""
    st.header("ğŸ” ì§ì ‘ ê²€ìƒ‰ ëª¨ë“œ")
    
    law_name = st.text_input(
        "ë²•ë ¹ëª…",
        placeholder="ì˜ˆ: ë¯¼ë²•, ìƒë²•, ê¸ˆìœµê°ë…ê·œì •",
        help="ê²€ìƒ‰í•  ë²•ë ¹ëª…ì„ ì…ë ¥í•˜ì„¸ìš” (í–‰ì •ê·œì¹™ë„ ê²€ìƒ‰ ê°€ëŠ¥)"
    )
    
    if st.button("ğŸ” ê²€ìƒ‰", type="primary", use_container_width=True):
        if not oc_code:
            st.error("ê¸°ê´€ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        elif not law_name:
            st.error("ë²•ë ¹ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        else:
            with st.spinner(f"'{law_name}' ê²€ìƒ‰ ì¤‘..."):
                collector = LawCollectorAPI(oc_code)
                results = collector.search_single_law(law_name)
                
                if results:
                    st.success(f"{len(results)}ê°œì˜ ë²•ë ¹ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                    
                    # í–‰ì •ê·œì¹™ ê°œìˆ˜ í‘œì‹œ
                    admin_count = sum(1 for r in results if r.get('is_admin_rule'))
                    if admin_count > 0:
                        st.info(f"ğŸ“‹ ì´ ì¤‘ {admin_count}ê°œëŠ” í–‰ì •ê·œì¹™ì…ë‹ˆë‹¤.")
                    
                    st.session_state.search_results = results
                else:
                    st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    st.info("ğŸ’¡ Tip: ë„ì–´ì“°ê¸°ë¥¼ ì¡°ì •í•˜ê±°ë‚˜ ê¸°ê´€ì½”ë“œë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.")
                    st.session_state.search_results = []


def handle_file_upload_mode(oc_code: str):
    """íŒŒì¼ ì—…ë¡œë“œ ëª¨ë“œ ì²˜ë¦¬"""
    st.header("ğŸ“„ íŒŒì¼ ì—…ë¡œë“œ ëª¨ë“œ")
    
    # AI ìƒíƒœ í‘œì‹œ
    if st.session_state.use_ai:
        st.info("ğŸ¤– AI ê°•í™” ëª¨ë“œê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤")
    else:
        st.info("ğŸ’¡ AI ì„¤ì •ì„ í†µí•´ ë²•ë ¹ëª… ì¶”ì¶œ ì •í™•ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    
    uploaded_file = st.file_uploader(
        "íŒŒì¼ ì„ íƒ",
        type=['pdf', 'xlsx', 'xls', 'md', 'txt'],
        help="PDF, Excel, Markdown, í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì§€ì›í•©ë‹ˆë‹¤"
    )
    
    if uploaded_file and not st.session_state.file_processed:
        st.subheader("ğŸ“‹ STEP 1: ë²•ë ¹ëª… ì¶”ì¶œ")
        
        with st.spinner("íŒŒì¼ì—ì„œ ë²•ë ¹ëª…ì„ ì¶”ì¶œí•˜ëŠ” ì¤‘..."):
            extractor = EnhancedLawFileExtractor(
                use_ai=st.session_state.use_ai,
                api_key=st.session_state.openai_api_key
            )
            
            file_type = uploaded_file.name.split('.')[-1].lower()
            
            try:
                extracted_laws = extractor.extract_from_file(uploaded_file, file_type)
                
                if extracted_laws:
                    st.success(f"âœ… {len(extracted_laws)}ê°œì˜ ë²•ë ¹ëª…ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                    st.session_state.extracted_laws = extracted_laws
                    st.session_state.file_processed = True
                else:
                    st.warning("íŒŒì¼ì—ì„œ ë²•ë ¹ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    
            except Exception as e:
                st.error(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
    
    # ì¶”ì¶œëœ ë²•ë ¹ í‘œì‹œ
    if st.session_state.extracted_laws:
        display_extracted_laws(oc_code)


def display_extracted_laws(oc_code: str):
    """ì¶”ì¶œëœ ë²•ë ¹ í‘œì‹œ ë° í¸ì§‘"""
    st.subheader("âœï¸ STEP 2: ë²•ë ¹ëª… í™•ì¸ ë° í¸ì§‘")
    
    # ì¶”ì¶œëœ ë²•ë ¹ ëª©ë¡
    st.write("**ì¶”ì¶œëœ ë²•ë ¹ëª…:**")
    col1, col2 = st.columns([3, 1])
    with col1:
        for idx, law in enumerate(st.session_state.extracted_laws, 1):
            # í–‰ì •ê·œì¹™ í‚¤ì›Œë“œ ì²´í¬
            is_admin = any(k in law for k in LawPatterns.ADMIN_KEYWORDS)
            emoji = "ğŸ“‹" if is_admin else "ğŸ“–"
            st.write(f"{idx}. {emoji} {law}")
    
    with col2:
        st.metric("ì´ ë²•ë ¹", len(st.session_state.extracted_laws))
        admin_count = sum(1 for law in st.session_state.extracted_laws 
                         if any(k in law for k in LawPatterns.ADMIN_KEYWORDS))
        if admin_count > 0:
            st.metric("í–‰ì •ê·œì¹™", admin_count)
    
    # í¸ì§‘ ì˜ì—­
    edited_laws = []
    st.write("\n**ë²•ë ¹ëª… í¸ì§‘:**")
    
    for idx, law_name in enumerate(st.session_state.extracted_laws):
        col1, col2 = st.columns([4, 1])
        with col1:
            edited_name = st.text_input(
                f"ë²•ë ¹ {idx+1}",
                value=law_name,
                key=f"edit_{idx}"
            )
            if edited_name:
                edited_laws.append(edited_name)
        with col2:
            if st.button("ì‚­ì œ", key=f"del_{idx}"):
                st.session_state.extracted_laws.pop(idx)
                st.rerun()
    
    # ë²•ë ¹ëª… ì¶”ê°€
    st.subheader("ë²•ë ¹ëª… ì¶”ê°€")
    new_law = st.text_input("ìƒˆ ë²•ë ¹ëª… ì…ë ¥", key="new_law_input")
    if st.button("â• ì¶”ê°€") and new_law:
        st.session_state.extracted_laws.append(new_law)
        st.rerun()
    
    # ê²€ìƒ‰ ë²„íŠ¼
    if st.button("ğŸ” ë²•ë ¹ ê²€ìƒ‰", type="primary", use_container_width=True):
        if not oc_code:
            st.error("ê¸°ê´€ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        else:
            search_laws_from_list(oc_code, edited_laws or st.session_state.extracted_laws)


def search_laws_from_list(oc_code: str, law_names: List[str]):
    """ë²•ë ¹ ëª©ë¡ ê²€ìƒ‰"""
    collector = LawCollectorAPI(oc_code)
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    def update_progress(progress):
        progress_bar.progress(progress)
    
    with st.spinner("ë²•ë ¹ì„ ê²€ìƒ‰í•˜ëŠ” ì¤‘..."):
        results = collector.search_laws(law_names, progress_callback=update_progress)
    
    progress_bar.progress(1.0)
    status_text.text("ê²€ìƒ‰ ì™„ë£Œ!")
    
    if results:
        st.success(f"âœ… ì´ {len(results)}ê°œì˜ ë²•ë ¹ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
        
        # í–‰ì •ê·œì¹™ í†µê³„
        admin_count = sum(1 for r in results if r.get('is_admin_rule'))
        if admin_count > 0:
            st.info(f"ğŸ“‹ ì´ ì¤‘ {admin_count}ê°œëŠ” í–‰ì •ê·œì¹™ì…ë‹ˆë‹¤.")
        
        st.session_state.search_results = results
    else:
        st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")


def display_search_results_and_collect(oc_code: str):
    """ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ ë° ìˆ˜ì§‘"""
    if not st.session_state.search_results:
        return
        
    st.subheader("ğŸ“‘ ê²€ìƒ‰ ê²°ê³¼")
    
    # ì „ì²´ ì„ íƒ
    select_all = st.checkbox("ì „ì²´ ì„ íƒ")
    
    # í…Œì´ë¸” í—¤ë”
    cols = st.columns([1, 1, 3, 2, 2, 2])
    headers = ["ì„ íƒ", "ìœ í˜•", "ë²•ë ¹ëª…", "ë²•ì¢…êµ¬ë¶„", "ì‹œí–‰ì¼ì", "ê²€ìƒ‰ì–´"]
    for col, header in zip(cols, headers):
        col.markdown(f"**{header}**")
    
    st.divider()
    
    # ê²°ê³¼ í‘œì‹œ
    selected_indices = []
    for idx, law in enumerate(st.session_state.search_results):
        cols = st.columns([1, 1, 3, 2, 2, 2])
        
        with cols[0]:
            # ë¹ˆ ë ˆì´ë¸” ê²½ê³  í•´ê²°: label_visibility ì‚¬ìš©
            if st.checkbox("ì„ íƒ", key=f"sel_{idx}", value=select_all, label_visibility="collapsed"):
                selected_indices.append(idx)
        
        with cols[1]:
            # ìœ í˜• ì•„ì´ì½˜
            if law.get('is_admin_rule') or law.get('law_type') in ['í›ˆë ¹', 'ì˜ˆê·œ', 'ê³ ì‹œ', 'ê·œì •']:
                st.write("ğŸ“‹")  # í–‰ì •ê·œì¹™
            else:
                st.write("ğŸ“–")  # ì¼ë°˜ ë²•ë ¹
        
        with cols[2]:
            st.write(law['law_name'])
        
        with cols[3]:
            st.write(law.get('law_type', ''))
        
        with cols[4]:
            st.write(law.get('enforcement_date', ''))
        
        with cols[5]:
            st.write(law.get('search_query', ''))
    
    # ì„ íƒëœ ë²•ë ¹ ì €ì¥
    st.session_state.selected_laws = [
        st.session_state.search_results[i] for i in selected_indices
    ]
    
    if st.session_state.selected_laws:
        st.success(f"{len(st.session_state.selected_laws)}ê°œ ë²•ë ¹ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤")
        
        # ì„ íƒëœ í–‰ì •ê·œì¹™ ê°œìˆ˜
        selected_admin = sum(1 for law in st.session_state.selected_laws 
                           if law.get('is_admin_rule') or 
                           law.get('law_type') in ['í›ˆë ¹', 'ì˜ˆê·œ', 'ê³ ì‹œ', 'ê·œì •'])
        if selected_admin > 0:
            st.info(f"ğŸ“‹ ì„ íƒëœ í–‰ì •ê·œì¹™: {selected_admin}ê°œ")
        
        # ìˆ˜ì§‘ ë²„íŠ¼
        if st.button("ğŸ“¥ ì„ íƒí•œ ë²•ë ¹ ìˆ˜ì§‘", type="primary", use_container_width=True):
            collect_selected_laws(oc_code)


def collect_selected_laws(oc_code: str):
    """ì„ íƒëœ ë²•ë ¹ ìˆ˜ì§‘"""
    collector = LawCollectorAPI(oc_code)
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    def update_progress(progress):
        progress_bar.progress(progress)
        
    with st.spinner("ë²•ë ¹ ìƒì„¸ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì¤‘..."):
        collected = collector.collect_law_details(
            st.session_state.selected_laws,
            progress_callback=update_progress
        )
    
    progress_bar.progress(1.0)
    
    success_count = len(collected)
    total_count = len(st.session_state.selected_laws)
    status_text.text(f"ìˆ˜ì§‘ ì™„ë£Œ! (ì„±ê³µ: {success_count}/{total_count})")
    
    if success_count < total_count:
        failed_laws = [law['law_name'] for law in st.session_state.selected_laws 
                      if law['law_id'] not in collected]
        with st.expander("âŒ ìˆ˜ì§‘ ì‹¤íŒ¨í•œ ë²•ë ¹"):
            for law_name in failed_laws:
                st.write(f"- {law_name}")
    
    st.session_state.collected_laws = collected
    
    # í†µê³„ í‘œì‹œ
    display_collection_stats(collected)


def display_collection_stats(collected_laws: Dict[str, Dict[str, Any]]):
    """ìˆ˜ì§‘ í†µê³„ í‘œì‹œ"""
    total_articles = sum(len(law.get('articles', [])) for law in collected_laws.values())
    total_provisions = sum(len(law.get('supplementary_provisions', [])) for law in collected_laws.values())
    total_attachments = sum(len(law.get('attachments', [])) for law in collected_laws.values())
    admin_rule_count = sum(1 for law in collected_laws.values() 
                          if 'í–‰ì •ê·œì¹™' in law.get('law_type', '') or 
                          law.get('law_type') in ['í›ˆë ¹', 'ì˜ˆê·œ', 'ê³ ì‹œ', 'ê·œì •'])
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ì´ ì¡°ë¬¸", f"{total_articles:,}ê°œ")
    with col2:
        st.metric("ì´ ë¶€ì¹™", f"{total_provisions}ê°œ")
    with col3:
        st.metric("ì´ ë³„í‘œ/ë³„ì²¨", f"{total_attachments}ê°œ")
    with col4:
        st.metric("í–‰ì •ê·œì¹™", f"{admin_rule_count}ê°œ")


def display_download_section():
    """ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ í‘œì‹œ"""
    if not st.session_state.collected_laws:
        return
        
    st.header("ğŸ’¾ ë‹¤ìš´ë¡œë“œ")
    
    exporter = LawExporter()
    
    # ë‹¤ìš´ë¡œë“œ ì˜µì…˜
    st.subheader("ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì˜µì…˜")
    download_option = st.radio(
        "ë‹¤ìš´ë¡œë“œ ë°©ì‹ ì„ íƒ",
        ["ê°œë³„ íŒŒì¼ (ZIP)", "í†µí•© íŒŒì¼ (ë‹¨ì¼)"],
        help="ê°œë³„ íŒŒì¼: ê° ë²•ë ¹ë³„ë¡œ íŒŒì¼ ìƒì„±\ní†µí•© íŒŒì¼: ëª¨ë“  ë²•ë ¹ì„ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ"
    )
    
    if download_option == "ê°œë³„ íŒŒì¼ (ZIP)":
        # ZIP ë‹¤ìš´ë¡œë“œ
        zip_data = exporter.export_to_zip(st.session_state.collected_laws)
        
        st.download_button(
            label="ğŸ“¦ ZIP ë‹¤ìš´ë¡œë“œ (JSON+TXT+MD)",
            data=zip_data,
            file_name=f"laws_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
            mime="application/zip",
            use_container_width=True
        )
    else:
        # í†µí•© íŒŒì¼
        file_format = st.selectbox(
            "íŒŒì¼ í˜•ì‹ ì„ íƒ",
            ["JSON", "Markdown", "Text"]
        )
        
        format_map = {
            "JSON": ("json", "application/json", "json"),
            "Markdown": ("markdown", "text/markdown", "md"),
            "Text": ("text", "text/plain", "txt")
        }
        
        fmt, mime, ext = format_map[file_format]
        content = exporter.export_single_file(st.session_state.collected_laws, fmt)
        
        st.download_button(
            label=f"ğŸ’¾ {file_format} í†µí•© íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            data=content,
            file_name=f"all_laws_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{ext}",
            mime=mime,
            use_container_width=True
        )
    
    # ìˆ˜ì§‘ ê²°ê³¼ ìƒì„¸
    with st.expander("ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìƒì„¸"):
        for law_id, law in st.session_state.collected_laws.items():
            emoji = "ğŸ“‹" if ('í–‰ì •ê·œì¹™' in law.get('law_type', '') or 
                           law.get('law_type') in ['í›ˆë ¹', 'ì˜ˆê·œ', 'ê³ ì‹œ', 'ê·œì •']) else "ğŸ“–"
            st.subheader(f"{emoji} {law['law_name']}")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.write(f"ì¡°ë¬¸: {len(law.get('articles', []))}ê°œ")
            with col2:
                st.write(f"ë¶€ì¹™: {len(law.get('supplementary_provisions', []))}ê°œ")
            with col3:
                st.write(f"ë³„í‘œ: {len(law.get('attachments', []))}ê°œ")
            
            # ìƒ˜í”Œ ì¡°ë¬¸
            if law.get('articles'):
                st.write("**ìƒ˜í”Œ ì¡°ë¬¸:**")
                sample = law['articles'][0]
                st.text(f"{sample['number']} {sample.get('title', '')}")
                st.text(sample['content'][:200] + "...")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    initialize_session_state()
    
    # ì œëª©
    st.title("ğŸ“š ë²•ì œì²˜ ë²•ë ¹ ìˆ˜ì§‘ê¸°")
    st.markdown("ë²•ì œì²˜ Open APIë¥¼ í™œìš©í•œ ë²•ë ¹ ìˆ˜ì§‘ ë„êµ¬ (v6.1)")
    st.markdown("**âœ¨ í–‰ì •ê·œì¹™(ê·œì •, ê³ ì‹œ, í›ˆë ¹ ë“±) ì™„ë²½ ì§€ì›!**")
    
    # ì‚¬ì´ë“œë°”
    oc_code = show_sidebar()
    
    # ëª¨ë“œë³„ ì²˜ë¦¬
    if st.session_state.mode == 'direct':
        handle_direct_search_mode(oc_code)
    else:
        handle_file_upload_mode(oc_code)
    
    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
    if st.session_state.search_results:
        display_search_results_and_collect(oc_code)
    
    # ë‹¤ìš´ë¡œë“œ ì„¹ì…˜
    display_download_section()


if __name__ == "__main__":
    main()
