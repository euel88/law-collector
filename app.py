"""
ê°œì„ ëœ ë²•ë ¹ ìˆ˜ì§‘ê¸° - íŒŒì¼ ì—…ë¡œë“œ + ì§ì ‘ ê²€ìƒ‰ í†µí•© ë²„ì „
ë²•ë ¹ëª… ì¶”ì¶œ ì •í™•ë„ í–¥ìƒ ë° ê¸°ì¡´ ê²€ìƒ‰ ê¸°ëŠ¥ ìœ ì§€
"""

import streamlit as st
import requests
import xml.etree.ElementTree as ET
import json
import time
import re
from datetime import datetime
from io import BytesIO
import base64
import urllib3
import zipfile
import pandas as pd
import openpyxl
import PyPDF2
import pdfplumber

# SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë²•ì œì²˜ ë²•ë ¹ ìˆ˜ì§‘ê¸°",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'mode' not in st.session_state:
    st.session_state.mode = 'direct'  # 'direct' or 'file'
if 'extracted_laws' not in st.session_state:
    st.session_state.extracted_laws = []
if 'search_results' not in st.session_state:
    st.session_state.search_results = []
if 'selected_laws' not in st.session_state:
    st.session_state.selected_laws = []
if 'collected_laws' not in st.session_state:
    st.session_state.collected_laws = {}
if 'file_processed' not in st.session_state:
    st.session_state.file_processed = False

class ImprovedLawFileExtractor:
    """ê°œì„ ëœ íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œí•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        # ì œì™¸í•  í‚¤ì›Œë“œ (ì¹´í…Œê³ ë¦¬, ì„¤ëª… ë“±)
        self.exclude_keywords = [
            'ìƒí•˜ìœ„ë²•', 'í–‰ì •ê·œì¹™', 'ë²•ë ¹', 'ì‹œí–‰ë ¹', 'ì‹œí–‰ê·œì¹™', 'ëŒ€í†µë ¹ë ¹', 
            'ì´ë¦¬ë ¹', 'ë¶€ë ¹', 'ê´€í•œ ê·œì •', 'ìƒìœ„ë²•', 'í•˜ìœ„ë²•', 'ê´€ë ¨ë²•ë ¹'
        ]
        
        # ì •í™•í•œ ë²•ë ¹ëª… íŒ¨í„´ (ë” ì—„ê²©í•˜ê²Œ)
        self.law_patterns = [
            # êµ¬ì²´ì ì¸ ë²•ë ¹ëª… íŒ¨í„´ (2ê°œ ì´ìƒì˜ í•œê¸€ + ë²•ë ¹ ì ‘ë¯¸ì‚¬)
            r'([ê°€-í£]{2,}(?:ì—\s*ê´€í•œ\s*)?(?:íŠ¹ë³„|ê¸°ë³¸|ê´€ë¦¬|ì´‰ì§„|ì§€ì›|ìœ¡ì„±|ì§„í¥|ë³´í˜¸|ê·œì œ|ë°©ì§€)?ë²•(?:ë¥ )?)\s*(?:\[ì‹œí–‰[^\]]+\])?',
            r'([ê°€-í£]{2,}(?:ì—\s*ê´€í•œ\s*)?(?:íŠ¹ë³„|ê¸°ë³¸|ê´€ë¦¬|ì´‰ì§„|ì§€ì›|ìœ¡ì„±|ì§„í¥|ë³´í˜¸|ê·œì œ|ë°©ì§€)?ë²•(?:ë¥ )?)\s*ì‹œí–‰ë ¹\s*(?:\[ì‹œí–‰[^\]]+\])?',
            r'([ê°€-í£]{2,}(?:ì—\s*ê´€í•œ\s*)?(?:íŠ¹ë³„|ê¸°ë³¸|ê´€ë¦¬|ì´‰ì§„|ì§€ì›|ìœ¡ì„±|ì§„í¥|ë³´í˜¸|ê·œì œ|ë°©ì§€)?ë²•(?:ë¥ )?)\s*ì‹œí–‰ê·œì¹™\s*(?:\[ì‹œí–‰[^\]]+\])?',
            r'([ê°€-í£]{2,}ê°ë…ê·œì •)\s*(?:\[ì‹œí–‰[^\]]+\])?',
            r'([ê°€-í£]{2,}ì—…ë¬´ì‹œí–‰ì„¸ì¹™)\s*(?:\[ì‹œí–‰[^\]]+\])?',
            r'([ê°€-í£]{2,}(?:ì—\s*ê´€í•œ\s*)?ê·œì •)\s*(?:\[ì‹œí–‰[^\]]+\])?',
            r'([ê°€-í£]{2,}ë¶„ë¥˜)\s*(?:\[ì‹œí–‰[^\]]+\])?',  # í•œêµ­í‘œì¤€ì‚°ì—…ë¶„ë¥˜ ë“±
        ]
        
    def extract_from_pdf(self, file):
        """PDF íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ - ê°œì„ ëœ ë²„ì „"""
        laws = set()
        
        try:
            # pdfplumber ì‚¬ìš©
            with pdfplumber.open(file) as pdf:
                for page in pdf.pages:
                    text = page.extract_text()
                    if text:
                        laws.update(self._extract_law_names_improved(text))
        except:
            # ì‹¤íŒ¨ ì‹œ PyPDF2ë¡œ ì‹œë„
            try:
                pdf_reader = PyPDF2.PdfReader(file)
                for page in pdf_reader.pages:
                    text = page.extract_text()
                    laws.update(self._extract_law_names_improved(text))
            except Exception as e:
                st.error(f"PDF ì½ê¸° ì˜¤ë¥˜: {str(e)}")
        
        return list(laws)
    
    def extract_from_excel(self, file):
        """Excel íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        laws = set()
        
        try:
            excel_file = pd.ExcelFile(file)
            
            for sheet_name in excel_file.sheet_names:
                df = pd.read_excel(file, sheet_name=sheet_name)
                
                for column in df.columns:
                    for value in df[column].dropna():
                        if isinstance(value, str):
                            laws.update(self._extract_law_names_improved(value))
        except Exception as e:
            st.error(f"Excel ì½ê¸° ì˜¤ë¥˜: {str(e)}")
        
        return list(laws)
    
    def extract_from_markdown(self, file):
        """Markdown íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        laws = set()
        
        try:
            content = file.read().decode('utf-8')
            laws.update(self._extract_law_names_improved(content))
        except Exception as e:
            st.error(f"Markdown ì½ê¸° ì˜¤ë¥˜: {str(e)}")
        
        return list(laws)
    
    def extract_from_text(self, file):
        """í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ"""
        laws = set()
        
        try:
            content = file.read().decode('utf-8')
            laws.update(self._extract_law_names_improved(content))
        except Exception as e:
            st.error(f"í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
        
        return list(laws)
    
    def _extract_law_names_improved(self, text):
        """ê°œì„ ëœ ë²•ë ¹ëª… ì¶”ì¶œ - ë” ì •í™•í•˜ê²Œ"""
        laws = set()
        
        # ì¤„ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ì—¬ ë” ì •í™•í•œ ì¶”ì¶œ
        lines = text.split('\n')
        
        for line in lines:
            # ê° íŒ¨í„´ìœ¼ë¡œ ë§¤ì¹­
            for pattern in self.law_patterns:
                matches = re.findall(pattern, line)
                for match in matches:
                    law_name = match.strip()
                    
                    # ì‹œí–‰ ì •ë³´ ì œê±°
                    law_name = re.sub(r'\s*\[ì‹œí–‰[^\]]+\]', '', law_name)
                    
                    # ì •ì œ
                    law_name = law_name.replace('\n', ' ').replace('\t', ' ')
                    law_name = ' '.join(law_name.split())
                    
                    # ì œì™¸ í‚¤ì›Œë“œ ì²´í¬ (ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê²½ìš°ë§Œ)
                    if law_name in self.exclude_keywords:
                        continue
                    
                    # ë„ˆë¬´ ì§§ì€ ê²ƒ ì œì™¸ (ìµœì†Œ 3ì ì´ìƒ)
                    if len(law_name) < 3:
                        continue
                    
                    # ìœ íš¨ì„± ê²€ì¦
                    # 1. ìµœì†Œ 2ê¸€ì ì´ìƒì˜ í•œê¸€ì´ ë²•ë ¹ ì ‘ë¯¸ì‚¬ ì•ì— ìˆì–´ì•¼ í•¨
                    if re.match(r'^[ê°€-í£]{2,}', law_name):
                        laws.add(law_name)
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        return sorted(list(laws))

class LawCollectorAPI:
    """ë²•ë ¹ ìˆ˜ì§‘ API í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.law_search_url = "http://www.law.go.kr/DRF/lawSearch.do"
        self.law_detail_url = "http://www.law.go.kr/DRF/lawService.do"
        self.delay = 0.5
        
    def search_law(self, oc_code: str, law_name: str):
        """ë²•ë ¹ ê²€ìƒ‰"""
        params = {
            'OC': oc_code,
            'target': 'law',
            'type': 'XML',
            'query': law_name,
            'display': '100',
            'page': '1'
        }
        
        try:
            response = requests.get(
                self.law_search_url, 
                params=params, 
                timeout=10,
                verify=False
            )
            response.encoding = 'utf-8'
            
            if response.status_code != 200:
                return []
            
            content = response.text
            if content.startswith('\ufeff'):
                content = content[1:]
            
            root = ET.fromstring(content.encode('utf-8'))
            laws = []
            
            for law_elem in root.findall('.//law'):
                law_id = law_elem.findtext('ë²•ë ¹ID', '')
                law_name_full = law_elem.findtext('ë²•ë ¹ëª…í•œê¸€', '')
                law_msn = law_elem.findtext('ë²•ë ¹ì¼ë ¨ë²ˆí˜¸', '')
                
                if law_id and law_name_full:
                    law_info = {
                        'law_id': law_id,
                        'law_msn': law_msn,
                        'law_name': law_name_full,
                        'law_type': law_elem.findtext('ë²•ì¢…êµ¬ë¶„', ''),
                        'promulgation_date': law_elem.findtext('ê³µí¬ì¼ì', ''),
                        'enforcement_date': law_elem.findtext('ì‹œí–‰ì¼ì', ''),
                    }
                    laws.append(law_info)
            
            return laws
            
        except Exception as e:
            st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def get_law_detail_with_full_content(self, oc_code: str, law_id: str, law_msn: str, law_name: str):
        """ë²•ë ¹ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ - ì¡°ë¬¸, ë¶€ì¹™, ë³„í‘œ ëª¨ë‘ í¬í•¨"""
        params = {
            'OC': oc_code,
            'target': 'law',
            'type': 'XML',
            'MST': law_msn,
            'mobileYn': 'N'
        }
        
        try:
            response = requests.get(
                self.law_detail_url,
                params=params,
                timeout=30,
                verify=False
            )
            response.encoding = 'utf-8'
            
            if response.status_code != 200:
                st.warning(f"{law_name} ìƒì„¸ ì •ë³´ ì ‘ê·¼ ì‹¤íŒ¨")
                return None
            
            content = response.text
            if content.startswith('\ufeff'):
                content = content[1:]
            
            try:
                root = ET.fromstring(content.encode('utf-8'))
            except ET.ParseError:
                st.warning(f"{law_name} XML íŒŒì‹± ì˜¤ë¥˜")
                return None
            
            # ë²•ë ¹ ì •ë³´ êµ¬ì¡°
            law_detail = {
                'law_id': law_id,
                'law_msn': law_msn,
                'law_name': law_name,
                'law_type': '',
                'promulgation_date': '',
                'enforcement_date': '',
                'articles': [],
                'supplementary_provisions': [],
                'attachments': [],
                'raw_content': '',
            }
            
            # ê¸°ë³¸ ì •ë³´
            basic_info = root.find('.//ê¸°ë³¸ì •ë³´')
            if basic_info is not None:
                law_detail['law_type'] = basic_info.findtext('ë²•ì¢…êµ¬ë¶„ëª…', '')
                law_detail['promulgation_date'] = basic_info.findtext('ê³µí¬ì¼ì', '')
                law_detail['enforcement_date'] = basic_info.findtext('ì‹œí–‰ì¼ì', '')
            
            # ì¡°ë¬¸, ë¶€ì¹™, ë³„í‘œ ì¶”ì¶œ (ê¸°ì¡´ ì½”ë“œ ë™ì¼)
            self._extract_all_articles(root, law_detail)
            self._extract_supplementary_provisions(root, law_detail)
            self._extract_attachments(root, law_detail)
            
            if not law_detail['articles']:
                law_detail['raw_content'] = self._extract_full_text(root)
            
            return law_detail
            
        except Exception as e:
            st.warning(f"{law_name} ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    # ë‚˜ë¨¸ì§€ ë©”ì„œë“œë“¤ì€ ê¸°ì¡´ê³¼ ë™ì¼...
    def _extract_all_articles(self, root, law_detail):
        """ëª¨ë“  ì¡°ë¬¸ ì¶”ì¶œ"""
        articles_section = root.find('.//ì¡°ë¬¸')
        if articles_section is not None:
            for article_unit in articles_section.findall('.//ì¡°ë¬¸ë‹¨ìœ„'):
                article_info = self._parse_article_unit(article_unit)
                if article_info:
                    law_detail['articles'].append(article_info)
        
        if not law_detail['articles']:
            for article_content in root.findall('.//ì¡°ë¬¸ë‚´ìš©'):
                if article_content.text:
                    article_info = self._parse_article_text(article_content.text)
                    if article_info:
                        law_detail['articles'].append(article_info)
        
        if not law_detail['articles']:
            article_elements = []
            for elem in root.iter():
                if elem.tag in ['ì¡°', 'ì¡°ë¬¸', 'article', 'ì¡°ë¬¸ë‹¨ìœ„']:
                    article_elements.append(elem)
            
            for elem in article_elements:
                article_info = self._extract_article_from_element(elem)
                if article_info and article_info['content']:
                    law_detail['articles'].append(article_info)
    
    def _parse_article_unit(self, article_elem):
        """ì¡°ë¬¸ë‹¨ìœ„ íŒŒì‹±"""
        article_info = {
            'number': '',
            'title': '',
            'content': '',
            'paragraphs': []
        }
        
        article_num = article_elem.findtext('ì¡°ë¬¸ë²ˆí˜¸', '')
        if article_num:
            article_info['number'] = f"ì œ{article_num}ì¡°"
        
        article_info['title'] = article_elem.findtext('ì¡°ë¬¸ì œëª©', '')
        
        article_content = article_elem.findtext('ì¡°ë¬¸ë‚´ìš©', '')
        if not article_content:
            article_content = self._get_all_text(article_elem)
        
        article_info['content'] = article_content
        
        for para in article_elem.findall('.//í•­'):
            para_info = {
                'number': para.findtext('í•­ë²ˆí˜¸', ''),
                'content': para.findtext('í•­ë‚´ìš©', '')
            }
            if para_info['content']:
                article_info['paragraphs'].append(para_info)
        
        return article_info if (article_info['number'] or article_info['content']) else None
    
    def _parse_article_text(self, text):
        """ì¡°ë¬¸ í…ìŠ¤íŠ¸ íŒŒì‹±"""
        pattern = r'(ì œ\d+ì¡°(?:ì˜\d+)?)\s*(?:\((.*?)\))?\s*(.*?)(?=ì œ\d+ì¡°|$)'
        matches = re.findall(pattern, text, re.DOTALL)
        
        articles = []
        for match in matches:
            article_info = {
                'number': match[0],
                'title': match[1],
                'content': match[2].strip(),
                'paragraphs': []
            }
            
            para_pattern = r'([â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]+)\s*(.*?)(?=[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]|$)'
            para_matches = re.findall(para_pattern, article_info['content'], re.DOTALL)
            
            for para_match in para_matches:
                article_info['paragraphs'].append({
                    'number': para_match[0],
                    'content': para_match[1].strip()
                })
            
            articles.append(article_info)
        
        return articles[0] if articles else None
    
    def _extract_article_from_element(self, elem):
        """ìš”ì†Œì—ì„œ ì¡°ë¬¸ ì •ë³´ ì¶”ì¶œ"""
        article_info = {
            'number': '',
            'title': '',
            'content': '',
            'paragraphs': []
        }
        
        for tag in ['ì¡°ë¬¸ë²ˆí˜¸', 'ì¡°ë²ˆí˜¸', 'ë²ˆí˜¸']:
            num = elem.findtext(tag, '')
            if num:
                article_info['number'] = f"ì œ{num}ì¡°" if not num.startswith('ì œ') else num
                break
        
        for tag in ['ì¡°ë¬¸ì œëª©', 'ì¡°ì œëª©', 'ì œëª©']:
            title = elem.findtext(tag, '')
            if title:
                article_info['title'] = title
                break
        
        for tag in ['ì¡°ë¬¸ë‚´ìš©', 'ì¡°ë‚´ìš©', 'ë‚´ìš©']:
            content = elem.findtext(tag, '')
            if content:
                article_info['content'] = content
                break
        
        if not article_info['content']:
            article_info['content'] = self._get_all_text(elem)
        
        return article_info
    
    def _extract_supplementary_provisions(self, root, law_detail):
        """ë¶€ì¹™ ì¶”ì¶œ"""
        for addendum in root.findall('.//ë¶€ì¹™'):
            addendum_info = {
                'number': addendum.findtext('ë¶€ì¹™ë²ˆí˜¸', ''),
                'promulgation_date': addendum.findtext('ë¶€ì¹™ê³µí¬ì¼ì', ''),
                'content': self._get_all_text(addendum)
            }
            if addendum_info['content']:
                law_detail['supplementary_provisions'].append(addendum_info)
        
        if not law_detail['supplementary_provisions']:
            for elem in root.iter():
                if elem.tag == 'ë¶€ì¹™ë‚´ìš©' and elem.text:
                    law_detail['supplementary_provisions'].append({
                        'number': '',
                        'promulgation_date': '',
                        'content': elem.text
                    })
    
    def _extract_attachments(self, root, law_detail):
        """ë³„í‘œ/ë³„ì²¨ ì¶”ì¶œ"""
        for table in root.findall('.//ë³„í‘œ'):
            table_info = {
                'type': 'ë³„í‘œ',
                'number': table.findtext('ë³„í‘œë²ˆí˜¸', ''),
                'title': table.findtext('ë³„í‘œì œëª©', ''),
                'content': self._get_all_text(table)
            }
            if table_info['content'] or table_info['title']:
                law_detail['attachments'].append(table_info)
        
        for form in root.findall('.//ë³„ì§€'):
            form_info = {
                'type': 'ë³„ì§€',
                'number': form.findtext('ë³„ì§€ë²ˆí˜¸', ''),
                'title': form.findtext('ë³„ì§€ì œëª©', ''),
                'content': self._get_all_text(form)
            }
            if form_info['content'] or form_info['title']:
                law_detail['attachments'].append(form_info)
        
        for format_elem in root.findall('.//ì„œì‹'):
            format_info = {
                'type': 'ì„œì‹',
                'number': format_elem.findtext('ì„œì‹ë²ˆí˜¸', ''),
                'title': format_elem.findtext('ì„œì‹ì œëª©', ''),
                'content': self._get_all_text(format_elem)
            }
            if format_info['content'] or format_info['title']:
                law_detail['attachments'].append(format_info)
    
    def _extract_full_text(self, root):
        """ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        return self._get_all_text(root)
    
    def _get_all_text(self, elem):
        """ìš”ì†Œì˜ ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        texts = []
        
        if elem.text and elem.text.strip():
            texts.append(elem.text.strip())
        
        for child in elem:
            child_text = self._get_all_text(child)
            if child_text:
                texts.append(child_text)
            
            if child.tail and child.tail.strip():
                texts.append(child.tail.strip())
        
        return ' '.join(texts)
    
    def export_to_zip(self, laws_dict):
        """ìˆ˜ì§‘ëœ ë²•ë ¹ì„ ZIPìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        zip_buffer = BytesIO()
        
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            all_data = {
                'collection_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'total_laws': len(laws_dict),
                'laws': laws_dict
            }
            
            zip_file.writestr(
                'all_laws.json',
                json.dumps(all_data, ensure_ascii=False, indent=2)
            )
            
            for law_id, law in laws_dict.items():
                safe_name = re.sub(r'[\\/*?:"<>|]', '_', law['law_name'])
                
                zip_file.writestr(
                    f'laws/{safe_name}.json',
                    json.dumps(law, ensure_ascii=False, indent=2)
                )
                
                text_content = self._format_law_full_text(law)
                zip_file.writestr(
                    f'laws/{safe_name}.txt',
                    text_content
                )
            
            readme = self._create_readme(laws_dict)
            zip_file.writestr('README.md', readme)
        
        zip_buffer.seek(0)
        return zip_buffer.getvalue()
    
    def _format_law_full_text(self, law):
        """ë²•ë ¹ ì „ì²´ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ í¬ë§·"""
        lines = []
        
        lines.append(f"{'=' * 80}")
        lines.append(f"ë²•ë ¹ëª…: {law['law_name']}")
        lines.append(f"ë²•ì¢…êµ¬ë¶„: {law.get('law_type', '')}")
        lines.append(f"ê³µí¬ì¼ì: {law.get('promulgation_date', '')}")
        lines.append(f"ì‹œí–‰ì¼ì: {law.get('enforcement_date', '')}")
        lines.append(f"{'=' * 80}\n")
        
        if law.get('articles'):
            lines.append("ã€ ì¡° ë¬¸ ã€‘\n")
            for article in law['articles']:
                lines.append(f"\n{article['number']} {article.get('title', '')}")
                lines.append(article['content'])
                
                if article.get('paragraphs'):
                    for para in article['paragraphs']:
                        lines.append(f"\n  {para['number']} {para['content']}")
                
                lines.append("")
        
        if law.get('supplementary_provisions'):
            lines.append("\n\nã€ ë¶€ ì¹™ ã€‘\n")
            for idx, supp in enumerate(law['supplementary_provisions'], 1):
                if supp.get('promulgation_date'):
                    lines.append(f"\në¶€ì¹™ <{supp['promulgation_date']}>")
                else:
                    lines.append(f"\në¶€ì¹™ {idx}")
                lines.append(supp['content'])
        
        if law.get('attachments'):
            lines.append("\n\nã€ ë³„í‘œ/ë³„ì²¨ ã€‘\n")
            for attach in law['attachments']:
                lines.append(f"\n[{attach['type']}] {attach.get('title', '')}")
                lines.append(attach['content'])
                lines.append("")
        
        if not law.get('articles') and law.get('raw_content'):
            lines.append("\n\nã€ ì› ë¬¸ ã€‘\n")
            lines.append(law['raw_content'])
        
        return '\n'.join(lines)
    
    def _create_readme(self, laws_dict):
        """README ìƒì„±"""
        content = f"""# ë²•ë ¹ ìˆ˜ì§‘ ê²°ê³¼

ìˆ˜ì§‘ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ì´ ë²•ë ¹ ìˆ˜: {len(laws_dict)}ê°œ

## ğŸ“ íŒŒì¼ êµ¬ì¡°

- `all_laws.json`: ì „ì²´ ë²•ë ¹ ë°ì´í„° (JSON)
- `laws/`: ê°œë³„ ë²•ë ¹ íŒŒì¼ ë””ë ‰í† ë¦¬
  - `*.json`: ë²•ë ¹ë³„ ìƒì„¸ ë°ì´í„°
  - `*.txt`: ë²•ë ¹ë³„ ì „ì²´ í…ìŠ¤íŠ¸ (ì¡°ë¬¸, ë¶€ì¹™, ë³„í‘œ í¬í•¨)
- `README.md`: ì´ íŒŒì¼

## ğŸ“Š ìˆ˜ì§‘ í†µê³„

"""
        total_articles = 0
        total_provisions = 0
        total_attachments = 0
        
        for law in laws_dict.values():
            total_articles += len(law.get('articles', []))
            total_provisions += len(law.get('supplementary_provisions', []))
            total_attachments += len(law.get('attachments', []))
        
        content += f"- ì´ ì¡°ë¬¸ ìˆ˜: {total_articles:,}ê°œ\n"
        content += f"- ì´ ë¶€ì¹™ ìˆ˜: {total_provisions}ê°œ\n"
        content += f"- ì´ ë³„í‘œ/ë³„ì²¨ ìˆ˜: {total_attachments}ê°œ\n"
        
        content += "\n## ğŸ“– ìˆ˜ì§‘ëœ ë²•ë ¹ ëª©ë¡\n\n"
        
        for law_id, law in laws_dict.items():
            article_count = len(law.get('articles', []))
            content += f"### {law['law_name']}\n"
            content += f"- ë²•ì¢…êµ¬ë¶„: {law.get('law_type', '')}\n"
            content += f"- ì‹œí–‰ì¼ì: {law.get('enforcement_date', '')}\n"
            content += f"- ì¡°ë¬¸: {article_count}ê°œ\n"
            content += f"- ë¶€ì¹™: {len(law.get('supplementary_provisions', []))}ê°œ\n"
            content += f"- ë³„í‘œ/ë³„ì²¨: {len(law.get('attachments', []))}ê°œ\n\n"
        
        return content


# ë©”ì¸ UI
def main():
    st.title("ğŸ“š ë²•ì œì²˜ ë²•ë ¹ ìˆ˜ì§‘ê¸°")
    st.markdown("ë²•ì œì²˜ Open APIë¥¼ í™œìš©í•œ ë²•ë ¹ ìˆ˜ì§‘ ë„êµ¬")
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # ê¸°ê´€ì½”ë“œ ì…ë ¥
        oc_code = st.text_input(
            "ê¸°ê´€ì½”ë“œ (OC)",
            placeholder="ì´ë©”ì¼ @ ì•ë¶€ë¶„",
            help="ì˜ˆ: test@korea.kr â†’ test"
        )
        
        st.divider()
        
        # ëª¨ë“œ ì„ íƒ
        st.subheader("ğŸ¯ ìˆ˜ì§‘ ë°©ì‹")
        mode = st.radio(
            "ë°©ì‹ ì„ íƒ",
            ["ì§ì ‘ ê²€ìƒ‰", "íŒŒì¼ ì—…ë¡œë“œ"],
            help="ì§ì ‘ ê²€ìƒ‰: ë²•ë ¹ëª…ì„ ì…ë ¥í•˜ì—¬ ê²€ìƒ‰\níŒŒì¼ ì—…ë¡œë“œ: PDF/Excel/MD íŒŒì¼ì—ì„œ ë²•ë ¹ ì¶”ì¶œ"
        )
        st.session_state.mode = 'direct' if mode == "ì§ì ‘ ê²€ìƒ‰" else 'file'
        
        # ì§ì ‘ ê²€ìƒ‰ ëª¨ë“œ
        if st.session_state.mode == 'direct':
            law_name = st.text_input(
                "ë²•ë ¹ëª…",
                placeholder="ì˜ˆ: ë¯¼ë²•, ìƒë²•, í˜•ë²•",
                help="ê²€ìƒ‰í•  ë²•ë ¹ëª…ì„ ì…ë ¥í•˜ì„¸ìš”"
            )
            
            search_btn = st.button("ğŸ” ê²€ìƒ‰", type="primary", use_container_width=True)
        
        # íŒŒì¼ ì—…ë¡œë“œ ëª¨ë“œ
        else:
            st.subheader("ğŸ“„ ë²•ë ¹ì²´ê³„ë„ íŒŒì¼ ì—…ë¡œë“œ")
            uploaded_file = st.file_uploader(
                "íŒŒì¼ ì„ íƒ",
                type=['pdf', 'xlsx', 'xls', 'md', 'txt'],
                help="PDF, Excel, Markdown, í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì§€ì›í•©ë‹ˆë‹¤"
            )
            
            if uploaded_file:
                st.success(f"âœ… {uploaded_file.name} ì—…ë¡œë“œë¨")
                file_type = uploaded_file.name.split('.')[-1].lower()
                st.info(f"íŒŒì¼ í˜•ì‹: {file_type.upper()}")
        
        # ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ”„ ì´ˆê¸°í™”", type="secondary", use_container_width=True):
            for key in st.session_state:
                if key != 'mode':
                    del st.session_state[key]
            st.experimental_rerun()
    
    # ë©”ì¸ ì»¨í…ì¸ 
    collector = LawCollectorAPI()
    
    # ì§ì ‘ ê²€ìƒ‰ ëª¨ë“œ
    if st.session_state.mode == 'direct':
        st.header("ğŸ” ì§ì ‘ ê²€ìƒ‰ ëª¨ë“œ")
        
        if 'search_btn' in locals() and search_btn:
            if not oc_code:
                st.error("ê¸°ê´€ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            elif not law_name:
                st.error("ë²•ë ¹ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            else:
                with st.spinner(f"'{law_name}' ê²€ìƒ‰ ì¤‘..."):
                    results = collector.search_law(oc_code, law_name)
                    
                    if results:
                        st.success(f"{len(results)}ê°œì˜ ë²•ë ¹ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                        st.session_state.search_results = results
                    else:
                        st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        st.session_state.search_results = []
        
        # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
        if st.session_state.search_results:
            display_search_results_and_collect(collector, oc_code)
    
    # íŒŒì¼ ì—…ë¡œë“œ ëª¨ë“œ
    else:
        st.header("ğŸ“„ íŒŒì¼ ì—…ë¡œë“œ ëª¨ë“œ")
        extractor = ImprovedLawFileExtractor()
        
        # íŒŒì¼ì—ì„œ ë²•ë ¹ ì¶”ì¶œ
        if uploaded_file and not st.session_state.file_processed:
            st.subheader("ğŸ“‹ STEP 1: ë²•ë ¹ëª… ì¶”ì¶œ")
            
            with st.spinner("íŒŒì¼ì—ì„œ ë²•ë ¹ëª…ì„ ì¶”ì¶œí•˜ëŠ” ì¤‘..."):
                file_type = uploaded_file.name.split('.')[-1].lower()
                
                # íŒŒì¼ íƒ€ì…ë³„ ì²˜ë¦¬
                if file_type == 'pdf':
                    extracted_laws = extractor.extract_from_pdf(uploaded_file)
                elif file_type in ['xlsx', 'xls']:
                    extracted_laws = extractor.extract_from_excel(uploaded_file)
                elif file_type == 'md':
                    extracted_laws = extractor.extract_from_markdown(uploaded_file)
                elif file_type == 'txt':
                    extracted_laws = extractor.extract_from_text(uploaded_file)
                else:
                    st.error("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤")
                    extracted_laws = []
                
                if extracted_laws:
                    st.success(f"âœ… {len(extracted_laws)}ê°œì˜ ë²•ë ¹ëª…ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                    st.session_state.extracted_laws = extracted_laws
                    st.session_state.file_processed = True
                else:
                    st.warning("íŒŒì¼ì—ì„œ ë²•ë ¹ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ì¶”ì¶œëœ ë²•ë ¹ í‘œì‹œ ë° í¸ì§‘
        if st.session_state.extracted_laws:
            st.subheader("âœï¸ STEP 2: ë²•ë ¹ëª… í™•ì¸ ë° í¸ì§‘")
            st.info("ì¶”ì¶œëœ ë²•ë ¹ëª…ì„ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ìˆ˜ì •í•˜ê±°ë‚˜ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            
            # ì¶”ì¶œëœ ë²•ë ¹ ëª©ë¡ í‘œì‹œ (ì½ê¸° ì „ìš©)
            st.write("**ì¶”ì¶œëœ ë²•ë ¹ëª…:**")
            for idx, law in enumerate(st.session_state.extracted_laws, 1):
                st.write(f"{idx}. {law}")
            
            # ë²•ë ¹ëª… í¸ì§‘ ì˜ì—­
            edited_laws = []
            
            st.write("\n**ë²•ë ¹ëª… í¸ì§‘:**")
            for idx, law_name in enumerate(st.session_state.extracted_laws):
                col1, col2 = st.columns([4, 1])
                with col1:
                    edited_name = st.text_input(
                        f"ë²•ë ¹ {idx+1}",
                        value=law_name,
                        key=f"edit_{idx}"
                    )
                    if edited_name:
                        edited_laws.append(edited_name)
                with col2:
                    if st.button("ì‚­ì œ", key=f"del_{idx}"):
                        st.session_state.extracted_laws.pop(idx)
                        st.experimental_rerun()
            
            # ë²•ë ¹ëª… ì¶”ê°€
            st.subheader("ë²•ë ¹ëª… ì¶”ê°€")
            new_law = st.text_input("ìƒˆ ë²•ë ¹ëª… ì…ë ¥", key="new_law_input")
            if st.button("â• ì¶”ê°€") and new_law:
                st.session_state.extracted_laws.append(new_law)
                st.experimental_rerun()
            
            # ë²•ë ¹ ê²€ìƒ‰ ë²„íŠ¼
            if st.button("ğŸ” ë²•ë ¹ ê²€ìƒ‰", type="primary", use_container_width=True):
                if not oc_code:
                    st.error("ê¸°ê´€ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
                else:
                    search_results = []
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    if edited_laws:
                        st.session_state.extracted_laws = edited_laws
                    
                    total = len(st.session_state.extracted_laws)
                    
                    for idx, law_name in enumerate(st.session_state.extracted_laws):
                        progress = (idx + 1) / total
                        progress_bar.progress(progress)
                        status_text.text(f"ê²€ìƒ‰ ì¤‘: {law_name}")
                        
                        results = collector.search_law(oc_code, law_name)
                        
                        for result in results:
                            if law_name in result['law_name'] or result['law_name'] in law_name:
                                result['search_query'] = law_name
                                search_results.append(result)
                        
                        time.sleep(collector.delay)
                    
                    progress_bar.progress(1.0)
                    status_text.text("ê²€ìƒ‰ ì™„ë£Œ!")
                    
                    if search_results:
                        st.success(f"âœ… ì´ {len(search_results)}ê°œì˜ ë²•ë ¹ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                        st.session_state.search_results = search_results
                    else:
                        st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
        if st.session_state.search_results:
            display_search_results_and_collect(collector, oc_code, is_file_mode=True)


def display_search_results_and_collect(collector, oc_code, is_file_mode=False):
    """ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ ë° ìˆ˜ì§‘ - ê³µí†µ í•¨ìˆ˜"""
    st.subheader("ğŸ“‘ ê²€ìƒ‰ ê²°ê³¼")
    
    # ì „ì²´ ì„ íƒ
    select_all = st.checkbox("ì „ì²´ ì„ íƒ", key="select_all_results")
    
    # í…Œì´ë¸” í—¤ë”
    if is_file_mode:
        col1, col2, col3, col4, col5 = st.columns([1, 3, 2, 2, 2])
        with col5:
            st.markdown("**ê²€ìƒ‰ì–´**")
    else:
        col1, col2, col3, col4 = st.columns([1, 3, 2, 2])
    
    with col1:
        st.markdown("**ì„ íƒ**")
    with col2:
        st.markdown("**ë²•ë ¹ëª…**")
    with col3:
        st.markdown("**ë²•ì¢…êµ¬ë¶„**")
    with col4:
        st.markdown("**ì‹œí–‰ì¼ì**")
    
    st.divider()
    
    # ì„ íƒëœ ë²•ë ¹
    selected_indices = []
    
    for idx, law in enumerate(st.session_state.search_results):
        if is_file_mode:
            col1, col2, col3, col4, col5 = st.columns([1, 3, 2, 2, 2])
        else:
            col1, col2, col3, col4 = st.columns([1, 3, 2, 2])
        
        with col1:
            is_selected = st.checkbox("", key=f"sel_{idx}", value=select_all)
            if is_selected:
                selected_indices.append(idx)
        
        with col2:
            st.write(law['law_name'])
        
        with col3:
            st.write(law.get('law_type', ''))
        
        with col4:
            st.write(law.get('enforcement_date', ''))
        
        if is_file_mode:
            with col5:
                st.write(law.get('search_query', ''))
    
    # ì„ íƒëœ ë²•ë ¹ ì €ì¥
    st.session_state.selected_laws = [
        st.session_state.search_results[i] for i in selected_indices
    ]
    
    if st.session_state.selected_laws:
        st.success(f"{len(st.session_state.selected_laws)}ê°œ ë²•ë ¹ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤")
        
        # ìˆ˜ì§‘ ë²„íŠ¼
        if st.button("ğŸ“¥ ì„ íƒí•œ ë²•ë ¹ ìˆ˜ì§‘", type="primary", use_container_width=True):
            collected_laws = {}
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            total = len(st.session_state.selected_laws)
            success_count = 0
            
            for idx, law in enumerate(st.session_state.selected_laws):
                progress = (idx + 1) / total
                progress_bar.progress(progress)
                status_text.text(f"ìˆ˜ì§‘ ì¤‘ ({idx + 1}/{total}): {law['law_name']}")
                
                law_detail = collector.get_law_detail_with_full_content(
                    oc_code,
                    law['law_id'],
                    law.get('law_msn', ''),
                    law['law_name']
                )
                
                if law_detail:
                    collected_laws[law['law_id']] = law_detail
                    success_count += 1
                
                time.sleep(collector.delay)
            
            progress_bar.progress(1.0)
            status_text.text(f"ìˆ˜ì§‘ ì™„ë£Œ! (ì„±ê³µ: {success_count}/{total})")
            
            st.session_state.collected_laws = collected_laws
            
            # í†µê³„ í‘œì‹œ
            total_articles = sum(len(law.get('articles', [])) for law in collected_laws.values())
            total_provisions = sum(len(law.get('supplementary_provisions', [])) for law in collected_laws.values())
            total_attachments = sum(len(law.get('attachments', [])) for law in collected_laws.values())
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì´ ì¡°ë¬¸", f"{total_articles:,}ê°œ")
            with col2:
                st.metric("ì´ ë¶€ì¹™", f"{total_provisions}ê°œ")
            with col3:
                st.metric("ì´ ë³„í‘œ/ë³„ì²¨", f"{total_attachments}ê°œ")
    
    # ë‹¤ìš´ë¡œë“œ ì„¹ì…˜
    if st.session_state.collected_laws:
        st.header("ğŸ’¾ ë‹¤ìš´ë¡œë“œ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # JSON ë‹¤ìš´ë¡œë“œ
            json_data = {
                'collection_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'mode': st.session_state.mode,
                'laws': st.session_state.collected_laws
            }
            json_str = json.dumps(json_data, ensure_ascii=False, indent=2)
            
            st.download_button(
                label="ğŸ“„ JSON ë‹¤ìš´ë¡œë“œ",
                data=json_str,
                file_name=f"laws_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                use_container_width=True
            )
        
        with col2:
            # ZIP ë‹¤ìš´ë¡œë“œ
            zip_data = collector.export_to_zip(st.session_state.collected_laws)
            
            st.download_button(
                label="ğŸ“¦ ZIP ë‹¤ìš´ë¡œë“œ (ì „ì²´ ë‚´ìš©)",
                data=zip_data,
                file_name=f"laws_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                mime="application/zip",
                use_container_width=True
            )
        
        # ìˆ˜ì§‘ ê²°ê³¼ ìƒì„¸
        with st.expander("ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìƒì„¸"):
            for law_id, law in st.session_state.collected_laws.items():
                st.subheader(law['law_name'])
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.write(f"ì¡°ë¬¸: {len(law.get('articles', []))}ê°œ")
                with col2:
                    st.write(f"ë¶€ì¹™: {len(law.get('supplementary_provisions', []))}ê°œ")
                with col3:
                    st.write(f"ë³„í‘œ: {len(law.get('attachments', []))}ê°œ")
                
                if law.get('articles'):
                    st.write("**ìƒ˜í”Œ ì¡°ë¬¸:**")
                    sample = law['articles'][0]
                    st.text(f"{sample['number']} {sample.get('title', '')}")
                    st.text(sample['content'][:200] + "..." if len(sample['content']) > 200 else sample['content'])


if __name__ == "__main__":
    main()
